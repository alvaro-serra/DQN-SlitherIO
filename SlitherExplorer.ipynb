{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slither Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import universe\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export OPENAI_REMOTE_VERBOSE=0 ##put this in the terminal to remove verbos#e\n",
    "#env = gym.make('internet.SlitherIO-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actionlist = [action for action in env.action_space]\n",
    "#env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PointerEvent', 69, 336, 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "There are 12 possible defined actions. The original number of actions are #pixels * 2, meaning we can\n",
    "press any pixel on the screen to define directions and either press space at the same time or not. In order\n",
    "to lower the number of allowed actions and still get a smooth direction control we decide to define 12 regions\n",
    "in the border of the screen where we will press either the center of the region or a random pixel in that region\n",
    "(depending on the strategy taken) so as to move in that direction.\n",
    "\"\"\"\n",
    "##y = 85-386, x = 18-522\n",
    "topleft = (19,86)\n",
    "bottomright = (522,386)\n",
    "div_x = 5\n",
    "div_y = 3\n",
    "interx = int((bottomright[0]-topleft[0])/div_x)\n",
    "intery = int((bottomright[1]-topleft[1])/div_y)\n",
    "pointers = ([(topleft[0],topleft[1]+intery*i) for i in range(div_y-1,-1,-1)]+\n",
    "           [(topleft[0]+interx*i,topleft[1]) for i in range(1,div_x-1)]+\n",
    "           [(topleft[0]+interx*4,topleft[1]+intery*i) for i in range(div_y)]+\n",
    "           [(topleft[0]+interx*i,topleft[1]+intery*2) for i in range(div_x-2,0,-1)])\n",
    "nactions = 12\n",
    "\n",
    "\n",
    "def idx2act(idx):\n",
    "    p = [[('PointerEvent', x+int(interx/2), y+int(intery/2), 0)] for (x,y) in pointers]\n",
    "    return p[idx]\n",
    "\n",
    "\n",
    "p = idx2act(0)\n",
    "#[i for i in range(3,-1,-1)]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:17,922] Making new env: internet.SlitherIO-v0\n",
      "[2018-05-08 23:35:18,174] Writing logs to file: /tmp/universe-20995.log\n",
      "[2018-05-08 23:35:18,252] Ports used: dict_keys([])\n",
      "[2018-05-08 23:35:18,254] [0] Creating container: image=quay.io/openai/universe.flashgames:0.20.28. Run the same thing by hand as: docker run -p 5900:5900 -p 15900:15900 --ipc host --privileged --cap-add SYS_ADMIN quay.io/openai/universe.flashgames:0.20.28\n",
      "[2018-05-08 23:35:20,739] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:20,747] At least one sockets was closed by the remote. Sleeping 1s...\n",
      "[2018-05-08 23:35:21,750] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:21,754] Remote closed: address=localhost:5900\n",
      "[2018-05-08 23:35:21,756] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m Setting VNC and rewarder password: openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:22,758] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:22,761] Remote closed: address=localhost:5900\n",
      "[2018-05-08 23:35:22,763] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:23 UTC 2018] Waiting for /tmp/.X11-unix/X0 to be created (try 1/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:23,765] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:23,768] Remote closed: address=localhost:5900\n",
      "[2018-05-08 23:35:23,771] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Xvnc TigerVNC 1.7.0 - built Sep  8 2016 10:39:22\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Copyright (C) 1999-2016 TigerVNC Team and many others (see README.txt)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] See http://www.tigervnc.org for information on TigerVNC.\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Underlying X server release 11400000, The X.Org Foundation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension VNC-EXTENSION\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension Generic Event Extension\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension SHAPE\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension MIT-SHM\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XInputExtension\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XTEST\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension BIG-REQUESTS\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension SYNC\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XKEYBOARD\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XC-MISC\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XINERAMA\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XFIXES\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension RENDER\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension RANDR\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension COMPOSITE\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension DAMAGE\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension MIT-SCREEN-SAVER\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension DOUBLE-BUFFER\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension RECORD\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension DPMS\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension X-Resource\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XVideo\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension XVideo-MotionCompensation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Initializing built-in extension GLX\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:35:23 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  vncext:      VNC extension running!\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  vncext:      Listening for VNC connections on all interface(s), port 5900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  vncext:      created VNC server for screen 0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/Type1/, removing from list!\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/75dpi/, removing from list!\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/100dpi/, removing from list!\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:24,303] Launching system_diagnostics_logger.py, recorder_logdir=/tmp/demo\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:24,305] Launching reward_recorder.py, recorder_logdir=/tmp/demo\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:24,308] Launching vnc_recorder.py, recorder_logdir=/tmp/demo\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:24,316] PID 57 launched with command ['sudo', '-H', '-u', 'nobody', 'DISPLAY=:0', 'DBUS_SESSION_BUS_ADDRESS=/dev/null', '/app/universe-envs/controlplane/bin/controlplane.py', '--rewarder-port=15901']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:24,774] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:24,777] Remote closed: address=localhost:5900\n",
      "[2018-05-08 23:35:24,779] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m WebSocket server settings:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m   - Listen on :5898\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m   - Flash security policy server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m   - No SSL/TLS support (no cert file)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m   - proxying from :5898 to localhost:5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:25,782] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:25,784] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:35:26 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 172.17.0.1::43068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:26,787] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:26,790] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 172.17.0.1::43068 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 0 rects, 0 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          0 B (1:-nan ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:27,228] init detected end of child process 60 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:27,792] Remote closed: address=localhost:15900\n",
      "[2018-05-08 23:35:27,793] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:27 [error] 68#68: *1 connect() failed (111: Connection refused) while connecting to upstream, client: 172.17.0.1, server: , request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:15901/\", host: \"127.0.0.1:10003\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 172.17.0.1 - openai [08/May/2018:21:35:27 +0000] \"GET / HTTP/1.1\" 502 182 \"-\" \"-\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:28,795] Using the golang VNC implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:28 [info] 68#68: *1 client 172.17.0.1 closed keepalive connection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:28,798] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'encoding': 'tight', 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "[2018-05-08 23:35:28,866] [0] Connecting to environment: vnc://localhost:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://localhost:15900/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:35:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 172.17.0.1::43086\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [reward_recorder] [2018-05-08 21:35:29,093] Listening on 0.0.0.0:15898\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [vnc_recorder] [2018-05-08 21:35:29,095] Listening on 0.0.0.0:5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:29,458] [0:localhost:5900] Waiting on rewarder: failed to complete WebSocket handshake. Retry in 1s (slept 0s/7s): connection was closed uncleanly (WebSocket connection upgrade failed (502 - BadGateway))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:29 [error] 68#68: *3 connect() failed (111: Connection refused) while connecting to upstream, client: 172.17.0.1, server: , request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:15901/\", host: \"localhost:15900\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 172.17.0.1 - openai [08/May/2018:21:35:29 +0000] \"GET / HTTP/1.1\" 502 182 \"-\" \"AutobahnPython/18.4.1\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:29 [info] 68#68: *3 client 172.17.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,537] [INFO:root] Starting play_controlplane.py with the following: command=['/app/universe-envs/controlplane/bin/controlplane.py', '--rewarder-port=15901'] args=Namespace(bot_demonstration=False, demonstration=False, env_id=None, idle_timeout=None, integrator_mode=False, no_env=False, no_rewarder=False, no_scorer=False, no_vexpect=False, remotes='vnc://127.0.0.1:5900', rewarder_fps=60, rewarder_port=15901, verbosity=0) env=environ({'DISPLAY': ':0', 'HOSTNAME': '880f794c67c3', 'USER': 'nobody', 'SUDO_UID': '0', 'SUDO_COMMAND': '/app/universe-envs/controlplane/bin/controlplane.py --rewarder-port=15901', 'USERNAME': 'nobody', 'TERM': 'xterm', 'SUDO_GID': '0', 'SHELL': '/usr/sbin/nologin', 'DBUS_SESSION_BUS_ADDRESS': '/dev/null', 'SUDO_USER': 'root', 'MAIL': '/var/mail/nobody', 'LOGNAME': 'nobody', 'HOME': '/nonexistent', 'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin'})\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,537] [INFO:root] [EnvStatus] Changing env_state: None (env_id=None) -> None (env_id=None) (episode_id: 0->0, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,537] [INFO:universe.rewarder.remote] Starting Rewarder on port=15901\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,540] [INFO:universe.extra.universe.wrappers.logger] Running VNC environments with Logger set to print_frequency=5. To change this, pass \"print_frequency=k\" or \"print_frequency=None\" to \"env.configure\".\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,541] [INFO:universe.remotes.hardcoded_addresses] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,541] [INFO:universe.envs.vnc_env] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,542] [INFO:universe.envs.vnc_env] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 9, 'fine_quality_level': 50, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,542] [INFO:universe.envs.vnc_env] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,587] [INFO:universe.envs.vnc_env] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,587] [INFO:universe.extra.universe.envs.vnc_env] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:35:29 I0508 21:35:29.587864 62 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,588] [INFO:root] [EnvStatus] Changing env_state: None (env_id=None) -> resetting (env_id=None) (episode_id: 0->1, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,588] [INFO:root] [MainThread] Env state: env_id=None episode_id=1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:35:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::56488\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,589] [INFO:root] [MainThread] Writing None to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:35:29 I0508 21:35:29.597885 62 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:29 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for none\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,624] [INFO:gym_flashgames.launcher] [MainThread] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,624] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:29,804] [selenium_wrapper_server] Calling webdriver.Chrome()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:30,402] Throttle fell behind by 1.50s; lost 89.86 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:30,468] [INFO:universe.rewarder.remote] Client connecting: peer=tcp4:127.0.0.1:60972 observer=False\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:30,469] [INFO:universe.rewarder.remote] WebSocket connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:39 [info] 68#68: *7 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:39 [info] 68#68: *8 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:44 [info] 68#68: *9 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:44,409] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 14.61s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:44,410] [INFO:gym_flashgames.launcher] [MainThread] Navigating browser to url=http://localhost\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:44,669] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=None) -> running (env_id=None) (episode_id: 1->1, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:44,671] [INFO:root] [MainThread] Writing None to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:44,675] [INFO:universe.wrappers.logger] Stats for the past 15.09s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=0.07\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m Manhole[1525815344.6777]: Patched <built-in function fork> and <built-in function fork>.\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m Manhole[1525815344.6780]: Manhole UDS path: /tmp/manhole-62\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m Manhole[1525815344.6781]: Waiting for new connection (in pid:62) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:45,473] Throttle fell behind by 1.00s; lost 60.06 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:49,673] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"247.85us\", \"mean\": \"343.13us\"}, \"rewarder.sleep\": {\"calls\": 300, \"std\": \"339.60us\", \"mean\": \"16.10ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"60.18us\", \"mean\": \"147.32us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"201.23us\", \"mean\": \"16.82ms\"}} counters={\"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.7711290998228358, \"mean\": 0.0730897009966778}} gauges={} (export_time=236.75us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:49,674] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<760 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:49,690] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=363361.6 vnc_pixels_ps[total]=528731.8 reward_lag=None rewarder_message_lag=None fps=60.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:50,481] [0:localhost:5900] ntpdate -q -p 8 localhost call timed out after 20.0s; killing the subprocess. This is ok, but you could have more accurate timings by enabling UDP port 123 traffic to your env. (Alternatively, you can try increasing the timeout by setting environment variable UNIVERSE_NTPDATE_TIMEOUT=10.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *12 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *13 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *14 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *15 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *16 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *17 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *18 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *19 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *20 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *21 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,506] [INFO:universe.rewarder.remote] CONNECTION STATUS: Marking connection as active: observer=False peer=tcp4:127.0.0.1:60972 total_conns=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:35:50,516] [0:localhost:5900] Sending reset for env_id=internet.SlitherIO-v0 fps=60 episode_id=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,518] [INFO:universe.rewarder.remote] Received reset message: {'method': 'v0.env.reset', 'headers': {'sent_at': 1525815350.5174723, 'message_id': 10, 'episode_id': '0'}, 'body': {'env_id': 'internet.SlitherIO-v0', 'seed': None, 'fps': 60}}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,585] [INFO:root] [EnvStatus] Changing env_state: running (env_id=None) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 1->2, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,586] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,589] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:50,623] init detected end of child process 118 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:50,631] init detected end of child process 133 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:50,635] init detected end of child process 339 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:50,637] init detected end of child process 360 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,637] [INFO:root] [EnvController] RESET CAUSE: changing out environments due to v0.env.reset (with episode_id=0): internet.SlitherIO-v0 -> internet.SlitherIO-v0 (new episode_id=2 fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,638] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:50,639] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:50 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *11 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:35:50 [info] 68#68: *10 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:50,914] Fetching files: git lfs pull -I git-lfs/internet.SlitherIO-v0.tar.gz\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:50,915] If this hangs, your docker container may not be able to communicate with Github\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:51,277] init detected end of child process 132 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:51,296] init detected end of child process 121 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:51,297] init detected end of child process 129 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:35:51,297] init detected end of child process 130 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,212] Finished running git lfs pull\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,212] git-lfs fetch succeeded\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,212] Unpacking files for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,276] Merged 4 files from /tmp/internet.SlitherIO-v0/public -> /app/universe-envs/flashgames/build/public/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,277] Merged 6 files from /tmp/internet.SlitherIO-v0/private -> /app/universe-envs/flashgames/build/private/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [unpack-lfs] [2018-05-08 21:35:58,277] Completed unpack for internet.SlitherIO-v0 in 7.381s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] [debug] unpack-lfs completed with status code: 0. Created completion file: /usr/local/openai/git-lfs/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:35:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:58,386] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:58,386] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:58,481] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:59,711] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:35:59,712] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:36:01 I0508 21:36:01.941705 62 gymvnc.go:374] [0:127.0.0.1:5900] update queue max of 60 reached; pausing further updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,028] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,563] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,564] [play_vexpect] Using the golang VNC implementation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:04,588] Throttle fell behind by 1.01s; lost 60.89 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,564] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,564] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,566] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:04,566] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:36:04 I0508 21:36:04.566522 772 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:36:04 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::56984\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:36:04 I0508 21:36:04.567888 772 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:05,132] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:05,614] Throttle fell behind by 1.01s; lost 60.51 frames\n",
      "[2018-05-08 23:36:06,670] Throttle fell behind by 1.04s; lost 62.33 frames\n",
      "[2018-05-08 23:36:07,716] Throttle fell behind by 1.03s; lost 61.68 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:07,883] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['364us', '200us', '178us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:07,884] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:07,885] [play_vexpect] vexpect macro complete in 3.284730s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:36:07 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::56984 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 31\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 24.952 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 3.30566 KiB (1:29.496 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 9 rects, 68.434 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  18.207 KiB (1:14.688 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 64 rects, 1.85139 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  5.29958 MiB (1:1.33279 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 81 rects, 1.94529 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          5.32073 MiB (1:1.39485 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:08,167] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 2->2, fps=60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:08,174] [0:localhost:5900] Initial reset complete: episode_id=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:08,168] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:08,169] [INFO:universe.rewarder.remote] Sending rewarder message: {'method': 'v0.reply.env.reset', 'body': {}, 'headers': {'sent_at': 1525815368.1696484, 'parent_message_id': 10, 'episode_id': '2', 'message_id': 15, 'parent_runtime': 17.65133500099182}}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:08,170] [INFO:root] [Rewarder] Changing reward_parsers: None -> internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:08,172] [INFO:root] [Rewarder] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:08,778] Throttle fell behind by 1.05s; lost 62.71 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 169, 136, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'env_status.reset.episode_id': '2', 'reward_buffer.local_time': 1525815368.1738863, 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1029603, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.gauges.diagnostics.lag.rewarder_message': array([0.60872133, 0.60963132]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'reward_buffer.remote_time': 1525815368.1696484, 'stats.vnc.updates.rectangles': 192, 'stats.vnc.updates.pixels': 9901931}], 'throttle.observation.available_at': 1525815368.7782433, 'throttle.action.available_at': 1525815368.7788827, 'stats.throttle.sleep': 0} \n",
      " count: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:09,952] Throttle fell behind by 1.07s; lost 64.35 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 269, 136, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.16990645, 0.17081645]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1053089, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 59, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 246, 'stats.vnc.updates.pixels': 9738489}], 'throttle.observation.available_at': 1525815369.951466, 'throttle.action.available_at': 1525815369.9528482, 'stats.throttle.sleep': 0} \n",
      " count: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:11,024] Throttle fell behind by 1.05s; lost 63.22 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 369, 136, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.17712934, 0.17803934]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1097303, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 250, 'stats.vnc.updates.pixels': 10073760}], 'throttle.observation.available_at': 1525815371.0236578, 'throttle.action.available_at': 1525815371.0241344, 'stats.throttle.sleep': 0} \n",
      " count: 0.0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,489] [INFO:gym_controlplane.registration] Loaded scorer: <gym_controlplane.reward.score.OCRScorerV0 object at 0x7fa224f4f9b0>\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,575] [INFO:gym_controlplane.registration] Created reward parser for internet.SlitherIO-v0: Reward<scorer=<gym_controlplane.reward.score.OCRScorerV0 object at 0x7fa224f4f9b0> vexpect=VExpect<{'ready1': <gym_controlplane.integration.transition.ClickTransition object at 0x7fa1f0118438>, 'ready0': <gym_controlplane.integration.transition.ClickTransition object at 0x7fa1f0118588>, 'ready2': <gym_controlplane.integration.transition.ClickTransition object at 0x7fa1f01185f8>}>>\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,575] [INFO:root] Using metadata_encoding={'x': 914, 'height': 100, 'type': 'qrcode', 'y': 658, 'width': 100} probe_key=96 subscription=[(79, 25, 482, 25), (47, 25, 481, 25), (96, 25, 480, 25), (62, 100, 730, 18), (914, 100, 658, 100)]\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,576] [INFO:universe.rewarder.remote] [Rewarder] Over past 21.90s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,576] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=0 episode_count=1 episode_duration=26.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,576] [INFO:universe.wrappers.logger] Stats for the past 21.89s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=2.47\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:36:11 I0508 21:36:11.578234 62 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,730] [INFO:universe.pyprofile] [pyprofile] period=22.06s timers={\"rewarder.sleep\": {\"calls\": 55, \"std\": \"216.98us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"152.11ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 3, \"std\": \"52.35us\", \"mean\": \"121.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 55, \"std\": \"43.50us\", \"mean\": \"132.52us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 3, \"std\": \"1.36us\", \"mean\": \"12.72us\"}, \"rewarder.compute_reward\": {\"calls\": 55, \"std\": \"20.69ms\", \"mean\": \"3.10ms\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 11, \"std\": \"565.57us\", \"mean\": \"1.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"771.52us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"151.79ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.68us\"}, \"rewarder.frame\": {\"calls\": 55, \"std\": \"40.85us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"control.env_id_change\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"control.env_id_change.internet.SlitherIO-v0\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 55, \"std\": 8.225238322051554, \"mean\": 1.1090909090909091}, \"rewarder_protocol.messages\": {\"calls\": 11, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.env.reset\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}} gauges={} (export_time=218.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,731] [INFO:root] [Rewarder] Rewarder fell behind by 3.5441815853118896s from target; losing 212 frames\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:11,752] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:12,096] Throttle fell behind by 1.05s; lost 63.22 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 469, 136, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [3.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 11767, 'reward_buffer.local_time': 1525815371.7538247, 'env_status.episode_id': '2', 'rewarder.vnc.updates.pixels': 13491, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.bytes': 1078089, 'rewarder.profile': {'timers': {'rewarder.sleep': {'mean': 0.016146222000000002, 'std': 0.0002169754, 'calls': 55, 'unit': 'seconds'}, 'rewarder.frame': {'mean': 0.0167850798, 'std': 4.08518e-05, 'calls': 55, 'unit': 'seconds'}, 'vnc_env.VNCEnv.vnc_session.step': {'mean': 0.0001325217, 'std': 4.3504e-05, 'calls': 55, 'unit': 'seconds'}, 'score.crop_cache.readthrough.OCRScorerV0': {'mean': 0.15178847310000002, 'std': 0, 'calls': 1, 'unit': 'seconds'}, 'reward.parsing.score': {'mean': 0.15210533140000002, 'std': 0, 'calls': 1, 'unit': 'seconds'}, 'score.crop_cache.get.MatchImage': {'mean': 1.2715700000000001e-05, 'std': 1.3557e-06, 'calls': 3, 'unit': 'seconds'}, 'score.crop_cache.readthrough.MatchImage': {'mean': 0.000121514, 'std': 5.2346e-05, 'calls': 3, 'unit': 'seconds'}, 'rewarder.compute_reward': {'mean': 0.0031038328000000002, 'std': 0.0206889327, 'calls': 55, 'unit': 'seconds'}, 'score.crop_cache.get.OCRScorerV0': {'mean': 6.6757e-06, 'std': 0, 'calls': 1, 'unit': 'seconds'}, 'rewarder_protocol.latency.rtt.skew_unadjusted': {'mean': 0.0011177496000000001, 'std': 0.0005655735, 'calls': 11, 'unit': 'seconds'}, 'reward.parsing.gameover': {'mean': 0.0007715225, 'std': 0, 'calls': 1, 'unit': 'seconds'}}, 'metadata': {'export_time': 0.00021839140000000002, 'period': 22.0569884777}, 'gauges': {}, 'counters': {'agent_conn.reward': {'mean': 0.0, 'unit': None, 'std': 0, 'total': 0, 'rate': 0, 'calls': 1}, 'control.env_id_change': {'mean': 1.0, 'unit': None, 'std': 0, 'total': 1, 'rate': 1, 'calls': 1}, 'rewarder_protocol.messages.v0.control.ping': {'mean': 1.0, 'unit': None, 'std': 0.0, 'total': 10, 'rate': 21.5266709064, 'calls': 10}, 'rewarder_protocol.messages.v0.env.reset': {'mean': 1.0, 'unit': None, 'std': 0, 'total': 1, 'rate': 1, 'calls': 1}, 'reward.vnc.updates.n': {'mean': 1.1090909091, 'unit': None, 'std': 8.2252383221, 'total': 61, 'rate': 2.9042258387, 'calls': 55}, 'control.env_id_change.internet.SlitherIO-v0': {'mean': 1.0, 'unit': None, 'std': 0, 'total': 1, 'rate': 1, 'calls': 1}, 'rewarder_protocol.messages': {'mean': 1.0, 'unit': None, 'std': 0.0, 'total': 11, 'rate': 23.6985546155, 'calls': 11}}}, 'stats.gauges.diagnostics.lag.rewarder_message': array([0.34366448, 0.34457448]), 'stats.gauges.diagnostics.lag.observation': array([0.16632087, 0.16723087]), 'stats.vnc.updates.n': 60, 'env_status.env_state': 'running', 'stats.reward.count': 2, 'stats.gauges.diagnostics.lag.action': None, 'reward_buffer.remote_time': 1525815371.7526844, 'stats.vnc.updates.rectangles': 246, 'stats.vnc.updates.pixels': 9916672}], 'throttle.observation.available_at': 1525815372.0962193, 'throttle.action.available_at': 1525815372.0968733, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:13,171] Throttle fell behind by 1.06s; lost 63.39 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 469, 236, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.1548825, 0.1557925]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1095384, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 250, 'stats.vnc.updates.pixels': 10047208}], 'throttle.observation.available_at': 1525815373.170139, 'throttle.action.available_at': 1525815373.171632, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:14,254] Throttle fell behind by 1.07s; lost 63.95 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 469, 336, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.14580233, 0.14671233]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1101350, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 250, 'stats.vnc.updates.pixels': 10073760}], 'throttle.observation.available_at': 1525815374.2533245, 'throttle.action.available_at': 1525815374.2548537, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:15,315] Throttle fell behind by 1.04s; lost 62.60 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 369, 336, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.14498765, 0.14589765]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1032268, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 58, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 238, 'stats.vnc.updates.pixels': 9561608}], 'throttle.observation.available_at': 1525815375.3145394, 'throttle.action.available_at': 1525815375.3157961, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:16,381] Throttle fell behind by 1.05s; lost 62.86 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 269, 336, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.12320263, 0.12411263]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1088129, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 252, 'stats.vnc.updates.pixels': 10080992}], 'throttle.observation.available_at': 1525815376.3796198, 'throttle.action.available_at': 1525815376.3809903, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:16,587] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=17.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=267073.5 vnc_pixels_ps[total]=462168.2 reward_lag=None rewarder_message_lag=None fps=58.29\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:16,736] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"939.03us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.85ms\", \"mean\": \"1.71ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"18.73ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"21.96us\", \"mean\": \"47.31us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.51ms\", \"mean\": \"475.84us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"2.50s\", \"mean\": \"1.77s\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 3, \"std\": \"20.78us\", \"mean\": \"61.99us\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"119.58us\", \"mean\": \"278.47us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.91us\", \"mean\": \"123.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"123.38us\", \"mean\": \"118.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"204.29ms\", \"mean\": \"28.56ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5999999999999999, \"value\": 13.0, \"mean\": 12.88}} (export_time=81.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:16,736] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.16s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2138 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:17,458] Throttle fell behind by 1.06s; lost 63.60 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 169, 336, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1346, 'reward_buffer.local_time': 1525815376.7381682, 'env_status.episode_id': '2', 'rewarder.vnc.updates.pixels': 10000, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.bytes': 1086337, 'rewarder.profile': {'timers': {'score.crop_cache.readthrough.MatchImage': {'mean': 6.19888e-05, 'std': 2.07848e-05, 'calls': 3, 'unit': 'seconds'}, 'rewarder.sleep': {'mean': 0.0160769762, 'std': 0.0009390349, 'calls': 299, 'unit': 'seconds'}, 'rewarder.frame': {'mean': 0.028560182200000003, 'std': 0.2042877744, 'calls': 301, 'unit': 'seconds'}, 'vnc_env.VNCEnv.vnc_session.step': {'mean': 0.0001230723, 'std': 4.79136e-05, 'calls': 301, 'unit': 'seconds'}, 'score.crop_cache.readthrough.OCRScorerV0': {'mean': 0.018730402, 'std': 0, 'calls': 1, 'unit': 'seconds'}, 'reward.parsing.score': {'mean': 0.0017085075000000001, 'std': 0.0048516745, 'calls': 25, 'unit': 'seconds'}, 'rewarder.sleep.missed': {'mean': 1.7742906809, 'std': 2.503003721, 'calls': 2, 'unit': 'seconds'}, 'rewarder.compute_reward': {'mean': 0.00047583520000000004, 'std': 0.0015076595000000001, 'calls': 301, 'unit': 'seconds'}, 'score.crop_cache.get.OCRScorerV0': {'mean': 0.00011828420000000001, 'std': 0.000123385, 'calls': 25, 'unit': 'seconds'}, 'score.crop_cache.get.MatchImage': {'mean': 4.73118e-05, 'std': 2.19576e-05, 'calls': 75, 'unit': 'seconds'}, 'reward.parsing.gameover': {'mean': 0.0002784729, 'std': 0.0001195805, 'calls': 25, 'unit': 'seconds'}}, 'metadata': {'export_time': 8.10623e-05, 'period': 5.0061354637}, 'gauges': {'reward_parser.score.last_score': {'mean': 12.88, 'std': 0.6000000000000001, 'calls': 25, 'value': 13.0, 'unit': None}}, 'counters': {'agent_conn.reward': {'mean': 1.5, 'unit': None, 'std': 2.1213203436, 'total': 3, 'rate': 6.7412452446, 'calls': 2}, 'reward.vnc.updates.n': {'mean': 0.08305647840000001, 'unit': None, 'std': 0.27642713350000003, 'total': 25, 'rate': 5.8639167631, 'calls': 301}, 'score.crop_cache.hit.MatchImage': {'mean': 1.0, 'unit': None, 'std': 0.0, 'total': 72, 'rate': 16.6907353256, 'calls': 72}, 'score.crop_cache.hit.OCRScorerV0': {'mean': 1.0, 'unit': None, 'std': 0.0, 'total': 24, 'rate': 4.7327022825, 'calls': 24}}}, 'stats.gauges.diagnostics.lag.rewarder_message': array([0.72041614, 0.72132614]), 'stats.gauges.diagnostics.lag.observation': array([0.10528309, 0.10619309]), 'stats.vnc.updates.n': 60, 'env_status.env_state': 'running', 'stats.reward.count': 1, 'stats.gauges.diagnostics.lag.action': None, 'reward_buffer.remote_time': 1525815376.7370522, 'stats.vnc.updates.rectangles': 245, 'stats.vnc.updates.pixels': 9893064}], 'throttle.observation.available_at': 1525815377.457357, 'throttle.action.available_at': 1525815377.4588835, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:18,531] Throttle fell behind by 1.06s; lost 63.33 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 69, 336, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.31702001, 0.31793001]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1091701, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 60, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 246, 'stats.vnc.updates.pixels': 9873168}], 'throttle.observation.available_at': 1525815378.5314107, 'throttle.action.available_at': 1525815378.5319614, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 23:36:19,601] Throttle fell behind by 1.05s; lost 63.07 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [('PointerEvent', 69, 236, 0)] \n",
      " observation: [{'text': [], 'vision': array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)}] \n",
      " reward: [0.0] \n",
      " done_n: [False] \n",
      " info: {'n': [{'stats.gauges.diagnostics.lag.observation': array([0.29107387, 0.29198387]), 'env_status.episode_id': '2', 'stats.vnc.updates.bytes': 1114566, 'stats.gauges.diagnostics.clock_skew': array([-0.00057318,  0.00033681]), 'stats.vnc.updates.n': 61, 'env_status.env_state': 'running', 'stats.reward.count': 0, 'stats.gauges.diagnostics.lag.action': None, 'stats.vnc.updates.rectangles': 250, 'stats.vnc.updates.pixels': 10064032}], 'throttle.observation.available_at': 1525815379.6011598, 'throttle.action.available_at': 1525815379.6017466, 'stats.throttle.sleep': 0} \n",
      " count: 3.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-22b684ef9bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n observation:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n reward:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n done_n:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n info:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n count:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:21,603] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6204.1 vnc_pixels_ps[total]=46029.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:21,753] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"221.97us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"130.81us\", \"mean\": \"318.55us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.02us\", \"mean\": \"43.80us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"203.73us\", \"mean\": \"323.05us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"117.40us\", \"mean\": \"250.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.84us\", \"mean\": \"112.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"39.29us\", \"mean\": \"95.43us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.59us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=255.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:21,754] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:26,620] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.0 vnc_pixels_ps[total]=44016.2 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:26,769] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"271.03us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"97.23us\", \"mean\": \"355.66us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.35us\", \"mean\": \"51.38us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"230.65us\", \"mean\": \"345.14us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"103.94us\", \"mean\": \"291.93us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.10us\", \"mean\": \"118.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.11us\", \"mean\": \"103.00us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"79.00us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=124.45us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:26,769] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:31,070] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.30s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:31,637] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7609.4 vnc_pixels_ps[total]=44807.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:31,770] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.15ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.59ms\", \"mean\": \"1.44ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"18.89us\", \"mean\": \"61.20us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.15ms\", \"mean\": \"476.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.27ms\", \"mean\": \"12.84ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"90.60us\", \"mean\": \"344.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"47.94us\", \"mean\": \"126.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"22.67us\", \"mean\": \"117.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"24.31us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27684719634237037, \"mean\": 0.08333333333333333}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5000000000000001, \"value\": 15.0, \"mean\": 13.999999999999998}} (export_time=238.66us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:32,153] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:35,636] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:36,653] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7621.1 vnc_pixels_ps[total]=44894.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:36,774] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"559.48us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.86ms\", \"mean\": \"925.72us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"15.99us\", \"mean\": \"36.29us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"632.77us\", \"mean\": \"336.90us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"750.05us\", \"mean\": \"5.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"77.91us\", \"mean\": \"203.70us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.45us\", \"mean\": \"103.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.35us\", \"mean\": \"75.63us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"22.04us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28181605677298177, \"mean\": 0.08666666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.9774377808252633, \"value\": 18.0, \"mean\": 16.346153846153843}} (export_time=84.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:36,775] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.14s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1912 bytes>', 'rewarder.vnc.updates.pixels': 1368}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:37,803] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:41,670] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7598.8 vnc_pixels_ps[total]=44726.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:41,786] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"666.43us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.74ms\", \"mean\": \"715.60us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"24.67us\", \"mean\": \"53.68us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"571.17us\", \"mean\": \"369.22us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.58ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"122.92us\", \"mean\": \"302.31us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.52us\", \"mean\": \"108.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.78us\", \"mean\": \"98.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.68us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.6370220572706055, \"value\": 20.0, \"mean\": 19.666666666666668}} (export_time=127.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:41,786] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.98s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:43,453] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:46,686] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9262.2 vnc_pixels_ps[total]=45274.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:46,802] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.55ms\", \"mean\": \"15.96ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.65ms\", \"mean\": \"2.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"24.38us\", \"mean\": \"54.54us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.55ms\", \"mean\": \"510.02us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.85ms\", \"mean\": \"12.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"119.39us\", \"mean\": \"305.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.20us\", \"mean\": \"112.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"29.87us\", \"mean\": \"100.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.89us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0954451150103324, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.6535897312015795, \"value\": 26.0, \"mean\": 23.19230769230769}} (export_time=112.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:46,803] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.35s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1916 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:48,419] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.62s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:49,503] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:51,703] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7835.9 vnc_pixels_ps[total]=46479.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:51,805] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.13ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.17ms\", \"mean\": \"1.20ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.74us\", \"mean\": \"45.99us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.02ms\", \"mean\": \"400.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.58ms\", \"mean\": \"10.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"94.40us\", \"mean\": \"256.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"123.03us\", \"mean\": \"118.88us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.09us\", \"mean\": \"90.53us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"340.37us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423705, \"mean\": 0.08333333333333331}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.8888194417315561, \"value\": 28.0, \"mean\": 27.040000000000006}} (export_time=270.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:51,805] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.30s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:56,720] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.4 vnc_pixels_ps[total]=44180.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:56,819] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"270.05us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"128.69us\", \"mean\": \"296.34us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.82us\", \"mean\": \"38.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"184.88us\", \"mean\": \"280.03us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"84.71us\", \"mean\": \"216.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.13us\", \"mean\": \"96.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.76us\", \"mean\": \"84.43us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.45us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=220.54us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:36:56,820] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:01,737] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5964.7 vnc_pixels_ps[total]=44169.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:01,836] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"259.70us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"148.19us\", \"mean\": \"339.51us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.38us\", \"mean\": \"45.20us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"229.48us\", \"mean\": \"338.81us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"108.81us\", \"mean\": \"256.35us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.27us\", \"mean\": \"114.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"90.35us\", \"mean\": \"108.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"34.54us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=226.26us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:01,837] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:02,937] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:05,986] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.05s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:06,753] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9251.8 vnc_pixels_ps[total]=45194.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:06,836] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"919.71us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.70ms\", \"mean\": \"1.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.48us\", \"mean\": \"41.86us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"910.89us\", \"mean\": \"411.64us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.48ms\", \"mean\": \"7.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"118.68us\", \"mean\": \"235.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.33us\", \"mean\": \"108.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"51.06us\", \"mean\": \"87.96us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"35.49us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.1401754250991378, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28181605677298177, \"mean\": 0.08666666666666671}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.021423717619304, \"value\": 33.0, \"mean\": 30.615384615384613}} (export_time=240.56us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:07,286] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:09,019] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:11,769] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8454.1 vnc_pixels_ps[total]=45156.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:11,836] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"858.28us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.55ms\", \"mean\": \"1.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"25.15us\", \"mean\": \"49.68us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"853.91us\", \"mean\": \"415.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.68ms\", \"mean\": \"7.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"125.94us\", \"mean\": \"277.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"42.36us\", \"mean\": \"110.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"33.88us\", \"mean\": \"92.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"25.77us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.5, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28181605677298177, \"mean\": 0.08666666666666668}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.5176301433017416, \"value\": 42.0, \"mean\": 40.46153846153847}} (export_time=127.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:11,837] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1909 bytes>', 'rewarder.vnc.updates.pixels': 10000}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:16,786] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5995.8 vnc_pixels_ps[total]=44498.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:16,852] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"218.35us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"94.60us\", \"mean\": \"304.37us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.09us\", \"mean\": \"42.88us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"195.68us\", \"mean\": \"318.32us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"95.55us\", \"mean\": \"242.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.33us\", \"mean\": \"108.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.73us\", \"mean\": \"89.03us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"34.66us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 42.0, \"mean\": 42.0}} (export_time=106.33us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:16,853] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1728 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:19,003] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:21,802] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7671.8 vnc_pixels_ps[total]=45286.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:21,852] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"520.41us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.54ms\", \"mean\": \"707.45us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.36us\", \"mean\": \"34.51us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"513.86us\", \"mean\": \"313.39us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"37.59us\", \"mean\": \"5.55ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"87.30us\", \"mean\": \"198.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.20us\", \"mean\": \"99.52us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.27us\", \"mean\": \"75.65us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"24.83us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.0833333333333333}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5066228051190228, \"value\": 43.0, \"mean\": 42.559999999999995}} (export_time=123.98us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:21,853] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.85s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:26,819] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7034.4 vnc_pixels_ps[total]=46293.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:26,853] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"391.09us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.18ms\", \"mean\": \"471.78us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"12.44us\", \"mean\": \"30.77us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"382.31us\", \"mean\": \"253.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.72ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"41.34us\", \"mean\": \"172.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"32.48us\", \"mean\": \"83.95us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.13us\", \"mean\": \"70.35us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"67.29us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.271746488194703, \"mean\": 0.08000000000000003}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9315329426211484, \"value\": 46.0, \"mean\": 45.54166666666666}} (export_time=173.09us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:26,853] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1888 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:31,837] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.4 vnc_pixels_ps[total]=44018.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:31,853] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"287.75us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"64.57us\", \"mean\": \"347.67us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"13.02us\", \"mean\": \"48.88us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"207.85us\", \"mean\": \"342.07us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"58.68us\", \"mean\": \"278.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.23us\", \"mean\": \"115.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.90us\", \"mean\": \"104.86us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"196.22us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2665063620734803, \"mean\": 0.07666666666666666}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 46.0, \"mean\": 46.0}} (export_time=217.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:31,853] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:33,519] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:36,853] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6818.4 vnc_pixels_ps[total]=44774.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:36,854] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"811.41us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.59ms\", \"mean\": \"939.17us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.23us\", \"mean\": \"59.43us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"813.05us\", \"mean\": \"418.19us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.62ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"70.46us\", \"mean\": \"334.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.27us\", \"mean\": \"121.57us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"20.08us\", \"mean\": \"119.04us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"27.92us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470293, \"mean\": 0.08}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4945353550468414, \"value\": 47.0, \"mean\": 46.62499999999999}} (export_time=229.12us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:36,855] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.34s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1891 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:41,120] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.26s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:41,870] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6818.5 vnc_pixels_ps[total]=44774.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:41,871] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"673.70us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.04ms\", \"mean\": \"792.97us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.90us\", \"mean\": \"55.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"653.74us\", \"mean\": \"404.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.94ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"94.75us\", \"mean\": \"310.30us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.87us\", \"mean\": \"124.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.93us\", \"mean\": \"110.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.84us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.675663924692175, \"value\": 49.0, \"mean\": 47.25000000000001}} (export_time=302.31us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:42,420] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:43,720] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:46,886] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9234.2 vnc_pixels_ps[total]=45198.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:46,886] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.54ms\", \"mean\": \"15.96ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.46ms\", \"mean\": \"2.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"22.78us\", \"mean\": \"53.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.52ms\", \"mean\": \"502.87us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.14ms\", \"mean\": \"12.13ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"113.43us\", \"mean\": \"300.06us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.73us\", \"mean\": \"112.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"27.57us\", \"mean\": \"97.80us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.77us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.6974716451435157, \"value\": 56.0, \"mean\": 53.25925925925927}} (export_time=164.27us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:46,887] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.17s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,886] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=311us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,886] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,887] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,887] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,887] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,888] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 2->3, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,888] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,888] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,888] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=3\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,888] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,889] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:48,903] init detected end of child process 490 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:48,907] init detected end of child process 505 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:48,907] init detected end of child process 711 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:48,921] init detected end of child process 731 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:37:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:37:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:37:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,958] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:48,958] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:49,044] [selenium_wrapper_server] Calling webdriver.Chrome()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:49,297] init detected end of child process 493 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:49,297] init detected end of child process 501 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:49,297] init detected end of child process 502 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:37:49,298] init detected end of child process 504 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:50,272] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:50,272] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:50,742] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,238] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,238] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,238] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,239] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,247] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,247] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:37:51 I0508 21:37:51.247964 1299 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:37:51 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::57608\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:37:51 I0508 21:37:51.249352 1299 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:51,365] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:55,399] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:55,932] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['147us', '72us', '60us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:55,932] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:55,933] [play_vexpect] vexpect macro complete in 4.651102s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:37:56 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::57608 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 3 rects, 389 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            90 B (1:17.6889 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 131.072 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.2695 KiB (1:31.4713 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 330.306 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.24 KiB (1:9.68493 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 24 rects, 789.447 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08394 MiB (1:2.77855 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,134] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 3->3, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,134] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,134] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=2->3, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,137] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.25s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,138] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=46.0 episode_count=50 episode_duration=104.56\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,139] [INFO:universe.wrappers.logger] Stats for the past 9.25s: vnc_updates_ps=1.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1790.2 vnc_pixels_ps[total]=9564.5 reward_lag=None rewarder_message_lag=None fps=13.08\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,148] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:56,148] [INFO:universe.pyprofile] [pyprofile] period=9.26s timers={\"rewarder.sleep\": {\"calls\": 120, \"std\": \"168.25us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 11, \"std\": \"2.56ms\", \"mean\": \"991.54us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.54ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 33, \"std\": \"8.39us\", \"mean\": \"23.83us\"}, \"rewarder.compute_reward\": {\"calls\": 121, \"std\": \"922.22us\", \"mean\": \"319.36us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.67us\", \"mean\": \"41.88us\"}, \"reward.parsing.gameover\": {\"calls\": 11, \"std\": \"118.42us\", \"mean\": \"192.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 121, \"std\": \"41.44us\", \"mean\": \"86.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 11, \"std\": \"24.02us\", \"mean\": \"61.58us\"}, \"rewarder.frame\": {\"calls\": 121, \"std\": \"1.28ms\", \"mean\": \"16.66ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 121, \"std\": 1.6520710768532954, \"mean\": 0.2314049586776859}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 27, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 11, \"std\": 13.869521850577128, \"value\": 10, \"mean\": 51.81818181818182}} (export_time=114.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:57,652] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.51s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2088 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:37:59,385] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:01,152] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=8.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16083.5 vnc_pixels_ps[total]=76983.0 reward_lag=None rewarder_message_lag=None fps=60.05\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:01,152] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.95ms\", \"mean\": \"1.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.44us\", \"mean\": \"34.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"961.75us\", \"mean\": \"329.98us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.10ms\", \"mean\": \"8.21ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"101.58us\", \"mean\": \"197.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.66us\", \"mean\": \"91.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"23.38us\", \"mean\": \"72.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"39.08us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.235723940575299, \"value\": 16.0, \"mean\": 11.96153846153846}} (export_time=140.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:01,152] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.77s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:05,019] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.87s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:06,169] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6639.9 vnc_pixels_ps[total]=43244.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:06,176] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"378.73us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.71ms\", \"mean\": \"731.16us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"14.17us\", \"mean\": \"30.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"576.86us\", \"mean\": \"281.03us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"811.41us\", \"mean\": \"6.15ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"70.80us\", \"mean\": \"171.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.29us\", \"mean\": \"88.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"23.30us\", \"mean\": \"65.86us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"34.94us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531566}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.3076696830622025, \"value\": 19.0, \"mean\": 16.72}} (export_time=90.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:06,176] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.16s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1925 bytes>', 'rewarder.vnc.updates.pixels': 1368}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:08,502] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.33s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,969] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=362us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,969] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,969] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.47s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,969] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 3->4, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=4\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,970] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:10,971] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:10,988] init detected end of child process 1048 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:10,994] init detected end of child process 1063 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:10,998] init detected end of child process 1265 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:10,998] init detected end of child process 1272 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:11,013] init detected end of child process 1297 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:11,052] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:11,052] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:11 [info] 68#68: *25 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:11 [info] 68#68: *26 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:11 [info] 68#68: *27 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:11 [info] 68#68: *24 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:11,143] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:11,357] init detected end of child process 1051 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:11,357] init detected end of child process 1059 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:11,357] init detected end of child process 1060 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:11,357] init detected end of child process 1062 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,406] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,407] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,467] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,957] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,957] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,957] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2, 'compress_level': 0, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,957] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,963] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:12,963] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:38:12 I0508 21:38:12.963872 1677 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:38:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::57760\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:38:12 I0508 21:38:12.965479 1677 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:13,091] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,157] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,758] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['270us', '143us', '126us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,759] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,759] [play_vexpect] vexpect macro complete in 4.761667s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:38:17 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::57760 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.682 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.448 KiB (1:10.3434 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09184 MiB (1:2.75759 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,949] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 4->4, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,949] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,949] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=3->4, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,950] [INFO:universe.rewarder.remote] [Rewarder] Over past 6.98s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,950] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=14.0 episode_count=11 episode_duration=21.81\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,951] [INFO:universe.wrappers.logger] Stats for the past 11.78s: vnc_updates_ps=2.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=3758.4 vnc_pixels_ps[total]=17500.2 reward_lag=None rewarder_message_lag=None fps=24.53\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,961] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:17,961] [INFO:universe.pyprofile] [pyprofile] period=11.79s timers={\"rewarder.sleep\": {\"calls\": 288, \"std\": \"772.20us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.51ms\", \"mean\": \"1.10ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.97ms\", \"mean\": \"7.29ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"12.24us\", \"mean\": \"26.27us\"}, \"rewarder.compute_reward\": {\"calls\": 289, \"std\": \"881.24us\", \"mean\": \"310.70us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.00us\", \"mean\": \"47.76us\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"115.68us\", \"mean\": \"181.62us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 289, \"std\": \"40.01us\", \"mean\": \"90.79us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"19.36us\", \"mean\": \"60.16us\"}, \"rewarder.frame\": {\"calls\": 289, \"std\": \"863.69us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 5, \"std\": 1.224744871391589, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 289, \"std\": 1.2610526351260074, \"mean\": 0.15570934256055363}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.85014619508076, \"value\": 10, \"mean\": 22.04}} (export_time=124.22us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:19,250] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2153 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:22,500] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.25s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:22,968] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16814.9 vnc_pixels_ps[total]=82479.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:22,968] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.08ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.59ms\", \"mean\": \"1.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.14us\", \"mean\": \"41.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"853.17us\", \"mean\": \"392.12us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.85ms\", \"mean\": \"7.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"99.47us\", \"mean\": \"235.76us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.49us\", \"mean\": \"116.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"31.44us\", \"mean\": \"87.88us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.87us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662217, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.2253727847224551, \"value\": 14.0, \"mean\": 11.69230769230769}} (export_time=202.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:24,034] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1930 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,768] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=526us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,768] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,768] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.73s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,769] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,769] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,769] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 4->5, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,770] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,770] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,771] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=5\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,772] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,772] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:26,791] init detected end of child process 1426 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:26,799] init detected end of child process 1441 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:26,801] init detected end of child process 1643 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:26,802] init detected end of child process 1650 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:26,818] init detected end of child process 1675 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:38:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,853] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,854] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:26 [info] 68#68: *29 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:26 [info] 68#68: *30 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:26 [info] 68#68: *31 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:38:26 [info] 68#68: *28 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:26,939] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:27,197] init detected end of child process 1429 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:27,197] init detected end of child process 1437 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:27,197] init detected end of child process 1438 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:38:27,197] init detected end of child process 1440 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:28,188] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:28,188] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:31,547] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,043] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,043] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,043] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'encoding': 'zrle', 'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,043] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,047] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:38:32 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::57930\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,049] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:38:32 I0508 21:38:32.049531 2063 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:38:32 I0508 21:38:32.05678 2063 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:32,177] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,478] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['153us', '64us', '57us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,478] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,478] [play_vexpect] vexpect macro complete in 2.395056s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:38:34 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::57930 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9209 KiB (1:15.7337 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 998.4 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.85778 MiB (1:1.33283 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 44 rects, 1.09468 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.87987 MiB (1:1.4502 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,733] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 5->5, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,733] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,734] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=4->5, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,734] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.97s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,734] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=7.0 episode_count=7 episode_duration=16.78\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,735] [INFO:universe.wrappers.logger] Stats for the past 11.77s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2660.0 vnc_pixels_ps[total]=14333.8 reward_lag=None rewarder_message_lag=None fps=19.46\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,745] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:34,745] [INFO:universe.pyprofile] [pyprofile] period=11.78s timers={\"rewarder.sleep\": {\"calls\": 228, \"std\": \"786.90us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 20, \"std\": \"3.04ms\", \"mean\": \"1.27ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.09ms\", \"mean\": \"9.85ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 60, \"std\": \"15.51us\", \"mean\": \"36.59us\"}, \"rewarder.compute_reward\": {\"calls\": 229, \"std\": \"1.05ms\", \"mean\": \"398.79us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"29.12us\", \"mean\": \"55.75us\"}, \"reward.parsing.gameover\": {\"calls\": 20, \"std\": \"153.68us\", \"mean\": \"250.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 229, \"std\": \"44.95us\", \"mean\": \"110.90us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 20, \"std\": \"25.88us\", \"mean\": \"80.81us\"}, \"rewarder.frame\": {\"calls\": 229, \"std\": \"864.69us\", \"mean\": \"16.73ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 229, \"std\": 1.4744302923655372, \"mean\": 0.17903930131004367}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 20, \"std\": 1.650358812660543, \"value\": 10, \"mean\": 16.250000000000004}} (export_time=136.14us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:35,918] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.18s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2152 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:39,751] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17491.3 vnc_pixels_ps[total]=86222.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:39,751] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"850.38us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.65ms\", \"mean\": \"694.07us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"12.14us\", \"mean\": \"28.85us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"525.27us\", \"mean\": \"289.19us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"112.11us\", \"mean\": \"5.95ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"63.05us\", \"mean\": \"165.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.54us\", \"mean\": \"95.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"19.13us\", \"mean\": \"66.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.55us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.8793937305515277, \"value\": 12.0, \"mean\": 11.240000000000002}} (export_time=125.89us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:39,752] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.83s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:43,318] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.57s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:44,768] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7614.4 vnc_pixels_ps[total]=44708.7 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:44,769] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"583.42us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.80ms\", \"mean\": \"805.44us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.61us\", \"mean\": \"38.30us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"578.74us\", \"mean\": \"308.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"242.43us\", \"mean\": \"6.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"87.57us\", \"mean\": \"213.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.64us\", \"mean\": \"95.10us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.24us\", \"mean\": \"75.74us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.98us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.151844507070317, \"value\": 18.0, \"mean\": 13.25}} (export_time=189.07us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:44,770] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1911 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:49,785] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.1 vnc_pixels_ps[total]=44024.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:49,785] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"245.70us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"84.55us\", \"mean\": \"263.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.03us\", \"mean\": \"36.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"172.58us\", \"mean\": \"246.87us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"92.50us\", \"mean\": \"210.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.72us\", \"mean\": \"91.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.80us\", \"mean\": \"76.62us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"33.54us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 18.0, \"mean\": 18.0}} (export_time=122.07us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:49,785] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1710 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:50,918] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.13s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:53,085] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:54,401] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 3 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:54,801] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10093.1 vnc_pixels_ps[total]=45677.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:54,802] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"745.59us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.07ms\", \"mean\": \"1.17ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"9.97us\", \"mean\": \"29.61us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"737.88us\", \"mean\": \"324.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"370.92us\", \"mean\": \"5.29ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"40.54us\", \"mean\": \"166.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"35.41us\", \"mean\": \"88.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"19.63us\", \"mean\": \"64.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.19us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.7606816861659007, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006217, \"mean\": 0.09302325581395345}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 3.059160932096513, \"value\": 27.0, \"mean\": 20.392857142857142}} (export_time=129.70us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:55,590] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.19s, sent 2 reward messages to agent: reward=11.0 reward_min=0 reward_max=11.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:57,101] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.51s, sent 4 reward messages to agent: reward=36.0 reward_min=1.0 reward_max=17.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:58,207] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.11s, sent 4 reward messages to agent: reward=59.0 reward_min=12.0 reward_max=16.0 done=False info={'rewarder.vnc.updates.bytes': 4664, 'rewarder.vnc.updates.pixels': 1548, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:59,401] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.19s, sent 4 reward messages to agent: reward=38.0 reward_min=2.0 reward_max=16.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:59,818] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=6.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16379.2 vnc_pixels_ps[total]=45733.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:38:59,818] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.18ms\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 33, \"std\": \"2.62ms\", \"mean\": \"2.31ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 99, \"std\": \"9.56us\", \"mean\": \"28.70us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"477.41us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 13, \"std\": \"164.57us\", \"mean\": \"5.25ms\"}, \"reward.parsing.gameover\": {\"calls\": 33, \"std\": \"30.93us\", \"mean\": \"162.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.24us\", \"mean\": \"96.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 33, \"std\": \"19.63us\", \"mean\": \"64.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.19us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 14, \"std\": 6.8098183803700945, \"mean\": 10.285714285714286}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.31295398916701517, \"mean\": 0.10963455149501658}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 99, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 20, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 33, \"std\": 47.853133110433305, \"value\": 171.0, \"mean\": 90.78787878787878}} (export_time=136.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:00,501] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 3 reward messages to agent: reward=26.0 reward_min=0 reward_max=17.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:02,606] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.10s, sent 4 reward messages to agent: reward=49.0 reward_min=1.0 reward_max=17.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:03,651] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.04s, sent 3 reward messages to agent: reward=29.0 reward_min=2.0 reward_max=18.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:04,834] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=6.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=13994.1 vnc_pixels_ps[total]=46339.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:04,835] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.03ms\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 31, \"std\": \"2.50ms\", \"mean\": \"1.91ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 93, \"std\": \"8.61us\", \"mean\": \"25.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"414.99us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 10, \"std\": \"248.65us\", \"mean\": \"5.25ms\"}, \"reward.parsing.gameover\": {\"calls\": 31, \"std\": \"24.59us\", \"mean\": \"145.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.18us\", \"mean\": \"94.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 31, \"std\": \"21.27us\", \"mean\": \"60.95us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.84us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 11, \"std\": 7.297571202430673, \"mean\": 9.636363636363637}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.30445201576000813, \"mean\": 0.10299003322259134}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 93, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 31, \"std\": 38.7783611092911, \"value\": 277.0, \"mean\": 234.1935483870968}} (export_time=124.45us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:04,835] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.18s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1941 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,584] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=246us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,584] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 5->6, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,585] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,586] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,586] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,602] init detected end of child process 1792 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,606] init detected end of child process 1807 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,607] init detected end of child process 2009 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,610] init detected end of child process 2016 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,625] init detected end of child process 2038 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:06 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:06 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:06 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,665] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,665] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:06,748] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:06 [info] 68#68: *33 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:06 [info] 68#68: *34 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:06 [info] 68#68: *35 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:06 [info] 68#68: *32 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,933] init detected end of child process 1795 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,933] init detected end of child process 1803 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,933] init detected end of child process 1804 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:06,933] init detected end of child process 1806 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:08,015] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:08,016] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:11,646] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,130] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,130] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,131] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,131] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,137] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,137] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:39:12 I0508 21:39:12.137768 2431 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:39:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58114\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:39:12 I0508 21:39:12.144995 2431 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:12,267] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,350] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['211us', '99us', '87us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,351] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,351] [play_vexpect] vexpect macro complete in 2.180006s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:39:14 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58114 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 16 rects, 901.12 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.57912 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 981.015 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.5982 MiB (1:1.44046 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,620] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 6->6, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,621] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,621] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=5->6, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,621] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.04s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,622] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=267.0 episode_count=40 episode_duration=39.89\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,623] [INFO:universe.wrappers.logger] Stats for the past 9.79s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1581.3 vnc_pixels_ps[total]=8223.7 reward_lag=None rewarder_message_lag=None fps=10.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,631] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:14,631] [INFO:universe.pyprofile] [pyprofile] period=9.80s timers={\"rewarder.sleep\": {\"calls\": 105, \"std\": \"179.19us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 9, \"std\": \"2.40ms\", \"mean\": \"999.56us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.24ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 27, \"std\": \"12.32us\", \"mean\": \"22.75us\"}, \"rewarder.compute_reward\": {\"calls\": 106, \"std\": \"839.54us\", \"mean\": \"305.50us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"14.00us\", \"mean\": \"35.76us\"}, \"reward.parsing.gameover\": {\"calls\": 9, \"std\": \"91.49us\", \"mean\": \"180.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 106, \"std\": \"42.87us\", \"mean\": \"88.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 9, \"std\": \"19.15us\", \"mean\": \"52.98us\"}, \"rewarder.frame\": {\"calls\": 106, \"std\": \"1.50ms\", \"mean\": \"16.61ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 106, \"std\": 2.14589183138889, \"mean\": 0.2830188679245283}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 8, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 9, \"std\": 89.0, \"value\": 10, \"mean\": 247.33333333333334}} (export_time=107.77us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:15,989] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2076 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:18 [info] 68#68: *37 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:18 [info] 68#68: *38 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:18 [info] 68#68: *39 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:19,639] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16523.4 vnc_pixels_ps[total]=85017.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:19,640] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"703.92us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.24ms\", \"mean\": \"595.45us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"27.53us\", \"mean\": \"50.58us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"437.18us\", \"mean\": \"385.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.13ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"138.97us\", \"mean\": \"283.69us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.01us\", \"mean\": \"124.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"32.74us\", \"mean\": \"100.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.53us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.48154341234307785, \"value\": 11.0, \"mean\": 10.666666666666664}} (export_time=251.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:19,641] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.65s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:22,089] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.45s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:24,656] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6787.6 vnc_pixels_ps[total]=44537.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:24,657] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"801.52us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.44ms\", \"mean\": \"890.56us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.93us\", \"mean\": \"58.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"778.42us\", \"mean\": \"398.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.92ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"114.12us\", \"mean\": \"328.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.14us\", \"mean\": \"118.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"34.27us\", \"mean\": \"114.50us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.02us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0179547554081034, \"value\": 13.0, \"mean\": 11.916666666666666}} (export_time=263.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:24,658] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.57s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=244us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.68s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,339] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 6->7, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,340] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,340] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,340] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,340] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,341] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,353] init detected end of child process 2162 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,357] init detected end of child process 2177 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,358] init detected end of child process 2379 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,359] init detected end of child process 2384 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,375] init detected end of child process 2406 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:39:26 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,415] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,415] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:39:26 [info] 68#68: *36 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:26,506] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,717] init detected end of child process 2165 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,717] init detected end of child process 2173 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,717] init detected end of child process 2174 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:39:26,718] init detected end of child process 2176 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:27,739] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:27,740] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,034] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,519] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,519] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,519] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,519] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,521] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,521] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:39:31 I0508 21:39:31.521931 2805 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:39:31 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58258\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:39:31 I0508 21:39:31.523427 2805 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:31,647] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:34,998] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['206us', '112us', '97us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:34,998] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:34,998] [play_vexpect] vexpect macro complete in 3.443131s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:39:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58258 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9209 KiB (1:15.7337 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 27 rects, 961.536 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.75224 MiB (1:1.33283 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 41 rects, 1.04637 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.77287 MiB (1:1.43968 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,205] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 7->7, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,205] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,206] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=6->7, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,206] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.87s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,207] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=3.0 episode_count=6 episode_duration=20.58\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,207] [INFO:universe.wrappers.logger] Stats for the past 10.55s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1437.8 vnc_pixels_ps[total]=7361.3 reward_lag=None rewarder_message_lag=None fps=9.67\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,215] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:35,215] [INFO:universe.pyprofile] [pyprofile] period=10.56s timers={\"rewarder.sleep\": {\"calls\": 101, \"std\": \"344.19us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.14ms\", \"mean\": \"935.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.88ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"14.06us\", \"mean\": \"29.95us\"}, \"rewarder.compute_reward\": {\"calls\": 102, \"std\": \"820.97us\", \"mean\": \"353.11us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.54us\", \"mean\": \"35.80us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"83.99us\", \"mean\": \"224.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 102, \"std\": \"33.29us\", \"mean\": \"94.14us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"24.67us\", \"mean\": \"69.33us\"}, \"rewarder.frame\": {\"calls\": 102, \"std\": \"1.49ms\", \"mean\": \"16.62ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 102, \"std\": 2.6797630264061882, \"mean\": 0.3529411764705882}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 0.9486832980505137, \"value\": 10, \"mean\": 12.7}} (export_time=117.54us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:40,224] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16896.7 vnc_pixels_ps[total]=93575.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:40,225] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"572.60us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"83.31us\", \"mean\": \"328.39us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.19us\", \"mean\": \"50.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"231.04us\", \"mean\": \"348.39us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.58us\", \"mean\": \"283.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.57us\", \"mean\": \"119.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.41us\", \"mean\": \"102.72us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.61us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 10.0, \"mean\": 10.0}} (export_time=230.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:40,226] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:44,507] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.28s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:45,240] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6798.4 vnc_pixels_ps[total]=44619.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:45,253] [INFO:universe.pyprofile] [pyprofile] period=5.03s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"589.88us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.70ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"76.82us\", \"mean\": \"59.68us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"923.20us\", \"mean\": \"419.21us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.28ms\", \"mean\": \"9.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"327.94us\", \"mean\": \"326.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.09us\", \"mean\": \"118.29us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.69us\", \"mean\": \"98.03us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.05us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531566}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.3741657386773941, \"value\": 11.0, \"mean\": 10.16}} (export_time=109.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:45,590] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1908 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:50,258] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6797.7 vnc_pixels_ps[total]=44578.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:50,258] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"813.17us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"137.16us\", \"mean\": \"399.51us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"33.04us\", \"mean\": \"59.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"268.66us\", \"mean\": \"373.91us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"144.98us\", \"mean\": \"330.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.26us\", \"mean\": \"123.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"37.34us\", \"mean\": \"115.07us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.25us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.5762081310400612, \"value\": 13.0, \"mean\": 12.82608695652174}} (export_time=190.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:50,259] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.67s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1784 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:55,274] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5944.8 vnc_pixels_ps[total]=44106.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:55,275] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"305.39us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"114.42us\", \"mean\": \"405.28us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.59us\", \"mean\": \"61.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"258.30us\", \"mean\": \"376.14us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"110.45us\", \"mean\": \"337.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.87us\", \"mean\": \"123.18us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"38.57us\", \"mean\": \"118.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.10us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=175.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:39:55,275] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:00,291] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.2 vnc_pixels_ps[total]=44024.7 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:00,292] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"309.35us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"118.44us\", \"mean\": \"412.27us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.09us\", \"mean\": \"58.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"262.75us\", \"mean\": \"384.08us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"105.56us\", \"mean\": \"328.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.55us\", \"mean\": \"124.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.33us\", \"mean\": \"120.80us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"104.04us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=225.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:00,292] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:05,307] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6254.6 vnc_pixels_ps[total]=46419.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:05,307] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"334.51us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"138.32us\", \"mean\": \"418.68us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"27.54us\", \"mean\": \"61.50us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"282.33us\", \"mean\": \"390.01us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"142.20us\", \"mean\": \"346.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.46us\", \"mean\": \"128.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"39.94us\", \"mean\": \"122.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.18us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=118.02us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:05,307] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:10,324] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.0 vnc_pixels_ps[total]=44177.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:10,325] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"239.42us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"94.51us\", \"mean\": \"358.34us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.58us\", \"mean\": \"51.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"229.78us\", \"mean\": \"374.01us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"101.74us\", \"mean\": \"290.65us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.66us\", \"mean\": \"128.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.76us\", \"mean\": \"103.26us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.86us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=205.28us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:10,325] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,007] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=607us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,008] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,008] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,009] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,009] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 7->8, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,009] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,010] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,010] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,011] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,012] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,034] init detected end of child process 2522 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,038] init detected end of child process 2537 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,039] init detected end of child process 2739 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,043] init detected end of child process 2745 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,058] init detected end of child process 2767 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,099] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,100] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:11 [info] 68#68: *41 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:11 [info] 68#68: *42 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:11 [info] 68#68: *43 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:11 [info] 68#68: *40 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:11,189] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,345] init detected end of child process 2525 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,345] init detected end of child process 2533 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,345] init detected end of child process 2534 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:11,345] init detected end of child process 2536 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:12,455] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:12,455] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:12,520] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,005] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,005] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,006] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,006] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,007] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,007] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:40:13 I0508 21:40:13.008019 3148 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:40:13 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58420\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:40:13 I0508 21:40:13.024142 3148 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:13,131] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:17,198] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,799] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['427us', '252us', '184us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,800] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,800] [play_vexpect] vexpect macro complete in 5.757917s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:40:18 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58420 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.078 KiB (1:10.3229 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27217 MiB (1:2.37022 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,995] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 8->8, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,996] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,996] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=7->8, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,997] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,997] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=3.0 episode_count=11 episode_duration=43.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:18,998] [INFO:universe.wrappers.logger] Stats for the past 8.67s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1026.5 vnc_pixels_ps[total]=3654.0 reward_lag=None rewarder_message_lag=None fps=4.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:19,009] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:19,010] [INFO:universe.pyprofile] [pyprofile] period=8.69s timers={\"rewarder.sleep\": {\"calls\": 41, \"std\": \"538.98us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"4.67ms\", \"mean\": \"2.55ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.74ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"40.88us\", \"mean\": \"54.18us\"}, \"rewarder.compute_reward\": {\"calls\": 42, \"std\": \"1.91ms\", \"mean\": \"702.11us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"35.60us\", \"mean\": \"60.20us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"331.66us\", \"mean\": \"487.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 42, \"std\": \"45.91us\", \"mean\": \"119.78us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"66.18us\", \"mean\": \"106.38us\"}, \"rewarder.frame\": {\"calls\": 42, \"std\": \"2.06ms\", \"mean\": \"16.45ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 42, \"std\": 3.853969099057808, \"mean\": 0.6904761904761905}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 1.3416407864998738, \"value\": 10, \"mean\": 12.4}} (export_time=141.62us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:21,065] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.07s, sent 3 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2068 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:22,165] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:24,015] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19271.2 vnc_pixels_ps[total]=88046.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:24,016] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.53ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.82ms\", \"mean\": \"2.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"27.77us\", \"mean\": \"58.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.62ms\", \"mean\": \"549.47us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"217.91us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.35ms\", \"mean\": \"12.50ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"139.54us\", \"mean\": \"331.38us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.72us\", \"mean\": \"130.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.87us\", \"mean\": \"99.98us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.11us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.900535366635859, \"value\": 20.0, \"mean\": 16.48148148148148}} (export_time=247.48us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:24,016] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.85s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2003 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:26,282] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.26s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:29,031] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.5 vnc_pixels_ps[total]=44297.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:29,032] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"790.43us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.43ms\", \"mean\": \"917.59us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"29.05us\", \"mean\": \"66.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"771.44us\", \"mean\": \"426.41us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"117.09us\", \"mean\": \"371.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.82us\", \"mean\": \"126.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.81us\", \"mean\": \"116.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.60us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5107539184552499, \"value\": 21.0, \"mean\": 20.499999999999996}} (export_time=199.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:29,033] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.75s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:34,048] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5958.2 vnc_pixels_ps[total]=44169.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:34,049] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"295.43us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"122.72us\", \"mean\": \"418.54us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.61us\", \"mean\": \"67.30us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"268.02us\", \"mean\": \"405.42us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"125.03us\", \"mean\": \"375.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.25us\", \"mean\": \"134.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"32.99us\", \"mean\": \"116.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.28us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 21.0, \"mean\": 21.0}} (export_time=267.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:34,050] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:36,248] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.20s, sent 2 reward messages to agent: reward=6.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:39,065] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9260.3 vnc_pixels_ps[total]=45262.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:39,067] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.70ms\", \"mean\": \"1.87ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"29.66us\", \"mean\": \"63.58us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.27ms\", \"mean\": \"531.59us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.21ms\", \"mean\": \"9.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"150.68us\", \"mean\": \"355.97us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.96us\", \"mean\": \"129.27us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"31.35us\", \"mean\": \"113.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.97us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096675, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.586949495507729, \"value\": 28.0, \"mean\": 25.666666666666668}} (export_time=331.16us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:39,068] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,797] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=222us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.73s, sent 3 reward messages to agent: reward=4.0 reward_min=0.0 reward_max=3.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 8->9, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,798] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,799] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,799] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,799] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,799] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:43,810] init detected end of child process 2891 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:43,814] init detected end of child process 2906 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:43,816] init detected end of child process 3108 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:43,818] init detected end of child process 3114 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:43,832] init detected end of child process 3136 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:40:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,872] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,872] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:43 [info] 68#68: *45 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:43 [info] 68#68: *46 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:43 [info] 68#68: *47 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:43 [info] 68#68: *44 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:43,962] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:44,365] init detected end of child process 2894 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:44,365] init detected end of child process 2902 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:44,365] init detected end of child process 2903 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:40:44,365] init detected end of child process 2905 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,261] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.30s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,261] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,298] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,783] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,784] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,784] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,784] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,790] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,790] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:40:45 I0508 21:40:45.7905 3510 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:40:45 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58588\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:40:45 I0508 21:40:45.793269 3510 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:45,907] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:49,940] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *52 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *53 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *54 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *55 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *56 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *57 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *58 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *59 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *60 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:40:50 [info] 68#68: *61 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,608] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['220us', '105us', '94us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,608] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,608] [play_vexpect] vexpect macro complete in 6.783267s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:40:52 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58588 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.01 KiB (1:10.3276 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09247 MiB (1:2.76008 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,894] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 9->9, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,894] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,895] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=8->9, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,895] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.10s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,895] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=22.0 episode_count=16 episode_duration=33.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,896] [INFO:universe.wrappers.logger] Stats for the past 13.83s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2705.1 vnc_pixels_ps[total]=15457.6 reward_lag=None rewarder_message_lag=None fps=20.61\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,906] [INFO:gym_controlplane.reward.reward] First score parsed: score=14. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:52,907] [INFO:universe.pyprofile] [pyprofile] period=13.84s timers={\"rewarder.sleep\": {\"calls\": 284, \"std\": \"953.40us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.34ms\", \"mean\": \"1.32ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.91us\", \"mean\": \"39.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 285, \"std\": \"44.24us\", \"mean\": \"111.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"28.13us\", \"mean\": \"49.30us\"}, \"rewarder.compute_reward\": {\"calls\": 285, \"std\": \"1.11ms\", \"mean\": \"428.99us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"1.27ms\", \"mean\": \"1.85ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"132.52us\", \"mean\": \"305.72us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.25ms\", \"mean\": \"11.56ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"39.18us\", \"mean\": \"103.58us\"}, \"rewarder.frame\": {\"calls\": 285, \"std\": \"909.57us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 285, \"std\": 1.851691671407519, \"mean\": 0.18947368421052638}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 4.548450922797942, \"value\": 10, \"mean\": 30.416666666666664}} (export_time=170.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:53,896] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2557 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:55,195] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:57,912] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19255.1 vnc_pixels_ps[total]=97495.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:57,912] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.33ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.54ms\", \"mean\": \"1.46ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"17.92us\", \"mean\": \"36.70us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"384.33us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.42ms\", \"mean\": \"10.32ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"88.57us\", \"mean\": \"206.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.23us\", \"mean\": \"103.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.88us\", \"mean\": \"77.97us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"33.91us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4999999999999998, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.0214237176193035, \"value\": 19.0, \"mean\": 17.384615384615383}} (export_time=145.20us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:57,912] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.72s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:40:59,962] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.05s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:02,929] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8340.2 vnc_pixels_ps[total]=44376.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:02,929] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"688.17us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.09ms\", \"mean\": \"960.15us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"8.77us\", \"mean\": \"26.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"686.52us\", \"mean\": \"286.76us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"394.20us\", \"mean\": \"6.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"29.27us\", \"mean\": \"148.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.05us\", \"mean\": \"88.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"15.21us\", \"mean\": \"62.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.60us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.7042932214309205, \"value\": 23.0, \"mean\": 21.23076923076923}} (export_time=134.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:02,929] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.97s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=254us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 9->10, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,629] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,630] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,630] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,630] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:03,641] init detected end of child process 3262 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:03,646] init detected end of child process 3277 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:03,648] init detected end of child process 3479 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:03,652] init detected end of child process 3485 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:03,666] init detected end of child process 3507 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,714] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,714] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:03 [info] 68#68: *49 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:03 [info] 68#68: *50 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:03 [info] 68#68: *51 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:03 [info] 68#68: *48 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:03,805] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:04,029] init detected end of child process 3265 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:04,029] init detected end of child process 3273 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:04,029] init detected end of child process 3274 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:04,029] init detected end of child process 3276 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,054] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,055] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,118] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,600] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,600] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,600] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,600] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,608] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,608] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:41:05 I0508 21:41:05.608516 3887 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:41:05 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58770\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:41:05 I0508 21:41:05.610246 3887 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:05,724] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:09,757] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,374] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['179us', '65us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,374] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,375] [play_vexpect] vexpect macro complete in 4.732664s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:41:10 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58770 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 13 rects, 395.426 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.286 KiB (1:10.3478 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 22 rects, 788.952 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09168 MiB (1:2.75709 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,595] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 10->10, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,595] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,596] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=9->10, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,596] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,597] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=13.0 episode_count=10 episode_duration=17.70\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,598] [INFO:universe.wrappers.logger] Stats for the past 7.67s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1121.2 vnc_pixels_ps[total]=3826.0 reward_lag=None rewarder_message_lag=None fps=5.61\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,607] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:10,607] [INFO:universe.pyprofile] [pyprofile] period=7.68s timers={\"rewarder.sleep\": {\"calls\": 42, \"std\": \"223.30us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.66ms\", \"mean\": \"1.88ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"14.79us\", \"mean\": \"23.60us\"}, \"rewarder.compute_reward\": {\"calls\": 43, \"std\": \"1.51ms\", \"mean\": \"476.58us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.63us\", \"mean\": \"44.54us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"136.41us\", \"mean\": \"266.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 43, \"std\": \"37.53us\", \"mean\": \"99.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"33.52us\", \"mean\": \"54.88us\"}, \"rewarder.frame\": {\"calls\": 43, \"std\": \"2.35ms\", \"mean\": \"16.41ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 43, \"std\": 2.897855013045588, \"mean\": 0.5348837209302326}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 5.813776741499453, \"value\": 10, \"mean\": 20.4}} (export_time=173.33us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:15,614] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=13840.7 vnc_pixels_ps[total]=77906.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:15,615] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"687.06us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"101.45us\", \"mean\": \"383.35us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.02us\", \"mean\": \"55.45us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.75us\", \"mean\": \"388.67us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"78.25us\", \"mean\": \"316.76us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.90us\", \"mean\": \"129.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.30us\", \"mean\": \"117.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.53us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 10.0, \"mean\": 10.0}} (export_time=278.23us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:15,615] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1724 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:19,730] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.11s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:20,631] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7034.8 vnc_pixels_ps[total]=46368.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:20,633] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"875.27us\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.68ms\", \"mean\": \"961.95us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"26.59us\", \"mean\": \"67.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"865.04us\", \"mean\": \"464.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"103.18us\", \"mean\": \"373.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.91us\", \"mean\": \"132.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"22.78us\", \"mean\": \"122.75us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.90us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.3741657386773941, \"value\": 11.0, \"mean\": 10.16}} (export_time=527.62us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:23,414] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1889 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:25,380] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:25,647] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8419.2 vnc_pixels_ps[total]=44840.2 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:25,647] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.30ms\", \"mean\": \"15.92ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.90ms\", \"mean\": \"1.82ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"25.44us\", \"mean\": \"60.57us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.27ms\", \"mean\": \"531.80us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.64ms\", \"mean\": \"11.65ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"132.22us\", \"mean\": \"339.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.57us\", \"mean\": \"138.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"57.04us\", \"mean\": \"128.90us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.36us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.3988090172238195, \"value\": 15.0, \"mean\": 12.04}} (export_time=126.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:26,681] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=10.0 reward_min=0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:28,230] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:30,664] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9253.6 vnc_pixels_ps[total]=45173.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:30,665] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.10ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.26ms\", \"mean\": \"1.60ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.61us\", \"mean\": \"48.79us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.10ms\", \"mean\": \"443.24us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.47ms\", \"mean\": \"8.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"121.68us\", \"mean\": \"276.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.27us\", \"mean\": \"111.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"30.10us\", \"mean\": \"98.59us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.75us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.4083189157584592, \"mean\": 2.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662219, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 4.5004273301372315, \"value\": 28.0, \"mean\": 24.57692307692308}} (export_time=248.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:30,665] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.44s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,380] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=312us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,380] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,380] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.71s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 10->11, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,381] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=11\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,382] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,382] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,400] init detected end of child process 3628 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,404] init detected end of child process 3643 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,407] init detected end of child process 3852 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,410] init detected end of child process 3934 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,424] init detected end of child process 3874 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:33 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:33 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:41:33 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,458] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,458] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:33 [info] 68#68: *63 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:33 [info] 68#68: *64 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:33 [info] 68#68: *65 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:41:33 [info] 68#68: *62 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:33,544] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,789] init detected end of child process 3631 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,789] init detected end of child process 3639 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,789] init detected end of child process 3640 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:41:33,790] init detected end of child process 3642 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:34,776] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:34,776] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,150] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,629] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,629] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,629] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,629] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,631] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,631] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:41:35 I0508 21:41:35.631516 4252 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:41:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::58938\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:41:35 I0508 21:41:35.636542 4252 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:35,747] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:39,781] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,715] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['413us', '252us', '216us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,716] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,717] [play_vexpect] vexpect macro complete in 6.051630s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:41:41 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::58938 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 331.026 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.828 KiB (1:9.6634 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.26424 MiB (1:2.38508 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,930] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 11->11, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,930] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,930] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=10->11, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,931] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.55s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,931] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=18.0 episode_count=14 episode_duration=31.33\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,932] [INFO:universe.wrappers.logger] Stats for the past 11.27s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1823.8 vnc_pixels_ps[total]=10481.3 reward_lag=None rewarder_message_lag=None fps=14.56\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,945] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:41,945] [INFO:universe.pyprofile] [pyprofile] period=11.28s timers={\"rewarder.sleep\": {\"calls\": 163, \"std\": \"392.11us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"3.07ms\", \"mean\": \"1.26ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.74ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"34.48us\", \"mean\": \"62.62us\"}, \"rewarder.compute_reward\": {\"calls\": 164, \"std\": \"1.12ms\", \"mean\": \"449.13us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.86us\", \"mean\": \"52.89us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"149.41us\", \"mean\": \"399.06us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 164, \"std\": \"42.73us\", \"mean\": \"114.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"51.77us\", \"mean\": \"119.24us\"}, \"rewarder.frame\": {\"calls\": 164, \"std\": \"1.14ms\", \"mean\": \"16.68ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 164, \"std\": 2.352032941002077, \"mean\": 0.2621951219512195}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 4.810702354423639, \"value\": 10, \"mean\": 26.714285714285715}} (export_time=195.74us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:43,048] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 2 reward messages to agent: reward=4.0 reward_min=2 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2097 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:44,364] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:46,948] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25152.7 vnc_pixels_ps[total]=91370.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:46,948] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.20ms\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.46ms\", \"mean\": \"1.17ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"30.72us\", \"mean\": \"50.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"836.70us\", \"mean\": \"386.21us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.13ms\", \"mean\": \"7.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"160.54us\", \"mean\": \"281.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.32us\", \"mean\": \"105.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"37.98us\", \"mean\": \"98.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.14us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662217, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.11151706753128, \"value\": 19.0, \"mean\": 16.192307692307693}} (export_time=116.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:46,949] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.58s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:48,264] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:51,949] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"519.13us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.45ms\", \"mean\": \"711.36us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.11us\", \"mean\": \"42.80us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"507.66us\", \"mean\": \"321.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.20us\", \"mean\": \"5.36ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"96.48us\", \"mean\": \"243.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"41.99us\", \"mean\": \"96.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"27.73us\", \"mean\": \"87.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"18.92us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2818160567729817, \"mean\": 0.08666666666666668}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.275207373784295, \"value\": 22.0, \"mean\": 21.11538461538462}} (export_time=198.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:51,949] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:51,965] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7839.3 vnc_pixels_ps[total]=46465.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:54,982] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:56,965] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"555.03us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.58ms\", \"mean\": \"795.53us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.67us\", \"mean\": \"46.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"540.57us\", \"mean\": \"356.04us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"109.75us\", \"mean\": \"5.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"80.48us\", \"mean\": \"264.99us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.12us\", \"mean\": \"108.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"28.25us\", \"mean\": \"94.94us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.29us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.8330302779823342, \"value\": 27.0, \"mean\": 25.12}} (export_time=270.84us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:56,965] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.98s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:56,981] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7623.1 vnc_pixels_ps[total]=44872.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:41:58,016] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:01,981] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"499.17us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.40ms\", \"mean\": \"620.09us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"27.11us\", \"mean\": \"48.15us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"479.05us\", \"mean\": \"360.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.91ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"172.47us\", \"mean\": \"279.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.45us\", \"mean\": \"116.89us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"32.93us\", \"mean\": \"94.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.83us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4423258684646913, \"value\": 28.0, \"mean\": 27.75}} (export_time=176.91us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:01,981] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.97s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1892 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:01,998] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.5 vnc_pixels_ps[total]=44291.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:03,214] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.23s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:05,598] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:06,981] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.28ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.91ms\", \"mean\": \"1.66ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.61us\", \"mean\": \"46.09us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.28ms\", \"mean\": \"464.20us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.23ms\", \"mean\": \"11.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"99.73us\", \"mean\": \"259.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.79us\", \"mean\": \"119.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"30.90us\", \"mean\": \"95.34us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"21.70us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117918, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28181605677298177, \"mean\": 0.08666666666666666}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4951202678663045, \"value\": 33.0, \"mean\": 29.34615384615385}} (export_time=256.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:06,982] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:07,014] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8340.9 vnc_pixels_ps[total]=44380.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:08,198] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:11,981] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"802.37us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.48ms\", \"mean\": \"863.14us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"57.65us\", \"mean\": \"61.69us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"790.09us\", \"mean\": \"398.79us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.05ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"333.14us\", \"mean\": \"357.55us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"46.82us\", \"mean\": \"120.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.35us\", \"mean\": \"102.65us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"27.99us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.271746488194703, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.8572224859501465, \"value\": 37.0, \"mean\": 35.833333333333336}} (export_time=238.90us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:11,982] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.78s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:12,031] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6717.0 vnc_pixels_ps[total]=43992.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:16,998] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"247.79us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"90.62us\", \"mean\": \"363.50us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.86us\", \"mean\": \"51.73us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"223.49us\", \"mean\": \"350.71us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"82.82us\", \"mean\": \"292.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.37us\", \"mean\": \"118.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.54us\", \"mean\": \"105.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.95us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=163.08us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:16,998] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:17,048] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.6 vnc_pixels_ps[total]=44335.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:21,998] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"234.12us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"99.28us\", \"mean\": \"346.56us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.96us\", \"mean\": \"48.75us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"217.59us\", \"mean\": \"339.17us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"89.68us\", \"mean\": \"274.68us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.98us\", \"mean\": \"115.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.36us\", \"mean\": \"101.42us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"18.58us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666676}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=209.09us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:21,999] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:22,065] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5937.4 vnc_pixels_ps[total]=44009.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:27,014] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"306.69us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"162.51us\", \"mean\": \"419.76us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.51us\", \"mean\": \"60.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"290.37us\", \"mean\": \"366.14us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"107.40us\", \"mean\": \"346.88us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.10us\", \"mean\": \"121.23us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.18us\", \"mean\": \"114.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.84us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=140.91us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:27,015] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:27,081] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6196.0 vnc_pixels_ps[total]=45928.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:29,222] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.21s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 5482, 'rewarder.vnc.updates.pixels': 10968, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:31,166] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.94s, sent 2 reward messages to agent: reward=4.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:32,031] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"953.05us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.80ms\", \"mean\": \"1.34ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.18us\", \"mean\": \"50.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"939.91us\", \"mean\": \"417.95us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.10ms\", \"mean\": \"8.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"98.59us\", \"mean\": \"285.31us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.94us\", \"mean\": \"108.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"27.94us\", \"mean\": \"101.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.07us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.8522595631156396, \"value\": 44.0, \"mean\": 39.84615384615385}} (export_time=109.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:32,098] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8416.4 vnc_pixels_ps[total]=44825.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:42:35 [info] 68#68: *67 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:42:35 [info] 68#68: *68 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:42:35 [info] 68#68: *69 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:37,048] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"247.69us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"152.20us\", \"mean\": \"353.59us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"36.43us\", \"mean\": \"50.76us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"230.91us\", \"mean\": \"343.98us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"148.00us\", \"mean\": \"282.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.44us\", \"mean\": \"119.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"46.36us\", \"mean\": \"103.66us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.47us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 44.0, \"mean\": 44.0}} (export_time=162.60us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:37,048] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.88s, sent 2 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1726 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:37,114] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.9 vnc_pixels_ps[total]=44338.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:42,064] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"244.36us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"104.42us\", \"mean\": \"372.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.93us\", \"mean\": \"54.17us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"227.09us\", \"mean\": \"368.90us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"89.49us\", \"mean\": \"306.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.04us\", \"mean\": \"125.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.25us\", \"mean\": \"107.11us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.22us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 44.0, \"mean\": 44.0}} (export_time=166.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:42,065] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:42,131] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,716] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=569us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,716] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,716] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.65s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,716] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,717] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,718] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 11->12, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,718] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,718] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,718] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=12\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,719] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,719] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:46,740] init detected end of child process 3995 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:46,744] init detected end of child process 4010 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:46,744] init detected end of child process 4218 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:42:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:46,763] init detected end of child process 4243 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:42:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:42:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,796] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,796] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:46,883] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:47,053] init detected end of child process 3998 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:47,053] init detected end of child process 4006 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:47,053] init detected end of child process 4007 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:42:47,054] init detected end of child process 4009 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,150] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,151] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,217] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,703] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,703] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,703] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,703] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,711] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,711] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:42:48 I0508 21:42:48.711993 4786 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:42:48 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59188\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:42:48 I0508 21:42:48.713217 4786 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:48,829] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:52,862] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,513] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['299us', '239us', '150us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,514] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,514] [play_vexpect] vexpect macro complete in 4.768730s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:42:53 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59188 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.682 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.405 KiB (1:10.3463 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27142 MiB (1:2.3681 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,704] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 12->12, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,704] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,705] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=11->12, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,705] [INFO:universe.rewarder.remote] [Rewarder] Over past 6.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,705] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=34.0 episode_count=29 episode_duration=71.77\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,706] [INFO:universe.wrappers.logger] Stats for the past 11.57s: vnc_updates_ps=1.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2804.1 vnc_pixels_ps[total]=17840.7 reward_lag=None rewarder_message_lag=None fps=23.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,719] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:53,719] [INFO:universe.pyprofile] [pyprofile] period=11.65s timers={\"rewarder.sleep\": {\"calls\": 279, \"std\": \"262.51us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"2.48ms\", \"mean\": \"916.68us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.09ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"23.75us\", \"mean\": \"54.67us\"}, \"rewarder.compute_reward\": {\"calls\": 280, \"std\": \"848.96us\", \"mean\": \"406.98us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"29.34us\", \"mean\": \"64.53us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"159.48us\", \"mean\": \"349.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 280, \"std\": \"48.46us\", \"mean\": \"118.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"36.64us\", \"mean\": \"111.22us\"}, \"rewarder.frame\": {\"calls\": 280, \"std\": \"756.04us\", \"mean\": \"16.73ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 280, \"std\": 1.3374743682074357, \"mean\": 0.15714285714285722}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 7.089490077940542, \"value\": 10, \"mean\": 42.52173913043478}} (export_time=139.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:56,556] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.85s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2102 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:58,056] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.50s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:58,722] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17389.6 vnc_pixels_ps[total]=81048.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:42:58,723] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.33ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.11ms\", \"mean\": \"1.47ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"20.56us\", \"mean\": \"46.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"447.95us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.85ms\", \"mean\": \"7.77ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"101.05us\", \"mean\": \"259.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.54us\", \"mean\": \"122.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.70us\", \"mean\": \"90.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.07us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096675, \"mean\": 0.08970099667774094}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.1596246568305393, \"value\": 13.0, \"mean\": 10.962962962962962}} (export_time=90.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:00,439] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:01,972] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:03,739] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8673.3 vnc_pixels_ps[total]=46828.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:03,739] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"821.95us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.45ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.94us\", \"mean\": \"36.75us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"816.02us\", \"mean\": \"340.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.60ms\", \"mean\": \"7.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"88.28us\", \"mean\": \"211.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.21us\", \"mean\": \"97.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"28.28us\", \"mean\": \"77.55us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.99us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5773502691896257, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.0817891713250307, \"value\": 19.0, \"mean\": 16.423076923076923}} (export_time=116.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:03,739] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.77s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,522] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=208us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,522] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,522] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,522] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,522] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 12->13, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,523] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,523] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,523] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=13\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,523] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,523] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,535] init detected end of child process 4528 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,540] init detected end of child process 4543 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,543] init detected end of child process 4745 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,543] init detected end of child process 4752 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,560] init detected end of child process 4777 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:04 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:04 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:04 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,593] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,594] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:04 [info] 68#68: *71 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:04 [info] 68#68: *72 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:04 [info] 68#68: *73 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:04 [info] 68#68: *70 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:04,679] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,913] init detected end of child process 4531 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,913] init detected end of child process 4539 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,913] init detected end of child process 4540 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:04,914] init detected end of child process 4542 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:05,950] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:05,950] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:09,621] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,094] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,094] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,095] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,095] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,100] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,100] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:10 I0508 21:43:10.10077 5179 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:10 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59362\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:10 I0508 21:43:10.108839 5179 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:10,222] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,273] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['309us', '200us', '166us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,273] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,274] [play_vexpect] vexpect macro complete in 2.139390s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59362 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 18 rects, 950.272 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.71982 MiB (1:1.33288 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 31 rects, 1.03017 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.7389 MiB (1:1.43493 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,492] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 13->13, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,493] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,493] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=12->13, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,494] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,494] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=9.0 episode_count=10 episode_duration=18.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,495] [INFO:universe.wrappers.logger] Stats for the past 8.76s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1013.0 vnc_pixels_ps[total]=3564.2 reward_lag=None rewarder_message_lag=None fps=5.48\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,504] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:12,505] [INFO:universe.pyprofile] [pyprofile] period=8.77s timers={\"rewarder.sleep\": {\"calls\": 47, \"std\": \"180.58us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.89ms\", \"mean\": \"1.95ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.75ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"14.93us\", \"mean\": \"21.54us\"}, \"rewarder.compute_reward\": {\"calls\": 48, \"std\": \"1.48ms\", \"mean\": \"441.96us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.23us\", \"mean\": \"33.06us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"96.70us\", \"mean\": \"212.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 48, \"std\": \"36.37us\", \"mean\": \"85.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"24.17us\", \"mean\": \"50.26us\"}, \"rewarder.frame\": {\"calls\": 48, \"std\": \"2.24ms\", \"mean\": \"16.44ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 48, \"std\": 3.46307779315141, \"mean\": 0.5833333333333334}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 4.024922359499621, \"value\": 10, \"mean\": 17.2}} (export_time=113.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:13,695] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2084 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:15,211] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=4.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:17,511] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18410.7 vnc_pixels_ps[total]=87243.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:17,511] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"902.94us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.79ms\", \"mean\": \"943.95us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.43us\", \"mean\": \"43.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"620.87us\", \"mean\": \"381.04us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"497.41us\", \"mean\": \"5.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"99.74us\", \"mean\": \"244.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.99us\", \"mean\": \"112.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"27.72us\", \"mean\": \"89.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.93us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.175740369126371, \"value\": 17.0, \"mean\": 14.576923076923077}} (export_time=147.82us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:17,512] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.30s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1909 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:22,527] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5979.2 vnc_pixels_ps[total]=44257.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:22,527] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"274.52us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"125.73us\", \"mean\": \"365.10us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.61us\", \"mean\": \"52.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"242.27us\", \"mean\": \"336.95us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"111.21us\", \"mean\": \"297.81us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.97us\", \"mean\": \"115.05us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"37.94us\", \"mean\": \"106.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.80us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 17.0, \"mean\": 17.0}} (export_time=77.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:22,528] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:24,777] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.25s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:27,544] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7554.9 vnc_pixels_ps[total]=44307.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:27,544] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"487.22us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.51ms\", \"mean\": \"641.89us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"7.07us\", \"mean\": \"25.49us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"483.19us\", \"mean\": \"253.77us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"612.48us\", \"mean\": \"5.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"25.30us\", \"mean\": \"147.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.98us\", \"mean\": \"83.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"12.92us\", \"mean\": \"60.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.22us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.3928388277184136, \"value\": 20.0, \"mean\": 18.239999999999995}} (export_time=143.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:27,544] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.77s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=214us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 13->14, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,294] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,295] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=14\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,295] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,295] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,305] init detected end of child process 4896 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,308] init detected end of child process 4911 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,311] init detected end of child process 5113 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,315] init detected end of child process 5119 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,331] init detected end of child process 5141 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,372] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,373] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:28,458] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:28 [info] 68#68: *75 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:28 [info] 68#68: *76 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:28 [info] 68#68: *77 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:28 [info] 68#68: *74 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,653] init detected end of child process 4899 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,653] init detected end of child process 4907 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,653] init detected end of child process 4908 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:28,653] init detected end of child process 4910 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:29,721] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:29,721] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:29,755] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,241] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,241] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,241] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7, 'encoding': 'zrle', 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,241] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,243] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,243] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:30 I0508 21:43:30.24407 5511 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:30 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59484\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:30 I0508 21:43:30.251458 5511 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:30,360] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:34,411] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,078] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['173us', '67us', '59us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,078] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,078] [play_vexpect] vexpect macro complete in 5.800600s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:36 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59484 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.045 KiB (1:10.3252 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27213 MiB (1:2.37029 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,332] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 14->14, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,332] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,333] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=13->14, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,333] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.79s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,333] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=10.0 episode_count=10 episode_duration=23.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,334] [INFO:universe.wrappers.logger] Stats for the past 8.79s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1160.1 vnc_pixels_ps[total]=4697.8 reward_lag=None rewarder_message_lag=None fps=5.23\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,342] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:36,343] [INFO:universe.pyprofile] [pyprofile] period=8.80s timers={\"rewarder.sleep\": {\"calls\": 45, \"std\": \"218.56us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.41ms\", \"mean\": \"1.72ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.61ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"8.16us\", \"mean\": \"17.28us\"}, \"rewarder.compute_reward\": {\"calls\": 46, \"std\": \"1.34ms\", \"mean\": \"422.14us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"26.63us\", \"mean\": \"45.74us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"138.03us\", \"mean\": \"229.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 46, \"std\": \"37.40us\", \"mean\": \"84.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"23.51us\", \"mean\": \"46.59us\"}, \"rewarder.frame\": {\"calls\": 46, \"std\": \"2.28ms\", \"mean\": \"16.43ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 46, \"std\": 3.5369683243614483, \"mean\": 0.6086956521739131}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 4.47213595499958, \"value\": 10, \"mean\": 18.0}} (export_time=112.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:37,668] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.33s, sent 5 reward messages to agent: reward=4.0 reward_min=-1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2070 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:41,351] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17696.7 vnc_pixels_ps[total]=87807.5 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:41,352] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.09ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.89ms\", \"mean\": \"1.04ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"17.52us\", \"mean\": \"42.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"933.08us\", \"mean\": \"392.88us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"6.00ms\", \"mean\": \"9.58ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"87.50us\", \"mean\": \"241.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.39us\", \"mean\": \"119.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"24.04us\", \"mean\": \"87.83us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.40us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0954451150103324, \"mean\": 0.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.2228591968761657, \"value\": 14.0, \"mean\": 13.15384615384615}} (export_time=190.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:41,352] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,083] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=241us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 14->15, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,084] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,085] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,085] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,095] init detected end of child process 5262 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,099] init detected end of child process 5277 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,102] init detected end of child process 5486 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,103] init detected end of child process 5479 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,118] init detected end of child process 5508 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:42 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:42 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:43:42 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,157] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,157] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:42,240] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:42 [info] 68#68: *79 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:42 [info] 68#68: *80 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:42 [info] 68#68: *81 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:43:42 [info] 68#68: *78 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,489] init detected end of child process 5265 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,489] init detected end of child process 5273 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,489] init detected end of child process 5274 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:43:42,490] init detected end of child process 5276 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:43,505] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:43,505] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:43,566] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,058] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,059] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,059] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,059] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,068] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,069] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:44 I0508 21:43:44.069136 5886 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:44 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59616\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:43:44 I0508 21:43:44.070316 5886 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:44,193] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:48,243] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:48,876] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['155us', '69us', '80us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:48,877] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:48,877] [play_vexpect] vexpect macro complete in 4.774467s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:43:48 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59616 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.682 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.434 KiB (1:10.3444 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09183 MiB (1:2.75763 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,067] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 15->15, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,068] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,068] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=14->15, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,068] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.72s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,068] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=4.0 episode_count=7 episode_duration=12.73\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,069] [INFO:universe.wrappers.logger] Stats for the past 7.72s: vnc_updates_ps=0.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1314.5 vnc_pixels_ps[total]=5298.3 reward_lag=None rewarder_message_lag=None fps=5.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,079] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:49,079] [INFO:universe.pyprofile] [pyprofile] period=7.73s timers={\"rewarder.sleep\": {\"calls\": 44, \"std\": \"511.57us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.99ms\", \"mean\": \"2.09ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.03ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"25.51us\", \"mean\": \"32.08us\"}, \"rewarder.compute_reward\": {\"calls\": 45, \"std\": \"1.60ms\", \"mean\": \"526.20us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.77us\", \"mean\": \"38.54us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"116.23us\", \"mean\": \"292.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 45, \"std\": \"39.64us\", \"mean\": \"92.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"47.13us\", \"mean\": \"71.86us\"}, \"rewarder.frame\": {\"calls\": 45, \"std\": \"2.31ms\", \"mean\": \"16.45ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 45, \"std\": 3.4271642133773725, \"mean\": 0.6000000000000001}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 1.7888543819998315, \"value\": 10, \"mean\": 13.2}} (export_time=114.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:50,686] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.62s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2084 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:51,969] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:53,485] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:54,085] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25342.1 vnc_pixels_ps[total]=81830.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:54,086] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.60ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"4.16ms\", \"mean\": \"2.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"17.70us\", \"mean\": \"41.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.46ms\", \"mean\": \"464.13us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"3.98ms\", \"mean\": \"8.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"84.28us\", \"mean\": \"229.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.65us\", \"mean\": \"98.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"24.17us\", \"mean\": \"82.62us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.23us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 0.8366600265340757, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.09302325581395349}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.2522769196418384, \"value\": 19.0, \"mean\": 15.535714285714283}} (export_time=120.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:56,352] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.87s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:58,069] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:59,102] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8403.7 vnc_pixels_ps[total]=44825.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:59,102] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"757.08us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.25ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.30us\", \"mean\": \"39.74us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"751.22us\", \"mean\": \"348.20us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.82ms\", \"mean\": \"6.72ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"81.15us\", \"mean\": \"224.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.17us\", \"mean\": \"98.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.19us\", \"mean\": \"81.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.16us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.7222525500500316, \"value\": 24.0, \"mean\": 21.38461538461539}} (export_time=104.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:43:59,102] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:03,069] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.97s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:04,119] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8356.4 vnc_pixels_ps[total]=44362.7 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:04,120] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"653.43us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.98ms\", \"mean\": \"972.53us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"17.82us\", \"mean\": \"37.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"653.42us\", \"mean\": \"348.44us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.16ms\", \"mean\": \"5.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"93.99us\", \"mean\": \"211.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.73us\", \"mean\": \"104.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.80us\", \"mean\": \"75.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.77us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4999999999999998, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.4922019523732934, \"value\": 28.0, \"mean\": 24.679999999999996}} (export_time=254.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:04,121] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:05,654] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:06,952] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:08,323] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 2 reward messages to agent: reward=6.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:09,135] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=11117.7 vnc_pixels_ps[total]=47330.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:09,135] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.78ms\", \"mean\": \"1.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"42.92us\", \"mean\": \"37.35us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"381.71us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"1.93ms\", \"mean\": \"6.39ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"209.93us\", \"mean\": \"211.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.62us\", \"mean\": \"89.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"21.61us\", \"mean\": \"65.04us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.44us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29555586085907787, \"mean\": 0.0963455149501661}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 3.82305683279729, \"value\": 45.0, \"mean\": 34.51724137931034}} (export_time=103.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:10,652] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.33s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1396, 'rewarder.profile': '<1912 bytes>', 'rewarder.vnc.updates.pixels': 9928, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:14,154] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6807.4 vnc_pixels_ps[total]=44508.1 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:14,155] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"400.99us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.14ms\", \"mean\": \"520.37us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.83us\", \"mean\": \"38.85us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"425.12us\", \"mean\": \"301.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.61ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"105.98us\", \"mean\": \"221.40us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.10us\", \"mean\": \"95.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.60us\", \"mean\": \"85.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.28us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.48154341234307513, \"value\": 46.0, \"mean\": 45.66666666666667}} (export_time=257.73us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:14,155] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.50s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1901 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:15,835] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.68s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:18,019] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:19,169] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7584.5 vnc_pixels_ps[total]=44570.1 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:19,170] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"621.22us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.71ms\", \"mean\": \"747.77us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"14.98us\", \"mean\": \"33.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"572.94us\", \"mean\": \"304.26us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"674.86us\", \"mean\": \"6.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"74.46us\", \"mean\": \"193.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.94us\", \"mean\": \"89.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"28.24us\", \"mean\": \"73.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.60us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.7461009761866494, \"value\": 48.0, \"mean\": 46.83999999999999}} (export_time=269.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:19,171] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,869] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=369us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,869] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,869] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.70s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,869] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,869] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,870] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 15->16, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,870] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,870] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,870] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=16\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,870] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,871] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:20,884] init detected end of child process 5629 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:20,888] init detected end of child process 5644 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:20,891] init detected end of child process 5846 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:20,894] init detected end of child process 5852 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:20,912] init detected end of child process 5877 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,948] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:20,948] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:20 [info] 68#68: *83 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:20 [info] 68#68: *84 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:20 [info] 68#68: *85 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:20 [info] 68#68: *82 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:21,036] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:21,173] init detected end of child process 5632 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:21,173] init detected end of child process 5640 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:21,173] init detected end of child process 5641 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:21,174] init detected end of child process 5643 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:22,298] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:22,298] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:25,557] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,036] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,036] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,036] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,036] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,041] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,041] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:26 I0508 21:44:26.041396 6261 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:26 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59832\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:26 I0508 21:44:26.043248 6261 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:26,162] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,513] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['458us', '217us', '159us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,514] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,514] [play_vexpect] vexpect macro complete in 3.439361s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59832 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3604 KiB (1:15.3485 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 39 rects, 1.13664 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.2536 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 52 rects, 1.21328 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.2727 MiB (1:1.4144 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,722] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 16->16, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,722] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,722] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=15->16, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,723] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.85s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,723] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=38.0 episode_count=29 episode_duration=40.65\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,724] [INFO:universe.wrappers.logger] Stats for the past 10.55s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1461.6 vnc_pixels_ps[total]=7588.9 reward_lag=None rewarder_message_lag=None fps=9.76\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,733] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:29,733] [INFO:universe.pyprofile] [pyprofile] period=10.56s timers={\"rewarder.sleep\": {\"calls\": 102, \"std\": \"396.32us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.39ms\", \"mean\": \"1.04ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.69ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"21.01us\", \"mean\": \"33.93us\"}, \"rewarder.compute_reward\": {\"calls\": 103, \"std\": \"947.17us\", \"mean\": \"351.78us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.12us\", \"mean\": \"44.27us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"152.29us\", \"mean\": \"257.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 103, \"std\": \"43.37us\", \"mean\": \"87.93us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"35.42us\", \"mean\": \"74.12us\"}, \"rewarder.frame\": {\"calls\": 103, \"std\": \"1.45ms\", \"mean\": \"16.64ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 103, \"std\": 2.7648152401910906, \"mean\": 0.35922330097087374}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 12.016655108639842, \"value\": 10, \"mean\": 44.2}} (export_time=148.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:34,740] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17036.7 vnc_pixels_ps[total]=94531.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:34,740] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"650.83us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"128.29us\", \"mean\": \"322.47us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.77us\", \"mean\": \"45.02us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"217.77us\", \"mean\": \"332.79us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"116.84us\", \"mean\": \"253.69us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.38us\", \"mean\": \"118.88us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"40.37us\", \"mean\": \"103.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.08us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=82.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:34,740] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=3 reward_min=0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,506] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=216us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,507] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,507] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.77s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,507] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,507] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,507] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 16->17, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,508] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,508] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,508] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=17\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,508] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,508] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,523] init detected end of child process 5994 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,527] init detected end of child process 6009 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,530] init detected end of child process 6211 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,531] init detected end of child process 6216 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,545] init detected end of child process 6237 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,585] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,585] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:38,667] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:38 [info] 68#68: *87 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:38 [info] 68#68: *88 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:38 [info] 68#68: *89 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:38 [info] 68#68: *86 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,901] init detected end of child process 5997 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,901] init detected end of child process 6005 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,901] init detected end of child process 6006 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:38,901] init detected end of child process 6008 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:39,906] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:39,907] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,321] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,804] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,805] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,805] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,805] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,807] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,807] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:43 I0508 21:44:43.807912 6628 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:43 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::59966\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:43 I0508 21:44:43.811126 6628 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:43,933] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,300] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['148us', '63us', '55us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,300] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,301] [play_vexpect] vexpect macro complete in 3.459447s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:47 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::59966 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9209 KiB (1:15.7337 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 41 rects, 1.16531 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.33569 MiB (1:1.33279 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 55 rects, 1.25014 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.35632 MiB (1:1.42107 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,501] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 17->17, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,501] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,501] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=16->17, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,502] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,502] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=3.0 episode_count=3 episode_duration=17.78\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,503] [INFO:universe.wrappers.logger] Stats for the past 12.76s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2102.1 vnc_pixels_ps[total]=12821.5 reward_lag=None rewarder_message_lag=None fps=17.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,512] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:47,513] [INFO:universe.pyprofile] [pyprofile] period=12.77s timers={\"rewarder.sleep\": {\"calls\": 226, \"std\": \"170.08us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 19, \"std\": \"1.99ms\", \"mean\": \"694.68us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.77ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 57, \"std\": \"16.18us\", \"mean\": \"28.67us\"}, \"rewarder.compute_reward\": {\"calls\": 227, \"std\": \"686.63us\", \"mean\": \"297.24us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"13.30us\", \"mean\": \"37.87us\"}, \"reward.parsing.gameover\": {\"calls\": 19, \"std\": \"90.74us\", \"mean\": \"191.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 227, \"std\": \"35.78us\", \"mean\": \"93.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 19, \"std\": \"27.81us\", \"mean\": \"68.49us\"}, \"rewarder.frame\": {\"calls\": 227, \"std\": \"990.64us\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 227, \"std\": 1.7415680118773835, \"mean\": 0.19383259911894277}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 51, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 19, \"std\": 0.6882472016116854, \"value\": 10, \"mean\": 12.842105263157896}} (export_time=139.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:48,569] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2102 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=318us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.82s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 17->18, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,386] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,387] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=18\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,387] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,387] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:50,399] init detected end of child process 6351 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:50,404] init detected end of child process 6366 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:50,405] init detected end of child process 6568 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:50,407] init detected end of child process 6574 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:50,422] init detected end of child process 6595 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:50 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:50 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:44:50 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,460] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,460] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:50,545] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:50 [info] 68#68: *91 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:50 [info] 68#68: *92 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:50 [info] 68#68: *93 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:44:50 [info] 68#68: *90 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:51,053] init detected end of child process 6354 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:51,053] init detected end of child process 6362 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:51,053] init detected end of child process 6363 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:44:51,053] init detected end of child process 6365 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:51,793] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:51,794] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,498] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,983] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,983] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,983] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,983] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,990] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:55,990] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:55 I0508 21:44:55.990451 6979 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::60098\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:44:55 I0508 21:44:55.992077 6979 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:56,107] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,191] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['296us', '173us', '153us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,192] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,192] [play_vexpect] vexpect macro complete in 2.168402s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:44:58 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::60098 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 15 rects, 901.12 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.57909 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 981.015 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.59818 MiB (1:1.44047 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,372] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 18->18, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,372] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,373] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=17->18, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,373] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,373] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=2.0 episode_count=3 episode_duration=10.87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,374] [INFO:universe.wrappers.logger] Stats for the past 10.87s: vnc_updates_ps=3.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7310.6 vnc_pixels_ps[total]=33601.8 reward_lag=None rewarder_message_lag=None fps=16.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,382] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:58,383] [INFO:universe.pyprofile] [pyprofile] period=10.87s timers={\"rewarder.sleep\": {\"calls\": 173, \"std\": \"978.53us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 15, \"std\": \"2.28ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.48ms\", \"mean\": \"6.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 45, \"std\": \"8.94us\", \"mean\": \"23.11us\"}, \"rewarder.compute_reward\": {\"calls\": 174, \"std\": \"807.85us\", \"mean\": \"305.72us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.14us\", \"mean\": \"43.59us\"}, \"reward.parsing.gameover\": {\"calls\": 15, \"std\": \"97.98us\", \"mean\": \"171.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 174, \"std\": \"36.33us\", \"mean\": \"92.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 15, \"std\": \"20.63us\", \"mean\": \"61.51us\"}, \"rewarder.frame\": {\"calls\": 174, \"std\": \"1.15ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 0.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 174, \"std\": 2.3597811069319645, \"mean\": 0.2586206896551725}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 39, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 15, \"std\": 1.0327955589886446, \"value\": 10, \"mean\": 11.066666666666666}} (export_time=108.24us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:44:59,991] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.62s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2167 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:01,723] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:03,391] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25797.0 vnc_pixels_ps[total]=90480.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:03,391] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.36ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.70ms\", \"mean\": \"1.60ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"26.03us\", \"mean\": \"56.97us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"461.01us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.31ms\", \"mean\": \"10.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"131.41us\", \"mean\": \"319.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.63us\", \"mean\": \"118.52us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"32.92us\", \"mean\": \"117.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.13us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 2.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.1083015396737914, \"value\": 20.0, \"mean\": 15.692307692307692}} (export_time=199.56us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:03,392] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1914 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:04,757] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.36s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,190] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=379us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,191] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,191] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.43s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,191] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,191] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,191] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 18->19, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,192] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,192] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,192] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=19\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,192] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,193] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,206] init detected end of child process 6709 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,210] init detected end of child process 6724 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,214] init detected end of child process 6926 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,215] init detected end of child process 6933 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,233] init detected end of child process 6955 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:45:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:45:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:45:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,270] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,271] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:07 [info] 68#68: *95 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:07 [info] 68#68: *96 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:07 [info] 68#68: *97 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:07 [info] 68#68: *94 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:07,361] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,601] init detected end of child process 6712 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,601] init detected end of child process 6720 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,601] init detected end of child process 6721 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:45:07,601] init detected end of child process 6723 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:08,602] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:08,603] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,019] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,500] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,500] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,500] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,500] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,506] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,506] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:45:12 I0508 21:45:12.506892 7357 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:45:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::60232\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:45:12 I0508 21:45:12.508286 7357 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:12,627] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:16,678] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:17,995] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['337us', '179us', '158us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:17,996] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:17,997] [play_vexpect] vexpect macro complete in 5.456115s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:45:18 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::60232 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3721 KiB (1:15.3392 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 36 rects, 1.09619 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.13779 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 50 rects, 1.18428 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.15836 MiB (1:1.43056 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,191] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 19->19, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,192] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,192] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=18->19, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,193] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.00s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,193] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=13.0 episode_count=8 episode_duration=19.82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,194] [INFO:universe.wrappers.logger] Stats for the past 14.80s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2267.1 vnc_pixels_ps[total]=11930.1 reward_lag=None rewarder_message_lag=None fps=15.47\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,202] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:18,202] [INFO:universe.pyprofile] [pyprofile] period=14.81s timers={\"rewarder.sleep\": {\"calls\": 228, \"std\": \"1.08ms\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 22, \"std\": \"3.33ms\", \"mean\": \"1.61ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.28ms\", \"mean\": \"9.27ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 66, \"std\": \"30.39us\", \"mean\": \"50.02us\"}, \"rewarder.compute_reward\": {\"calls\": 229, \"std\": \"1.22ms\", \"mean\": \"474.83us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.28us\", \"mean\": \"51.98us\"}, \"reward.parsing.gameover\": {\"calls\": 22, \"std\": \"161.14us\", \"mean\": \"315.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 229, \"std\": \"53.06us\", \"mean\": \"115.89us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 22, \"std\": \"39.66us\", \"mean\": \"93.89us\"}, \"rewarder.frame\": {\"calls\": 229, \"std\": \"950.13us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 229, \"std\": 2.5216597905521514, \"mean\": 0.2576419213973799}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 60, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 19, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 22, \"std\": 2.8333969944465123, \"value\": 10, \"mean\": 21.13636363636363}} (export_time=167.37us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:21,143] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.95s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2147 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:22,243] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:23,210] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21271.4 vnc_pixels_ps[total]=113913.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:23,211] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.17ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.09ms\", \"mean\": \"1.24ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"26.64us\", \"mean\": \"56.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"999.75us\", \"mean\": \"428.50us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.09ms\", \"mean\": \"11.00ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"129.51us\", \"mean\": \"320.81us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"64.61us\", \"mean\": \"122.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"31.74us\", \"mean\": \"104.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.05us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961358, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.3043437243605824, \"value\": 16.0, \"mean\": 11.68}} (export_time=169.04us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:27,660] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.42s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:28,226] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6797.7 vnc_pixels_ps[total]=44615.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:28,227] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"411.29us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.05ms\", \"mean\": \"563.68us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.86us\", \"mean\": \"52.17us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"390.11us\", \"mean\": \"346.72us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.14ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"102.86us\", \"mean\": \"292.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.05us\", \"mean\": \"110.90us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.02us\", \"mean\": \"100.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.80us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260707, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.1293194051465594, \"value\": 20.0, \"mean\": 16.333333333333336}} (export_time=156.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:28,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 3 reward messages to agent: reward=8.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:30,693] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:33,243] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9216.7 vnc_pixels_ps[total]=45027.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:33,244] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"833.80us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.33ms\", \"mean\": \"1.30ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.71us\", \"mean\": \"49.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"827.45us\", \"mean\": \"428.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"759.20us\", \"mean\": \"6.42ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"107.54us\", \"mean\": \"277.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.09us\", \"mean\": \"116.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.66us\", \"mean\": \"96.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.12us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.7888543819998317, \"mean\": 2.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609667, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.714144826857427, \"value\": 31.0, \"mean\": 27.555555555555557}} (export_time=208.14us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:33,245] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.55s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:38,260] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6192.2 vnc_pixels_ps[total]=45938.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:38,260] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"257.08us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"106.73us\", \"mean\": \"299.73us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.98us\", \"mean\": \"43.06us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"197.42us\", \"mean\": \"307.85us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"115.89us\", \"mean\": \"244.10us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.09us\", \"mean\": \"108.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"30.85us\", \"mean\": \"86.47us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.56us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910305}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 31.0, \"mean\": 31.0}} (export_time=113.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:38,260] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:39,376] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:40,460] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:41,759] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:42,843] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:43,276] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10908.2 vnc_pixels_ps[total]=45975.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:43,276] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.28ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.65ms\", \"mean\": \"2.03ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.16us\", \"mean\": \"36.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.28ms\", \"mean\": \"442.76us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"3.08ms\", \"mean\": \"7.86ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"107.92us\", \"mean\": \"209.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.06us\", \"mean\": \"97.18us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.57us\", \"mean\": \"77.09us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.14us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.3801311186847085, \"mean\": 1.7142857142857142}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.3173115192070467, \"mean\": 0.09634551495016612}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.070862978089297, \"value\": 39.0, \"mean\": 34.74074074074073}} (export_time=135.18us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:44,126] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:48,293] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6711.1 vnc_pixels_ps[total]=43793.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:48,293] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"438.17us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.26ms\", \"mean\": \"573.22us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.84us\", \"mean\": \"41.58us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"429.94us\", \"mean\": \"307.29us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.21ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"85.25us\", \"mean\": \"236.35us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.41us\", \"mean\": \"97.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.79us\", \"mean\": \"91.19us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.11us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.41485111699905175, \"value\": 44.0, \"mean\": 43.79166666666667}} (export_time=133.51us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:48,294] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.17s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1898 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *102 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *103 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *104 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *105 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *106 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *107 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *108 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *109 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *110 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:45:50 [info] 68#68: *111 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:51,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.65s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:53,226] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:53,311] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8467.7 vnc_pixels_ps[total]=45089.1 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:53,312] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"783.62us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.33ms\", \"mean\": \"1.05ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.91ms\", \"mean\": \"6.63ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"18.61us\", \"mean\": \"35.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"782.45us\", \"mean\": \"352.37us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"908.66us\", \"mean\": \"1.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"81.51us\", \"mean\": \"200.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.98us\", \"mean\": \"100.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"23.15us\", \"mean\": \"75.36us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.89us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.70801280154532, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.0863787375415282}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.760566590418968, \"value\": 46.0, \"mean\": 44.46153846153847}} (export_time=363.83us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:55,626] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.40s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2331 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:58,326] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7593.7 vnc_pixels_ps[total]=44584.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:58,327] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"666.43us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.93ms\", \"mean\": \"848.58us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.04us\", \"mean\": \"42.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"636.37us\", \"mean\": \"343.25us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.26ms\", \"mean\": \"6.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"121.26us\", \"mean\": \"238.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.25us\", \"mean\": \"99.88us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.80us\", \"mean\": \"85.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.78us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.2394482175782737, \"value\": 55.0, \"mean\": 53.833333333333336}} (export_time=147.10us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:45:58,327] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.70s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:03,343] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.6 vnc_pixels_ps[total]=44020.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:03,344] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"254.36us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"107.96us\", \"mean\": \"360.71us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.29us\", \"mean\": \"54.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"237.02us\", \"mean\": \"360.76us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"115.18us\", \"mean\": \"307.11us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.09us\", \"mean\": \"122.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.63us\", \"mean\": \"104.70us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.79us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 55.0, \"mean\": 55.0}} (export_time=280.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:03,345] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,993] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=404us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,993] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,994] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.65s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,994] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,994] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,994] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 19->20, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,995] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,995] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,995] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=20\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,995] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:04,996] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,010] init detected end of child process 7073 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,014] init detected end of child process 7088 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,016] init detected end of child process 7290 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,018] init detected end of child process 7297 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,031] init detected end of child process 7319 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:05,072] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:05,072] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:05,156] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:05 [info] 68#68: *99 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:05 [info] 68#68: *100 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:05 [info] 68#68: *101 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:05 [info] 68#68: *98 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,337] init detected end of child process 7076 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,337] init detected end of child process 7084 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,337] init detected end of child process 7085 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:05,338] init detected end of child process 7087 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,385] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,385] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,467] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,937] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,938] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,938] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,938] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,939] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:06,940] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:46:06 I0508 21:46:06.94016 7872 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:46:06 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::60454\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:46:06 I0508 21:46:06.946028 7872 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:07,058] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:11,092] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:11,759] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['317us', '169us', '146us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:11,760] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:11,761] [play_vexpect] vexpect macro complete in 4.786919s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:46:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::60454 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 13 rects, 395.426 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.275 KiB (1:10.3486 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 22 rects, 788.952 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09167 MiB (1:2.75711 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,031] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 20->20, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,032] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,032] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=19->20, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,033] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.04s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,033] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=45.0 episode_count=30 episode_duration=53.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,034] [INFO:universe.wrappers.logger] Stats for the past 8.69s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1775.1 vnc_pixels_ps[total]=9216.7 reward_lag=None rewarder_message_lag=None fps=11.51\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,044] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:12,044] [INFO:universe.pyprofile] [pyprofile] period=8.70s timers={\"rewarder.sleep\": {\"calls\": 99, \"std\": \"335.75us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.79ms\", \"mean\": \"1.22ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.94ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"25.99us\", \"mean\": \"46.37us\"}, \"rewarder.compute_reward\": {\"calls\": 100, \"std\": \"1.07ms\", \"mean\": \"495.93us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"32.87us\", \"mean\": \"61.83us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"147.02us\", \"mean\": \"335.57us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 100, \"std\": \"60.17us\", \"mean\": \"134.34us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"36.34us\", \"mean\": \"86.71us\"}, \"rewarder.frame\": {\"calls\": 100, \"std\": \"1.42ms\", \"mean\": \"16.64ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 100, \"std\": 2.011557515052363, \"mean\": 0.29}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 14.230249470757707, \"value\": 10, \"mean\": 50.5}} (export_time=163.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:16,750] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.72s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2066 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:17,049] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=8.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14902.8 vnc_pixels_ps[total]=79929.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:17,050] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"812.46us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.18ms\", \"mean\": \"587.05us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"36.67us\", \"mean\": \"57.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"423.55us\", \"mean\": \"370.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.82ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"166.35us\", \"mean\": \"323.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.75us\", \"mean\": \"118.15us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.16us\", \"mean\": \"99.49us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.29us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.20412414523193156, \"value\": 12.0, \"mean\": 11.041666666666666}} (export_time=110.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:18,050] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1887 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:22,067] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8440.9 vnc_pixels_ps[total]=45153.9 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:22,069] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.04ms\", \"mean\": \"1.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.33us\", \"mean\": \"56.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"464.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.52ms\", \"mean\": \"9.09ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"117.41us\", \"mean\": \"315.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.47us\", \"mean\": \"125.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"28.79us\", \"mean\": \"100.91us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.89us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.632993161855452, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662219, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.086446799501629, \"value\": 20.0, \"mean\": 17.384615384615383}} (export_time=496.63us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:22,070] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.02s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1914 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:25,633] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.56s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:27,083] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7625.1 vnc_pixels_ps[total]=44884.3 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:27,083] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.56ms\", \"mean\": \"1.43ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"47.35us\", \"mean\": \"68.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"466.69us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"150.04us\", \"mean\": \"12.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"182.26us\", \"mean\": \"373.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.88us\", \"mean\": \"125.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"19.88us\", \"mean\": \"109.87us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.27us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0049875621120885, \"value\": 23.0, \"mean\": 20.52}} (export_time=172.85us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:27,084] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1890 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:32,100] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.0 vnc_pixels_ps[total]=44177.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:32,101] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"282.30us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"63.79us\", \"mean\": \"434.49us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.95us\", \"mean\": \"69.28us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"271.70us\", \"mean\": \"412.88us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"96.70us\", \"mean\": \"388.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.86us\", \"mean\": \"135.37us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"16.81us\", \"mean\": \"122.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.03us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 23.0, \"mean\": 23.0}} (export_time=283.00us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:32,102] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:33,450] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.35s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:34,966] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:37,117] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9161.9 vnc_pixels_ps[total]=44644.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:37,118] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.06ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.06ms\", \"mean\": \"1.59ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"23.58us\", \"mean\": \"51.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"480.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.13ms\", \"mean\": \"8.24ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"112.36us\", \"mean\": \"291.25us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"56.18us\", \"mean\": \"121.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"32.14us\", \"mean\": \"101.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.48us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774083}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.2702083943651816, \"value\": 29.0, \"mean\": 25.33333333333334}} (export_time=257.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:37,119] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:42,133] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6234.2 vnc_pixels_ps[total]=46262.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:42,134] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"344.68us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"93.33us\", \"mean\": \"338.83us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.40us\", \"mean\": \"50.30us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"223.31us\", \"mean\": \"332.70us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"96.24us\", \"mean\": \"281.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.47us\", \"mean\": \"111.92us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.18us\", \"mean\": \"96.50us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.47us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 29.0, \"mean\": 29.0}} (export_time=155.21us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:42,134] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,749] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=253us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.62s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 20->21, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,750] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,751] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=21\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,751] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,751] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:43,763] init detected end of child process 7614 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:43,768] init detected end of child process 7629 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:43,769] init detected end of child process 7831 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:43,771] init detected end of child process 7838 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:43,790] init detected end of child process 7863 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,829] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,829] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:43,911] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:43 [info] 68#68: *113 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:43 [info] 68#68: *114 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:43 [info] 68#68: *115 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:43 [info] 68#68: *112 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:44,101] init detected end of child process 7617 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:44,101] init detected end of child process 7625 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:44,101] init detected end of child process 7626 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:44,101] init detected end of child process 7628 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:45,153] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:45,154] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:48,568] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,053] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,053] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,053] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,053] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,057] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,057] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:46:49 I0508 21:46:49.05803 8255 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:46:49 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::60666\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:46:49 I0508 21:46:49.059498 8255 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:49,176] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,510] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['200us', '95us', '86us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,511] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,511] [play_vexpect] vexpect macro complete in 2.419495s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:46:51 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::60666 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.874 KiB (1:15.7691 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 34 rects, 1.05933 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.03225 MiB (1:1.33281 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 48 rects, 1.14416 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.05283 MiB (1:1.42988 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,743] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 21->21, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,744] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,744] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=20->21, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,744] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,744] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=19.0 episode_count=18 episode_duration=39.71\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,745] [INFO:universe.wrappers.logger] Stats for the past 9.61s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1443.9 vnc_pixels_ps[total]=7131.0 reward_lag=None rewarder_message_lag=None fps=10.20\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,755] [INFO:gym_controlplane.reward.reward] First score parsed: score=16. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:51,755] [INFO:universe.pyprofile] [pyprofile] period=9.62s timers={\"rewarder.sleep\": {\"calls\": 97, \"std\": \"250.59us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 9, \"std\": \"2.90ms\", \"mean\": \"1.24ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.78ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 27, \"std\": \"20.42us\", \"mean\": \"34.03us\"}, \"rewarder.compute_reward\": {\"calls\": 98, \"std\": \"1.05ms\", \"mean\": \"370.00us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"24.68us\", \"mean\": \"48.48us\"}, \"reward.parsing.gameover\": {\"calls\": 9, \"std\": \"116.08us\", \"mean\": \"270.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 98, \"std\": \"33.13us\", \"mean\": \"88.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 9, \"std\": \"32.40us\", \"mean\": \"70.78us\"}, \"rewarder.frame\": {\"calls\": 98, \"std\": \"1.52ms\", \"mean\": \"16.61ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 98, \"std\": 2.532037513569681, \"mean\": 0.336734693877551}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 8, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 9, \"std\": 6.333333333333334, \"value\": 10, \"mean\": 26.88888888888889}} (export_time=170.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:53,578] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.83s, sent 3 reward messages to agent: reward=14.0 reward_min=4 reward_max=6 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2080 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:56,761] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18249.8 vnc_pixels_ps[total]=85877.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:56,761] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"943.53us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.09ms\", \"mean\": \"984.65us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"12.31us\", \"mean\": \"33.68us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"672.61us\", \"mean\": \"323.68us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.39ms\", \"mean\": \"5.98ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"52.17us\", \"mean\": \"190.91us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.05us\", \"mean\": \"98.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"14.56us\", \"mean\": \"66.72us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.27us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.0615528128088303, \"mean\": 3.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 3.0783841987903866, \"value\": 25.0, \"mean\": 22.541666666666668}} (export_time=94.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:56,762] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.18s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,511] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=212us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,511] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,511] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,511] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 21->22, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=22\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,512] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,513] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,524] init detected end of child process 7980 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,529] init detected end of child process 7995 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,531] init detected end of child process 8202 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,532] init detected end of child process 8197 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,553] init detected end of child process 8223 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:46:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,587] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,588] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:58 [info] 68#68: *117 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:58 [info] 68#68: *118 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:58 [info] 68#68: *119 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:46:58 [info] 68#68: *116 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:58,679] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,893] init detected end of child process 7983 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,893] init detected end of child process 7991 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,893] init detected end of child process 7992 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:46:58,893] init detected end of child process 7994 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:59,944] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:46:59,945] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:03,792] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,302] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,302] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,303] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'fine_quality_level': 50, 'subsample_level': 2, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,303] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,305] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,305] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:47:04 I0508 21:47:04.305327 8614 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:47:04 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::60860\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:47:04 I0508 21:47:04.306684 8614 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:04,430] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,481] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,747] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['164us', '146us', '64us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,748] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,748] [play_vexpect] vexpect macro complete in 4.409432s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:47:08 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::60860 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 11 rects, 92.114 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  22.5947 KiB (1:15.9307 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 25 rects, 934.06 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.67359 MiB (1:1.33283 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 43 rects, 1.03821 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.69732 MiB (1:1.46848 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,998] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 22->22, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,999] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,999] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=21->22, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:08,999] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.49s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:09,000] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=15.0 episode_count=6 episode_duration=17.26\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:09,001] [INFO:universe.wrappers.logger] Stats for the past 12.24s: vnc_updates_ps=0.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1235.3 vnc_pixels_ps[total]=6351.5 reward_lag=None rewarder_message_lag=None fps=8.66\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:09,011] [INFO:gym_controlplane.reward.reward] First score parsed: score=20. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:09,011] [INFO:universe.pyprofile] [pyprofile] period=12.25s timers={\"rewarder.sleep\": {\"calls\": 105, \"std\": \"156.63us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.74ms\", \"mean\": \"1.08ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.69ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"9.36us\", \"mean\": \"21.93us\"}, \"rewarder.compute_reward\": {\"calls\": 106, \"std\": \"1.03ms\", \"mean\": \"351.76us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.88us\", \"mean\": \"34.33us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"81.98us\", \"mean\": \"177.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 106, \"std\": \"44.56us\", \"mean\": \"98.78us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"23.36us\", \"mean\": \"58.22us\"}, \"rewarder.frame\": {\"calls\": 106, \"std\": \"1.47ms\", \"mean\": \"16.62ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 106, \"std\": 3.693185974400617, \"mean\": 0.4433962264150943}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 4.743416490252569, \"value\": 10, \"mean\": 23.5}} (export_time=116.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:10,517] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=13.0 reward_min=1.0 reward_max=10 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2080 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:11,816] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:14,017] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=13.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29025.6 vnc_pixels_ps[total]=106934.0 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:14,018] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.74ms\", \"mean\": \"15.88ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.51ms\", \"mean\": \"2.29ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"25.85us\", \"mean\": \"52.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.60ms\", \"mean\": \"567.26us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"3.56ms\", \"mean\": \"11.14ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"132.79us\", \"mean\": \"292.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.93us\", \"mean\": \"121.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"35.99us\", \"mean\": \"106.83us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.80us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 3.6147844564602556, \"mean\": 2.6666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.295555860859078, \"mean\": 0.09634551495016613}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 2.260171317452828, \"value\": 26.0, \"mean\": 23.413793103448278}} (export_time=223.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:14,018] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.20s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,033] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5937.5 vnc_pixels_ps[total]=44010.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,033] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"256.06us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"134.30us\", \"mean\": \"281.28us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"27.47us\", \"mean\": \"41.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"206.07us\", \"mean\": \"304.71us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"163.96us\", \"mean\": \"243.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.52us\", \"mean\": \"102.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"36.51us\", \"mean\": \"82.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.58us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 26.0, \"mean\": 26.0}} (export_time=96.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,034] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,751] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=869us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,752] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,752] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,753] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,753] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 22->23, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,753] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,753] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,754] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=23\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,754] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,755] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:19,776] init detected end of child process 8331 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:19,784] init detected end of child process 8346 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:19,787] init detected end of child process 8548 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:19,790] init detected end of child process 8555 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:19,802] init detected end of child process 8577 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,848] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,848] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:19 [info] 68#68: *121 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:19 [info] 68#68: *122 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:19 [info] 68#68: *123 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:19 [info] 68#68: *120 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:19,937] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:20,161] init detected end of child process 8334 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:20,161] init detected end of child process 8342 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:20,161] init detected end of child process 8343 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:20,161] init detected end of child process 8345 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,205] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,206] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,240] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,759] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,759] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,759] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,759] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,761] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,761] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:47:21 I0508 21:47:21.761669 8944 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:47:21 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::32788\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:47:21 I0508 21:47:21.763017 8944 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:21,891] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:25,958] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:27,824] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['187us', '124us', '78us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:27,825] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:27,825] [play_vexpect] vexpect macro complete in 6.021898s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:47:27 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::32788 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.237 KiB (1:10.3187 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27232 MiB (1:2.37071 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,062] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 23->23, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,062] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,063] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=22->23, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,063] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.03s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,063] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=16.0 episode_count=9 episode_duration=19.06\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,064] [INFO:universe.wrappers.logger] Stats for the past 9.03s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=980.2 vnc_pixels_ps[total]=3465.2 reward_lag=None rewarder_message_lag=None fps=4.87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,073] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:28,073] [INFO:universe.pyprofile] [pyprofile] period=9.04s timers={\"rewarder.sleep\": {\"calls\": 43, \"std\": \"276.21us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.43ms\", \"mean\": \"1.93ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.84ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"25.72us\", \"mean\": \"42.84us\"}, \"rewarder.compute_reward\": {\"calls\": 44, \"std\": \"1.47ms\", \"mean\": \"589.24us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"56.80us\", \"mean\": \"79.75us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"439.90us\", \"mean\": \"467.06us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 44, \"std\": \"50.99us\", \"mean\": \"111.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"54.87us\", \"mean\": \"89.69us\"}, \"rewarder.frame\": {\"calls\": 44, \"std\": \"1.89ms\", \"mean\": \"16.48ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 44, \"std\": 3.7660860061205224, \"mean\": 0.6590909090909092}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 7.155417527999327, \"value\": 10, \"mean\": 22.8}} (export_time=111.10us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:29,680] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.62s, sent 5 reward messages to agent: reward=6.0 reward_min=-1.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2081 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:30,980] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:32,513] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:33,080] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21742.8 vnc_pixels_ps[total]=88673.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:33,080] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.72ms\", \"mean\": \"1.61ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"15.08us\", \"mean\": \"33.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"990.91us\", \"mean\": \"376.58us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"924.70us\", \"mean\": \"6.55ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"72.93us\", \"mean\": \"190.52us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"34.84us\", \"mean\": \"83.30us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"25.91us\", \"mean\": \"75.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.06us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 9, \"std\": 1.2360330811826106, \"mean\": 1.5555555555555556}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.295555860859078, \"mean\": 0.0963455149501661}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 3.985194273685387, \"value\": 24.0, \"mean\": 17.896551724137925}} (export_time=152.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:34,463] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1929 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:35,547] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:37,280] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:38,097] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10035.1 vnc_pixels_ps[total]=45311.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:38,097] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.07ms\", \"mean\": \"1.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"11.94us\", \"mean\": \"33.07us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"356.26us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.38ms\", \"mean\": \"7.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"45.19us\", \"mean\": \"188.57us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"22.09us\", \"mean\": \"72.99us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"13.20us\", \"mean\": \"64.77us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.91us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.0488088481701516, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006217, \"mean\": 0.09302325581395349}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.77460135846804, \"value\": 32.0, \"mean\": 27.92857142857143}} (export_time=108.48us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:39,913] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.63s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:41,863] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:43,114] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7629.4 vnc_pixels_ps[total]=44962.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:43,115] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.73ms\", \"mean\": \"1.05ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"11.33us\", \"mean\": \"38.33us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"917.61us\", \"mean\": \"352.45us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.59ms\", \"mean\": \"9.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"44.50us\", \"mean\": \"218.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"314.26us\", \"mean\": \"105.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"14.70us\", \"mean\": \"81.98us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"573.14us\", \"mean\": \"16.85ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.7078251276599272, \"value\": 37.0, \"mean\": 35.000000000000014}} (export_time=269.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:43,116] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.25s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:48,130] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.7 vnc_pixels_ps[total]=44344.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:48,131] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"301.11us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"109.82us\", \"mean\": \"340.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.28us\", \"mean\": \"51.19us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"219.78us\", \"mean\": \"315.47us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"115.86us\", \"mean\": \"290.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.39us\", \"mean\": \"102.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.36us\", \"mean\": \"100.70us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.71us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=150.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:48,131] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:49,231] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:50,261] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:53,147] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8421.3 vnc_pixels_ps[total]=45000.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:53,148] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"985.20us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.86ms\", \"mean\": \"1.20ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"23.46us\", \"mean\": \"43.75us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"956.39us\", \"mean\": \"382.50us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.73ms\", \"mean\": \"7.91ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"117.80us\", \"mean\": \"250.42us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.26us\", \"mean\": \"100.61us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"38.25us\", \"mean\": \"91.79us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.71us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.0897009966777409}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.2954005859434679, \"value\": 40.0, \"mean\": 38.7037037037037}} (export_time=115.63us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:53,148] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.89s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:54,213] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.06s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:55,763] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:57,147] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,163] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10915.2 vnc_pixels_ps[total]=45949.4 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,164] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"878.41us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.26ms\", \"mean\": \"1.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"18.21us\", \"mean\": \"31.64us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"827.12us\", \"mean\": \"360.19us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"389.79us\", \"mean\": \"5.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"80.54us\", \"mean\": \"178.62us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.13us\", \"mean\": \"90.14us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"21.56us\", \"mean\": \"67.41us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.57us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.3972762620115438, \"mean\": 1.5714285714285714}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006217, \"mean\": 0.09302325581395346}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 3.4233867324006386, \"value\": 51.0, \"mean\": 46.64285714285714}} (export_time=124.45us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,164] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,930] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=288us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,930] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 23->24, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,931] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=24\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,932] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:58,932] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:58,945] init detected end of child process 8696 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:58,950] init detected end of child process 8711 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:58,950] init detected end of child process 8919 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:58,957] init detected end of child process 8913 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:58,968] init detected end of child process 8941 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:47:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:59,002] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:59,002] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:47:59,084] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:59 [info] 68#68: *125 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:59 [info] 68#68: *126 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:59 [info] 68#68: *127 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:47:59 [info] 68#68: *124 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:59,285] init detected end of child process 8699 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:59,285] init detected end of child process 8707 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:59,285] init detected end of child process 8708 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:47:59,285] init detected end of child process 8710 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,336] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,337] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,413] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,894] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,894] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,894] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,894] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,903] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:00,903] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:48:00 I0508 21:48:00.903308 9323 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:48:00 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::33138\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:48:00 I0508 21:48:00.90506 9323 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:01,020] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:05,070] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,754] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['332us', '178us', '159us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,755] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,755] [play_vexpect] vexpect macro complete in 5.818729s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:48:06 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::33138 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.039 KiB (1:10.3256 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27213 MiB (1:2.3703 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,995] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 24->24, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,996] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,996] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=23->24, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,997] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.83s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,997] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=41.0 episode_count=32 episode_duration=38.93\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:06,998] [INFO:universe.wrappers.logger] Stats for the past 8.83s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1001.9 vnc_pixels_ps[total]=3542.1 reward_lag=None rewarder_message_lag=None fps=5.32\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:07,007] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:07,007] [INFO:universe.pyprofile] [pyprofile] period=8.84s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"182.53us\", \"mean\": \"16.31ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.62ms\", \"mean\": \"1.82ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"8.52us\", \"mean\": \"18.49us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"1.40ms\", \"mean\": \"425.99us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.02us\", \"mean\": \"38.98us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"160.21us\", \"mean\": \"223.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"41.74us\", \"mean\": \"88.89us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"24.32us\", \"mean\": \"49.07us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.18ms\", \"mean\": \"16.44ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 3.4994383056619442, \"mean\": 0.5957446808510639}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 18.335757415498275, \"value\": 10, \"mean\": 42.8}} (export_time=105.14us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:08,565] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.57s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2081 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:12,014] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17839.4 vnc_pixels_ps[total]=88917.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:12,015] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.62ms\", \"mean\": \"1.42ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.43us\", \"mean\": \"58.38us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"445.33us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.48ms\", \"mean\": \"12.58ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"114.01us\", \"mean\": \"328.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.62us\", \"mean\": \"121.63us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.96us\", \"mean\": \"113.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.94us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9168313422570858, \"value\": 12.0, \"mean\": 11.166666666666666}} (export_time=228.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:12,015] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.45s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=368us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,764] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 24->25, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,765] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,765] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,765] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=25\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,765] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,765] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:16,776] init detected end of child process 9065 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:16,779] init detected end of child process 9080 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:16,781] init detected end of child process 9282 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:16,784] init detected end of child process 9289 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:16,796] init detected end of child process 9314 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:48:16 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:48:16 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:48:16 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,843] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,843] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:48:16 [info] 68#68: *129 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:48:16 [info] 68#68: *130 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:48:16 [info] 68#68: *131 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:48:16 [info] 68#68: *128 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:16,929] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:17,117] init detected end of child process 9068 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:17,117] init detected end of child process 9076 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:17,117] init detected end of child process 9077 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:48:17,117] init detected end of child process 9079 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:18,158] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:18,159] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,112] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,578] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,578] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,578] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,578] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,586] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,586] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:48:22 I0508 21:48:22.587035 9713 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:48:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::33308\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:48:22 I0508 21:48:22.594016 9713 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:22,709] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,609] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['171us', '69us', '58us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,609] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,610] [play_vexpect] vexpect macro complete in 1.989122s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:48:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::33308 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 6 rects, 3.068 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            192 B (1:64.2917 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 13.585 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.85352 KiB (1:28.6491 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 5 rects, 67.522 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.4814 KiB (1:15.0912 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 24 rects, 949.968 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.71909 MiB (1:1.33284 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 38 rects, 1.03414 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.73815 MiB (1:1.44089 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,872] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 25->25, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,872] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,872] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=24->25, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,873] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.11s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,873] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=2.0 episode_count=5 episode_duration=17.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,874] [INFO:universe.wrappers.logger] Stats for the past 12.86s: vnc_updates_ps=1.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2612.9 vnc_pixels_ps[total]=16714.4 reward_lag=None rewarder_message_lag=None fps=22.24\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,885] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:24,885] [INFO:universe.pyprofile] [pyprofile] period=12.87s timers={\"rewarder.sleep\": {\"calls\": 285, \"std\": \"250.55us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.99ms\", \"mean\": \"680.49us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.85ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"26.10us\", \"mean\": \"35.78us\"}, \"rewarder.compute_reward\": {\"calls\": 286, \"std\": \"696.43us\", \"mean\": \"321.27us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.15us\", \"mean\": \"49.55us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"157.15us\", \"mean\": \"234.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 286, \"std\": \"39.68us\", \"mean\": \"97.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.88us\", \"mean\": \"80.14us\"}, \"rewarder.frame\": {\"calls\": 286, \"std\": \"876.74us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 286, \"std\": 1.9069798634831188, \"mean\": 0.19230769230769235}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.40824829046386296, \"value\": 10, \"mean\": 11.916666666666666}} (export_time=154.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:27,323] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.45s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2102 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:29,890] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25338.8 vnc_pixels_ps[total]=89207.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:29,904] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"831.92us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.66ms\", \"mean\": \"966.87us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"14.47us\", \"mean\": \"33.85us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"878.58us\", \"mean\": \"331.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.48ms\", \"mean\": \"8.89ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"72.67us\", \"mean\": \"192.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.10us\", \"mean\": \"98.51us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"24.00us\", \"mean\": \"76.11us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.49us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531558}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5099019513592791, \"value\": 11.0, \"mean\": 10.479999999999999}} (export_time=192.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:29,904] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.58s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1924 bytes>', 'rewarder.vnc.updates.pixels': 1368}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:31,007] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:34,907] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8465.4 vnc_pixels_ps[total]=45337.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:34,907] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.01ms\", \"mean\": \"789.72us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"17.06us\", \"mean\": \"32.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"655.09us\", \"mean\": \"311.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.51ms\", \"mean\": \"7.23ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"59.59us\", \"mean\": \"179.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.97us\", \"mean\": \"95.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"14.59us\", \"mean\": \"66.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.14us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.1045361017187263, \"value\": 15.0, \"mean\": 14.499999999999998}} (export_time=93.46us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:34,908] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.90s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1928 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:37,573] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.67s, sent 3 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:38,940] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:39,923] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=11487.7 vnc_pixels_ps[total]=44339.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:39,930] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"883.10us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.53ms\", \"mean\": \"1.75ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"10.44us\", \"mean\": \"26.99us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"973.80us\", \"mean\": \"399.95us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 8, \"std\": \"486.30us\", \"mean\": \"5.52ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"41.67us\", \"mean\": \"152.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.60us\", \"mean\": \"105.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"21.42us\", \"mean\": \"59.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.51us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 8, \"std\": 3.7961446607992015, \"mean\": 3.125}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29555586085907787, \"mean\": 0.09634551495016612}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 4.737961150333439, \"value\": 40.0, \"mean\": 23.344827586206897}} (export_time=76.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:40,157] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 3 reward messages to agent: reward=43.0 reward_min=12.0 reward_max=19.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1924 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:41,229] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 5 reward messages to agent: reward=78.0 reward_min=15.0 reward_max=16.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:44,906] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 5 reward messages to agent: reward=55.0 reward_min=1.0 reward_max=16.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:44,940] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=6.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=15016.5 vnc_pixels_ps[total]=47265.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:44,940] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.17ms\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 32, \"std\": \"2.62ms\", \"mean\": \"1.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 96, \"std\": \"9.57us\", \"mean\": \"27.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"420.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 10, \"std\": \"225.59us\", \"mean\": \"5.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 32, \"std\": \"30.05us\", \"mean\": \"152.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.07us\", \"mean\": \"90.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 32, \"std\": \"10.09us\", \"mean\": \"57.26us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.96us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 12, \"std\": 5.104958967573203, \"mean\": 13.666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.3087502045587354, \"mean\": 0.10631229235880404}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 96, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 32, \"std\": 51.369471290301995, \"value\": 203.0, \"mean\": 158.62500000000003}} (export_time=135.42us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:45,974] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 3 reward messages to agent: reward=26.0 reward_min=0 reward_max=17.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1940 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:49,956] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10081.1 vnc_pixels_ps[total]=45528.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:49,957] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.99ms\", \"mean\": \"1.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.87us\", \"mean\": \"32.07us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.00ms\", \"mean\": \"363.77us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.88ms\", \"mean\": \"6.76ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"64.89us\", \"mean\": \"181.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.72us\", \"mean\": \"93.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"19.97us\", \"mean\": \"66.87us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.79us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 6.7946057035465035, \"mean\": 11.166666666666668}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2976467318242718, \"mean\": 0.08970099667774091}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 29.674982988783942, \"value\": 271.0, \"mean\": 247.26923076923077}} (export_time=94.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:49,957] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.98s, sent 4 reward messages to agent: reward=41.0 reward_min=0 reward_max=17.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:52,690] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.73s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:54,973] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7248.8 vnc_pixels_ps[total]=43775.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:54,973] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"503.65us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.48ms\", \"mean\": \"706.90us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"14.86us\", \"mean\": \"38.28us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"497.52us\", \"mean\": \"300.34us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"194.72us\", \"mean\": \"5.32ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"73.04us\", \"mean\": \"216.57us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.30us\", \"mean\": \"94.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"21.88us\", \"mean\": \"80.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.83us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0132456102380345, \"value\": 273.0, \"mean\": 271.88000000000005}} (export_time=83.45us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:54,974] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.28s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:59,107] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.13s, sent 2 reward messages to agent: reward=12.0 reward_min=1.0 reward_max=11.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:59,990] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10685.4 vnc_pixels_ps[total]=44138.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:48:59,990] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"804.40us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.24ms\", \"mean\": \"1.39ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"7.99us\", \"mean\": \"26.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"800.57us\", \"mean\": \"329.56us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"76.26us\", \"mean\": \"5.26ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"24.96us\", \"mean\": \"148.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.41us\", \"mean\": \"89.40us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"12.73us\", \"mean\": \"59.97us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.52us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 11.503622617824933, \"mean\": 13.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 25.40599117264246, \"value\": 364.0, \"mean\": 286.1851851851852}} (export_time=74.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:00,206] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 6 reward messages to agent: reward=91.0 reward_min=0.0 reward_max=34.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:01,395] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.19s, sent 3 reward messages to agent: reward=57.0 reward_min=17.0 reward_max=22.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:02,773] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 5 reward messages to agent: reward=62.0 reward_min=2.0 reward_max=18.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:04,073] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=12.0 reward_min=3.0 reward_max=9.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:05,007] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=6.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14970.3 vnc_pixels_ps[total]=47149.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:05,007] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 32, \"std\": \"2.54ms\", \"mean\": \"2.01ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 96, \"std\": \"7.84us\", \"mean\": \"24.87us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.06ms\", \"mean\": \"427.66us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 11, \"std\": \"222.11us\", \"mean\": \"5.23ms\"}, \"reward.parsing.gameover\": {\"calls\": 32, \"std\": \"22.38us\", \"mean\": \"139.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.00us\", \"mean\": \"98.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 32, \"std\": \"10.80us\", \"mean\": \"53.50us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.02us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 13, \"std\": 7.679476477883045, \"mean\": 11.153846153846155}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.3087502045587353, \"mean\": 0.106312292358804}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 96, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 32, \"std\": 51.68636027724988, \"value\": 509.0, \"mean\": 455.9375}} (export_time=132.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,640] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=526us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,641] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,641] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.57s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1927 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,641] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,641] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 25->26, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=26\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,642] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,655] init detected end of child process 9432 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,659] init detected end of child process 9447 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,661] init detected end of child process 9649 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,663] init detected end of child process 9656 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,681] init detected end of child process 9678 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,717] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,717] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:08,805] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:08 [info] 68#68: *133 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:08 [info] 68#68: *134 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:08 [info] 68#68: *135 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:08 [info] 68#68: *132 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,973] init detected end of child process 9435 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,973] init detected end of child process 9443 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,973] init detected end of child process 9444 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:08,973] init detected end of child process 9446 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:10,056] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:10,057] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,464] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,943] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,944] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,944] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'subsample_level': 2, 'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,944] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,953] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:13,953] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:49:13 I0508 21:49:13.953981 10242 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:49:13 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::33518\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:49:13 I0508 21:49:13.955486 10242 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:14,072] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,407] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['269us', '149us', '134us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,407] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,408] [play_vexpect] vexpect macro complete in 2.420094s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:49:16 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::33518 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 8.713 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.19531 KiB (1:28.5033 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3721 KiB (1:15.3392 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 36 rects, 1.09619 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.13779 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 51 rects, 1.18146 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.15801 MiB (1:1.42732 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,646] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 26->26, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,646] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,646] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=25->26, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,646] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.01s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,647] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=499.0 episode_count=55 episode_duration=51.77\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,648] [INFO:universe.wrappers.logger] Stats for the past 11.64s: vnc_updates_ps=1.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2225.0 vnc_pixels_ps[total]=13486.8 reward_lag=None rewarder_message_lag=None fps=18.81\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,661] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:16,661] [INFO:universe.pyprofile] [pyprofile] period=11.65s timers={\"rewarder.sleep\": {\"calls\": 218, \"std\": \"147.37us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 18, \"std\": \"2.82ms\", \"mean\": \"898.80us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 54, \"std\": \"15.19us\", \"mean\": \"29.06us\"}, \"rewarder.compute_reward\": {\"calls\": 219, \"std\": \"929.10us\", \"mean\": \"298.06us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"32.37us\", \"mean\": \"62.66us\"}, \"reward.parsing.gameover\": {\"calls\": 18, \"std\": \"160.14us\", \"mean\": \"215.52us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 219, \"std\": \"41.12us\", \"mean\": \"93.72us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 18, \"std\": \"26.29us\", \"mean\": \"64.65us\"}, \"rewarder.frame\": {\"calls\": 219, \"std\": \"959.87us\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 219, \"std\": 1.5719649130111841, \"mean\": 0.18264840182648406}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 48, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 17, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 18, \"std\": 117.6154279373624, \"value\": 10, \"mean\": 481.27777777777777}} (export_time=164.75us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:18,030] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 3 reward messages to agent: reward=8.0 reward_min=2.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2099 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:20 [info] 68#68: *137 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:20 [info] 68#68: *138 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:20 [info] 68#68: *139 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:21,664] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17359.3 vnc_pixels_ps[total]=85103.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:21,665] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.56ms\", \"mean\": \"723.78us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.67us\", \"mean\": \"34.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"511.44us\", \"mean\": \"316.30us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"356.39us\", \"mean\": \"5.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"105.49us\", \"mean\": \"202.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.22us\", \"mean\": \"100.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.61us\", \"mean\": \"79.05us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"122.79us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896257, \"mean\": 2.6666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.529895326532154, \"value\": 18.0, \"mean\": 17.083333333333336}} (export_time=193.60us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:21,665] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,414] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=222us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,414] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,414] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.75s, sent 2 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=2.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,414] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,414] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,415] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 26->27, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,415] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,415] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,415] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=27\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,415] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,416] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,427] init detected end of child process 9974 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,436] init detected end of child process 9989 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,437] init detected end of child process 10196 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,437] init detected end of child process 10191 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,449] init detected end of child process 10218 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:49:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,492] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,493] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:49:25 [info] 68#68: *136 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:25,582] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,777] init detected end of child process 9977 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,777] init detected end of child process 9985 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,777] init detected end of child process 9986 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:49:25,777] init detected end of child process 9988 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:26,860] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:26,861] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:26,928] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,427] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,427] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,427] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,427] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,437] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,437] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:49:27 I0508 21:49:27.437756 10587 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:49:27 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::33626\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:49:27 I0508 21:49:27.439316 10587 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:27,554] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:31,587] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,254] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['237us', '96us', '58us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,255] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,255] [play_vexpect] vexpect macro complete in 7.783656s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:49:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::33626 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.188 KiB (1:10.3221 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09265 MiB (1:2.76054 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,533] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 27->27, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,533] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,533] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=26->27, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,534] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.12s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,534] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=10.0 episode_count=6 episode_duration=18.89\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,535] [INFO:universe.wrappers.logger] Stats for the past 13.87s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2346.1 vnc_pixels_ps[total]=12823.3 reward_lag=None rewarder_message_lag=None fps=16.29\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,545] [INFO:gym_controlplane.reward.reward] First score parsed: score=21. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:35,545] [INFO:universe.pyprofile] [pyprofile] period=13.88s timers={\"rewarder.sleep\": {\"calls\": 225, \"std\": \"549.42us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 21, \"std\": \"2.39ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.67ms\", \"mean\": \"7.93ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 63, \"std\": \"24.46us\", \"mean\": \"42.26us\"}, \"rewarder.compute_reward\": {\"calls\": 226, \"std\": \"883.80us\", \"mean\": \"358.20us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.23us\", \"mean\": \"38.27us\"}, \"reward.parsing.gameover\": {\"calls\": 21, \"std\": \"126.20us\", \"mean\": \"270.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 226, \"std\": \"39.48us\", \"mean\": \"92.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 21, \"std\": \"35.70us\", \"mean\": \"85.71us\"}, \"rewarder.frame\": {\"calls\": 226, \"std\": \"977.37us\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 0.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 226, \"std\": 2.670056842058425, \"mean\": 0.26548672566371684}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 57, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 19, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 21, \"std\": 2.2424476423255535, \"value\": 10, \"mean\": 19.142857142857146}} (export_time=149.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:37,684] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 4 reward messages to agent: reward=18.0 reward_min=2 reward_max=11 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2168 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:39,434] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:40,551] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=13.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29109.5 vnc_pixels_ps[total]=108951.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:40,552] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.57ms\", \"mean\": \"1.35ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"9.93us\", \"mean\": \"28.16us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"898.73us\", \"mean\": \"346.96us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.99ms\", \"mean\": \"6.27ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"43.41us\", \"mean\": \"159.89us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.55us\", \"mean\": \"88.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"18.46us\", \"mean\": \"66.43us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.45us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 3.8297084310253524, \"mean\": 3.333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.0930232558139535}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.5881291888954654, \"value\": 30.0, \"mean\": 26.57142857142857}} (export_time=221.73us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:40,553] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:41,834] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:43,117] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:44,417] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:45,568] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10269.2 vnc_pixels_ps[total]=45237.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:45,568] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"832.32us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.26ms\", \"mean\": \"1.36ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"9.12us\", \"mean\": \"26.70us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"819.04us\", \"mean\": \"327.95us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"465.97us\", \"mean\": \"5.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"37.15us\", \"mean\": \"152.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.14us\", \"mean\": \"79.30us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"16.49us\", \"mean\": \"62.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.37us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 0.9759000729485332, \"mean\": 1.4285714285714286}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.0930232558139535}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.6095064302514706, \"value\": 40.0, \"mean\": 34.928571428571445}} (export_time=252.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:45,569] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:48,751] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.18s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:49,834] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:50,584] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8428.1 vnc_pixels_ps[total]=44972.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:50,585] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"565.16us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.66ms\", \"mean\": \"803.65us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"8.47us\", \"mean\": \"26.61us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"552.43us\", \"mean\": \"281.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"156.62us\", \"mean\": \"5.08ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"40.48us\", \"mean\": \"153.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.04us\", \"mean\": \"88.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"13.68us\", \"mean\": \"61.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.48us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.9190295885418385, \"value\": 43.0, \"mean\": 41.269230769230774}} (export_time=176.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:55,467] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.63s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1908 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:55,601] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6817.7 vnc_pixels_ps[total]=44769.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:55,601] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"707.83us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.32ms\", \"mean\": \"718.57us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.71us\", \"mean\": \"31.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"702.03us\", \"mean\": \"285.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.16ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"91.28us\", \"mean\": \"181.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.24us\", \"mean\": \"87.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.12us\", \"mean\": \"71.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.39us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 43.0, \"mean\": 43.0}} (export_time=156.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:56,767] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1869 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:49:58,284] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:00,617] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8377.5 vnc_pixels_ps[total]=44582.8 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:00,618] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"783.43us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.37ms\", \"mean\": \"1.05ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.71us\", \"mean\": \"31.33us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"778.44us\", \"mean\": \"330.16us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.90ms\", \"mean\": \"6.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"61.17us\", \"mean\": \"176.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.56us\", \"mean\": \"98.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"16.08us\", \"mean\": \"67.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.54us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.70801280154532, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662217, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.624064866120112, \"value\": 53.0, \"mean\": 48.57692307692307}} (export_time=115.63us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:00,618] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.33s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1916 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:04,567] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.95s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:05,634] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.5 vnc_pixels_ps[total]=44291.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:05,634] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"368.51us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.12ms\", \"mean\": \"455.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"11.39us\", \"mean\": \"29.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"361.67us\", \"mean\": \"240.85us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.44ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"53.53us\", \"mean\": \"167.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.06us\", \"mean\": \"81.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.35us\", \"mean\": \"66.55us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.41us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.38069349381344, \"value\": 54.0, \"mean\": 53.166666666666664}} (export_time=103.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:05,635] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:10,435] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.80s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:10,651] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7867.0 vnc_pixels_ps[total]=46598.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:10,652] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"505.39us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.45ms\", \"mean\": \"687.05us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"15.19us\", \"mean\": \"38.72us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"499.63us\", \"mean\": \"303.03us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"717.17us\", \"mean\": \"5.30ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"75.56us\", \"mean\": \"218.71us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.16us\", \"mean\": \"90.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.75us\", \"mean\": \"78.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.96us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.46409548089225505, \"value\": 56.0, \"mean\": 54.846153846153854}} (export_time=188.35us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:15,401] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.97s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1942 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:15,668] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6764.0 vnc_pixels_ps[total]=44143.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:15,669] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"349.86us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.00ms\", \"mean\": \"445.09us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"9.69us\", \"mean\": \"29.67us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"332.01us\", \"mean\": \"260.83us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"4.82ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"46.51us\", \"mean\": \"168.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.37us\", \"mean\": \"89.29us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"19.63us\", \"mean\": \"69.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.23us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.20851441405707502, \"value\": 57.0, \"mean\": 56.04347826086956}} (export_time=275.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,234] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=213us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,234] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,234] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.83s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1907 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 27->28, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=28\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,235] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,236] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,251] init detected end of child process 10330 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,255] init detected end of child process 10345 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,256] init detected end of child process 10547 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,258] init detected end of child process 10553 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,273] init detected end of child process 10575 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,313] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,313] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:18 [info] 68#68: *141 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:18 [info] 68#68: *142 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:18 [info] 68#68: *143 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:18 [info] 68#68: *140 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:18,405] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,577] init detected end of child process 10333 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,577] init detected end of child process 10341 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,577] init detected end of child process 10342 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:18,577] init detected end of child process 10344 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:19,710] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.30s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:19,711] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,209] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,692] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,693] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,693] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,693] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,695] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,695] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:50:23 I0508 21:50:23.695356 11141 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:50:23 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::33866\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:50:23 I0508 21:50:23.704964 11141 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:23,821] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:27,871] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,188] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['169us', '65us', '55us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,189] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,189] [play_vexpect] vexpect macro complete in 4.460043s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:50:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::33866 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9395 KiB (1:15.7198 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 34 rects, 1.06752 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.05569 MiB (1:1.33281 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 48 rects, 1.15235 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.07633 MiB (1:1.42911 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,385] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 28->28, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,385] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,386] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=27->28, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,386] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.15s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,386] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=47.0 episode_count=32 episode_duration=52.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,387] [INFO:universe.wrappers.logger] Stats for the past 12.72s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1628.0 vnc_pixels_ps[total]=9379.6 reward_lag=None rewarder_message_lag=None fps=12.19\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,396] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:28,396] [INFO:universe.pyprofile] [pyprofile] period=12.73s timers={\"rewarder.sleep\": {\"calls\": 154, \"std\": \"237.43us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.19ms\", \"mean\": \"808.02us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"10.13us\", \"mean\": \"26.56us\"}, \"rewarder.compute_reward\": {\"calls\": 155, \"std\": \"797.83us\", \"mean\": \"318.31us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.78us\", \"mean\": \"40.41us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"70.96us\", \"mean\": \"192.86us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 155, \"std\": \"46.94us\", \"mean\": \"95.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"20.23us\", \"mean\": \"62.43us\"}, \"rewarder.frame\": {\"calls\": 155, \"std\": \"1.23ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 155, \"std\": 2.7383144724408575, \"mean\": 0.3032258064516129}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 12.561278369883945, \"value\": 10, \"mean\": 53.642857142857146}} (export_time=150.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:31,053] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.67s, sent 3 reward messages to agent: reward=7.0 reward_min=2.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:33,404] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20448.2 vnc_pixels_ps[total]=102491.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:33,405] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"875.55us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.90ms\", \"mean\": \"830.73us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"18.51us\", \"mean\": \"40.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"629.15us\", \"mean\": \"335.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.37ms\", \"mean\": \"6.79ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"93.54us\", \"mean\": \"226.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.22us\", \"mean\": \"101.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.36us\", \"mean\": \"83.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.88us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.6000000000000005, \"value\": 17.0, \"mean\": 15.319999999999999}} (export_time=256.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:33,406] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.35s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,204] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=555us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,204] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,205] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,205] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,205] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 28->29, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,205] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,206] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,206] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=29\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,208] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,209] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,227] init detected end of child process 10873 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,234] init detected end of child process 10888 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,235] init detected end of child process 11090 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,238] init detected end of child process 11095 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,253] init detected end of child process 11117 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:50:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,289] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,289] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:34 [info] 68#68: *145 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:34 [info] 68#68: *146 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:34 [info] 68#68: *147 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:34 [info] 68#68: *144 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:34,376] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,565] init detected end of child process 10876 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,565] init detected end of child process 10884 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,565] init detected end of child process 10885 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:50:34,565] init detected end of child process 10887 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:35,654] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:35,654] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,510] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,985] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,985] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,985] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,986] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,991] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:39,991] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:50:39 I0508 21:50:39.991588 11504 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:50:39 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::34000\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:50:39 I0508 21:50:39.992965 11504 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:40,119] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,169] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,169] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['219us', '114us', '97us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,170] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,170] [play_vexpect] vexpect macro complete in 4.145086s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:50:44 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::34000 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 18 rects, 983.04 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.81359 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 31 rects, 1.06293 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.83267 MiB (1:1.43156 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,374] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 29->29, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,375] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,375] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=28->29, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,375] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.97s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,375] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=7.0 episode_count=5 episode_duration=15.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,376] [INFO:universe.wrappers.logger] Stats for the past 10.97s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=924.7 vnc_pixels_ps[total]=3727.0 reward_lag=None rewarder_message_lag=None fps=4.47\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,387] [INFO:gym_controlplane.reward.reward] First score parsed: score=16. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:44,387] [INFO:universe.pyprofile] [pyprofile] period=10.98s timers={\"rewarder.sleep\": {\"calls\": 48, \"std\": \"517.21us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"3.99ms\", \"mean\": \"1.95ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.94ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"21.04us\", \"mean\": \"36.21us\"}, \"rewarder.compute_reward\": {\"calls\": 49, \"std\": \"1.64ms\", \"mean\": \"582.53us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"30.92us\", \"mean\": \"58.97us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"280.41us\", \"mean\": \"353.89us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 49, \"std\": \"130.65us\", \"mean\": \"116.59us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"45.27us\", \"mean\": \"81.22us\"}, \"rewarder.frame\": {\"calls\": 49, \"std\": \"1.96ms\", \"mean\": \"16.50ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 49, \"std\": 4.709322784481372, \"mean\": 0.7755102040816326}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 2.8577380332470415, \"value\": 10, \"mean\": 15.833333333333334}} (export_time=136.14us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:46,576] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.20s, sent 2 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=6 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2084 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:48,526] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:49,392] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21551.1 vnc_pixels_ps[total]=104494.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:49,393] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.65ms\", \"mean\": \"1.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"15.97us\", \"mean\": \"33.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"916.37us\", \"mean\": \"361.17us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.97ms\", \"mean\": \"7.14ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"79.74us\", \"mean\": \"188.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.94us\", \"mean\": \"93.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"27.23us\", \"mean\": \"79.90us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.01us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.1908902300206643, \"mean\": 2.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395356}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 1.4561491580090171, \"value\": 22.0, \"mean\": 17.25}} (export_time=79.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *152 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *153 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *154 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *155 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *156 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *157 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *158 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *159 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *160 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:50:50 [info] 68#68: *161 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:50,931] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.41s, sent 3 reward messages to agent: reward=6.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 5482, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 10968, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:52,459] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=8.0 reward_min=1.0 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:53,759] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:54,409] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10050.2 vnc_pixels_ps[total]=45231.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:54,410] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"829.91us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.28ms\", \"mean\": \"1.32ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"257.23us\", \"mean\": \"5.64ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.99us\", \"mean\": \"28.51us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"789.79us\", \"mean\": \"330.79us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"343.12us\", \"mean\": \"1.23ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"70.72us\", \"mean\": \"164.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.17us\", \"mean\": \"91.54us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.86us\", \"mean\": \"65.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"241.64us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 2.898275349237888, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152828}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 7.0269809689838745, \"value\": 40.0, \"mean\": 30.53846153846154}} (export_time=149.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:57,692] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.93s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2332 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:59,426] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7602.1 vnc_pixels_ps[total]=44653.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:59,426] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"495.30us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.56ms\", \"mean\": \"695.57us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.25us\", \"mean\": \"28.99us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"487.16us\", \"mean\": \"270.11us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"31.36us\", \"mean\": \"5.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"46.47us\", \"mean\": \"163.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.20us\", \"mean\": \"93.88us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"19.47us\", \"mean\": \"66.03us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.98us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.8434823356732996, \"value\": 42.0, \"mean\": 40.56521739130435}} (export_time=92.27us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:50:59,426] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:01,009] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.58s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:02,309] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1347, 'rewarder.vnc.updates.pixels': 9824, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:04,443] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8441.3 vnc_pixels_ps[total]=45083.7 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:04,443] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"641.68us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.93ms\", \"mean\": \"885.29us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"7.94us\", \"mean\": \"26.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"641.64us\", \"mean\": \"290.66us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.11ms\", \"mean\": \"5.82ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"28.32us\", \"mean\": \"150.26us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.78us\", \"mean\": \"87.10us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"10.35us\", \"mean\": \"61.05us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.28us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.85899390587776, \"value\": 49.0, \"mean\": 44.57692307692307}} (export_time=190.97us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:04,444] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.13s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:07,509] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.07s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1347, 'rewarder.vnc.updates.pixels': 9824, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:09,460] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6828.0 vnc_pixels_ps[total]=44584.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:09,461] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"395.37us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.02ms\", \"mean\": \"504.54us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.78us\", \"mean\": \"43.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"393.17us\", \"mean\": \"313.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.11ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"151.74us\", \"mean\": \"255.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.74us\", \"mean\": \"99.29us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.28us\", \"mean\": \"85.77us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.94us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.48989794855663404, \"value\": 50.0, \"mean\": 49.36}} (export_time=202.66us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:09,462] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:14,009] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.55s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:14,476] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7014.5 vnc_pixels_ps[total]=46212.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:14,476] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"418.62us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.04ms\", \"mean\": \"471.78us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.30us\", \"mean\": \"32.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"354.56us\", \"mean\": \"262.11us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"94.21us\", \"mean\": \"184.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.82us\", \"mean\": \"93.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.46us\", \"mean\": \"76.85us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.69us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5646597025732792, \"value\": 52.0, \"mean\": 50.16666666666667}} (export_time=83.68us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=210us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.17s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1901 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 29->30, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,176] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,177] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,177] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=30\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,177] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,181] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,195] init detected end of child process 11232 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,200] init detected end of child process 11247 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,203] init detected end of child process 11449 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,204] init detected end of child process 11454 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,220] init detected end of child process 11476 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,259] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,259] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:17,347] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:17 [info] 68#68: *149 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:17 [info] 68#68: *150 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:17 [info] 68#68: *151 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:17 [info] 68#68: *148 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,529] init detected end of child process 11235 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,529] init detected end of child process 11243 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,529] init detected end of child process 11244 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:17,530] init detected end of child process 11246 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:18,579] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:18,579] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:21,913] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,401] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,401] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,401] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,401] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,406] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,406] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:51:22 I0508 21:51:22.407129 11877 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:51:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::34226\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:51:22 I0508 21:51:22.409746 11877 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:22,534] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:25,868] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['245us', '132us', '142us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:25,869] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:25,869] [play_vexpect] vexpect macro complete in 3.428622s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:51:26 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::34226 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.8926 KiB (1:15.7551 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 44 rects, 1.08649 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.8564 MiB (1:1.45117 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,095] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 30->30, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,096] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,096] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=29->30, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,096] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.92s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,097] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=42.0 episode_count=24 episode_duration=41.72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,098] [INFO:universe.wrappers.logger] Stats for the past 11.62s: vnc_updates_ps=1.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1764.4 vnc_pixels_ps[total]=10131.4 reward_lag=None rewarder_message_lag=None fps=14.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,105] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:26,106] [INFO:universe.pyprofile] [pyprofile] period=11.63s timers={\"rewarder.sleep\": {\"calls\": 162, \"std\": \"167.74us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"1.86ms\", \"mean\": \"726.85us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.99ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"14.94us\", \"mean\": \"25.95us\"}, \"rewarder.compute_reward\": {\"calls\": 163, \"std\": \"673.51us\", \"mean\": \"289.37us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.07us\", \"mean\": \"36.20us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"87.75us\", \"mean\": \"185.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 163, \"std\": \"31.62us\", \"mean\": \"88.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"23.61us\", \"mean\": \"64.80us\"}, \"rewarder.frame\": {\"calls\": 163, \"std\": \"1.19ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 163, \"std\": 2.670654255579342, \"mean\": 0.28834355828220865}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 11.224972160321824, \"value\": 10, \"mean\": 49.0}} (export_time=197.17us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:31,115] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=23176.6 vnc_pixels_ps[total]=96336.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:31,116] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"585.61us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"131.55us\", \"mean\": \"314.46us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.16us\", \"mean\": \"43.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.47us\", \"mean\": \"318.04us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"104.78us\", \"mean\": \"250.46us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.82us\", \"mean\": \"111.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"34.16us\", \"mean\": \"94.61us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.04us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 10.0, \"mean\": 10.0}} (export_time=300.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:31,117] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:32,831] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.71s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:36,131] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8454.1 vnc_pixels_ps[total]=45176.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:36,132] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"756.79us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.16ms\", \"mean\": \"1.07ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"14.89us\", \"mean\": \"43.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"729.76us\", \"mean\": \"403.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.06ms\", \"mean\": \"6.58ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"72.20us\", \"mean\": \"247.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.46us\", \"mean\": \"114.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.92us\", \"mean\": \"88.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.84us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662219, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.2108483993274486, \"value\": 13.0, \"mean\": 11.884615384615389}} (export_time=235.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:36,132] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.30s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:40,180] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.05s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:41,147] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6766.9 vnc_pixels_ps[total]=44377.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:41,148] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"712.22us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.22ms\", \"mean\": \"807.34us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.46us\", \"mean\": \"54.35us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"695.86us\", \"mean\": \"408.83us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.82ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"114.30us\", \"mean\": \"305.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.24us\", \"mean\": \"127.34us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.64us\", \"mean\": \"100.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.48us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.3806934938134407, \"value\": 14.0, \"mean\": 13.166666666666666}} (export_time=188.59us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:43,431] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.25s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:44,947] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:46,164] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9277.4 vnc_pixels_ps[total]=45434.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:46,164] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.69ms\", \"mean\": \"1.83ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.18us\", \"mean\": \"50.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"482.82us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.49ms\", \"mean\": \"9.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"93.56us\", \"mean\": \"283.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.68us\", \"mean\": \"118.46us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.02us\", \"mean\": \"93.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.96us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.2504700363735997, \"value\": 20.0, \"mean\": 16.23076923076923}} (export_time=147.10us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:46,164] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:51,181] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:51,181] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"217.46us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"94.19us\", \"mean\": \"312.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.18us\", \"mean\": \"44.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"199.05us\", \"mean\": \"332.43us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"98.10us\", \"mean\": \"252.52us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.70us\", \"mean\": \"114.54us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.05us\", \"mean\": \"90.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.60us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 20.0, \"mean\": 20.0}} (export_time=178.34us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:51,182] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:56,197] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5958.2 vnc_pixels_ps[total]=44169.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:56,198] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"222.19us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"85.41us\", \"mean\": \"289.72us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.94us\", \"mean\": \"42.07us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"192.15us\", \"mean\": \"289.25us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"113.21us\", \"mean\": \"239.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.04us\", \"mean\": \"95.95us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.21us\", \"mean\": \"86.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.74us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.0797342192691031}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 20.0, \"mean\": 20.0}} (export_time=113.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:56,198] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,880] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=227us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,880] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,880] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.68s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 30->31, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=31\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,881] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,882] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:58,899] init detected end of child process 11605 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:58,903] init detected end of child process 11620 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:58,903] init detected end of child process 11829 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:58,906] init detected end of child process 11906 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:58,919] init detected end of child process 11850 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:51:58 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,956] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:58,957] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:51:59,041] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:59 [info] 68#68: *163 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:59 [info] 68#68: *164 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:59 [info] 68#68: *165 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:51:59 [info] 68#68: *162 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:59,226] init detected end of child process 11619 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:59,241] init detected end of child process 11608 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:59,241] init detected end of child process 11616 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:51:59,241] init detected end of child process 11617 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:00,316] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:00,317] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:00,823] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,303] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,303] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,303] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,303] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,305] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,305] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:52:01 I0508 21:52:01.305877 12225 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:52:01 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::34380\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:52:01 I0508 21:52:01.307305 12225 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:01,440] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:05,456] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:09,490] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,424] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['236us', '111us', '97us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,424] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,424] [play_vexpect] vexpect macro complete in 9.085078s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:52:10 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::34380 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 131.153 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3193 KiB (1:31.3954 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 331.282 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.949 KiB (1:9.66221 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08473 MiB (1:2.78069 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,703] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 31->31, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,703] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,703] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=30->31, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,704] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.82s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,704] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=10.0 episode_count=16 episode_duration=44.61\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,705] [INFO:universe.wrappers.logger] Stats for the past 14.51s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1509.2 vnc_pixels_ps[total]=8829.1 reward_lag=None rewarder_message_lag=None fps=11.17\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,715] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:10,716] [INFO:universe.pyprofile] [pyprofile] period=14.52s timers={\"rewarder.sleep\": {\"calls\": 161, \"std\": \"280.59us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.42ms\", \"mean\": \"963.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.18ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"26.91us\", \"mean\": \"40.28us\"}, \"rewarder.compute_reward\": {\"calls\": 162, \"std\": \"864.97us\", \"mean\": \"368.95us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.60us\", \"mean\": \"37.47us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"125.35us\", \"mean\": \"265.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 162, \"std\": \"53.24us\", \"mean\": \"107.31us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"57.64us\", \"mean\": \"89.13us\"}, \"rewarder.frame\": {\"calls\": 162, \"std\": \"1.22ms\", \"mean\": \"16.68ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 162, \"std\": 2.9134171322606917, \"mean\": 0.30864197530864196}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 2.6726124191242437, \"value\": 10, \"mean\": 19.285714285714285}} (export_time=162.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:15,721] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=12.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19226.7 vnc_pixels_ps[total]=110543.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:15,721] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"726.92us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"118.60us\", \"mean\": \"338.08us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.04us\", \"mean\": \"49.77us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"217.45us\", \"mean\": \"341.09us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"128.18us\", \"mean\": \"281.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.17us\", \"mean\": \"110.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"35.26us\", \"mean\": \"105.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.65us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 10.0, \"mean\": 10.0}} (export_time=81.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:15,721] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1725 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:19,488] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.77s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:20,738] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6727.1 vnc_pixels_ps[total]=44045.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:20,738] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"567.29us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.75ms\", \"mean\": \"692.48us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.37us\", \"mean\": \"47.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"560.56us\", \"mean\": \"381.88us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.60ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"92.18us\", \"mean\": \"264.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.44us\", \"mean\": \"114.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.77us\", \"mean\": \"97.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.53us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4148511169990527, \"value\": 11.0, \"mean\": 10.208333333333336}} (export_time=139.00us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:20,739] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.25s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1908 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:25,554] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.82s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:25,755] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6787.0 vnc_pixels_ps[total]=44533.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:25,756] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"895.27us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.86ms\", \"mean\": \"923.63us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.16us\", \"mean\": \"49.84us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"891.93us\", \"mean\": \"408.27us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.81ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"114.73us\", \"mean\": \"280.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.94us\", \"mean\": \"114.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.40us\", \"mean\": \"102.74us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.50us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 11.0, \"mean\": 11.0}} (export_time=219.58us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:30,772] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6192.1 vnc_pixels_ps[total]=45938.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:30,773] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"376.28us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"92.43us\", \"mean\": \"317.35us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.63us\", \"mean\": \"45.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"240.96us\", \"mean\": \"356.33us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"90.81us\", \"mean\": \"256.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"79.72us\", \"mean\": \"119.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.30us\", \"mean\": \"92.75us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"223.79us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=225.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:30,774] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.22s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:35,788] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5905.7 vnc_pixels_ps[total]=43804.3 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:35,788] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"276.03us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.11us\", \"mean\": \"244.44us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"15.35us\", \"mean\": \"32.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"161.87us\", \"mean\": \"268.43us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"75.98us\", \"mean\": \"183.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.46us\", \"mean\": \"96.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.93us\", \"mean\": \"74.54us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.88us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=231.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:35,789] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:40,805] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5964.5 vnc_pixels_ps[total]=44258.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:40,805] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"239.22us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"100.30us\", \"mean\": \"296.76us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.50us\", \"mean\": \"40.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"207.32us\", \"mean\": \"275.85us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"129.06us\", \"mean\": \"233.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.27us\", \"mean\": \"91.35us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.64us\", \"mean\": \"88.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.35us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=225.31us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:40,806] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:45,821] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.9 vnc_pixels_ps[total]=44022.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:45,822] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"791.01us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"50.09us\", \"mean\": \"278.17us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.20us\", \"mean\": \"37.49us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"226.94us\", \"mean\": \"268.06us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"54.62us\", \"mean\": \"208.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.70us\", \"mean\": \"81.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"21.46us\", \"mean\": \"88.35us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"631.76us\", \"mean\": \"16.88ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289037}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=141.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:45,822] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:50,825] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5949.8 vnc_pixels_ps[total]=44114.6 reward_lag=None rewarder_message_lag=None fps=59.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:50,826] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.34ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"29.43us\", \"mean\": \"313.92us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"13.61us\", \"mean\": \"48.09us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"685.28us\", \"mean\": \"340.45us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"43.84us\", \"mean\": \"267.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"610.87us\", \"mean\": \"139.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"11.56us\", \"mean\": \"93.41us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"1.17ms\", \"mean\": \"17.02ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.0766666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=148.30us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:50,826] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1716 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:55,838] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5952.5 vnc_pixels_ps[total]=44124.3 reward_lag=None rewarder_message_lag=None fps=60.06\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:55,838] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"570.35us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"49.44us\", \"mean\": \"308.76us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.54us\", \"mean\": \"43.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"302.52us\", \"mean\": \"304.91us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"61.96us\", \"mean\": \"248.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"245.27us\", \"mean\": \"107.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"21.37us\", \"mean\": \"97.86us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"355.66us\", \"mean\": \"16.81ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=143.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:55,839] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,405] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=500us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,405] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,405] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,406] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,406] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 31->32, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,406] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,406] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,406] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=32\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,407] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,407] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,419] init detected end of child process 11967 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,442] init detected end of child process 11982 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,451] init detected end of child process 12184 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,469] init detected end of child process 12190 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,469] init detected end of child process 12216 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:52:56 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:52:56 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:52:56 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,543] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,543] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:52:56 [info] 68#68: *167 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:52:56 [info] 68#68: *168 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:52:56 [info] 68#68: *169 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:52:56 [info] 68#68: *166 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:56,713] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,741] init detected end of child process 11981 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,741] init detected end of child process 11970 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,741] init detected end of child process 11978 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:52:56,741] init detected end of child process 11979 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:58,097] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.38s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:58,105] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:58,172] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,039] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,039] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,039] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0, 'fine_quality_level': 50, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,039] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,081] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,085] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:52:59 I0508 21:52:59.089847 12752 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:52:59 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::34896\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:52:59 I0508 21:52:59.120343 12752 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:52:59,279] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:03,329] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,513] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['202us', '95us', '80us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,513] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,514] [play_vexpect] vexpect macro complete in 6.363981s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:53:05 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::34896 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.682 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.439 KiB (1:10.344 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27146 MiB (1:2.36803 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,790] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 32->32, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,798] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,798] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=31->32, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,798] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.96s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,799] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=3.0 episode_count=13 episode_duration=55.09\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,800] [INFO:universe.wrappers.logger] Stats for the past 9.96s: vnc_updates_ps=0.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=883.3 vnc_pixels_ps[total]=3101.2 reward_lag=None rewarder_message_lag=None fps=3.51\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,817] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:05,821] [INFO:universe.pyprofile] [pyprofile] period=9.98s timers={\"rewarder.sleep\": {\"calls\": 34, \"std\": \"440.99us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 4, \"std\": \"8.34ms\", \"mean\": \"4.46ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"16.71ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 12, \"std\": \"17.27us\", \"mean\": \"30.64us\"}, \"rewarder.compute_reward\": {\"calls\": 35, \"std\": \"3.68ms\", \"mean\": \"923.82us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"41.72us\", \"mean\": \"81.10us\"}, \"reward.parsing.gameover\": {\"calls\": 4, \"std\": \"263.13us\", \"mean\": \"435.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 35, \"std\": \"53.26us\", \"mean\": \"92.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 4, \"std\": \"41.12us\", \"mean\": \"69.56us\"}, \"rewarder.frame\": {\"calls\": 35, \"std\": \"2.41ms\", \"mean\": \"16.35ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 35, \"std\": 3.377632804397858, \"mean\": 0.6571428571428571}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 6, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 3, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 4, \"std\": 1.5, \"value\": 10, \"mean\": 12.25}} (export_time=169.28us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:06,921] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.profile': '<2053 bytes>', 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:09,281] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.36s, sent 1 reward messages to agent: reward=7.0 reward_min=7.0 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:10,398] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:10,815] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=9.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16478.4 vnc_pixels_ps[total]=80046.9 reward_lag=None rewarder_message_lag=None fps=59.63\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:10,832] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 297, \"std\": \"1.22ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"6.36ms\", \"mean\": \"2.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.40us\", \"mean\": \"41.13us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"2.05ms\", \"mean\": \"512.81us\"}, \"rewarder.sleep.missed\": {\"calls\": 3, \"std\": \"9.83ms\", \"mean\": \"10.78ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"6.46ms\", \"mean\": \"18.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"48.15us\", \"mean\": \"231.50us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"331.71us\", \"mean\": \"125.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"16.15us\", \"mean\": \"88.15us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"1.55ms\", \"mean\": \"16.98ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 3.2015621187164247, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177285, \"mean\": 0.09000000000000002}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.5769920037472542, \"value\": 19.0, \"mean\": 12.888888888888888}} (export_time=161.89us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:11,948] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 3 reward messages to agent: reward=5.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2037 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:14,765] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:15,831] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10069.5 vnc_pixels_ps[total]=45461.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:15,832] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.60ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.63ms\", \"mean\": \"2.43ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.15us\", \"mean\": \"40.40us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.58ms\", \"mean\": \"464.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.21ms\", \"mean\": \"11.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"48.33us\", \"mean\": \"225.35us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"94.47us\", \"mean\": \"88.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"12.81us\", \"mean\": \"76.87us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"226.55us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.0327955589886444, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177274, \"mean\": 0.09000000000000001}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.4967214970072726, \"value\": 29.0, \"mean\": 24.185185185185183}} (export_time=109.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:15,832] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:17,801] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:19,972] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:20,839] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8644.4 vnc_pixels_ps[total]=46609.0 reward_lag=None rewarder_message_lag=None fps=59.92\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:20,839] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 298, \"std\": \"1.02ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.98ms\", \"mean\": \"2.00ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"13.83us\", \"mean\": \"44.75us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.68ms\", \"mean\": \"472.61us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"1.24ms\", \"mean\": \"3.57ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.71ms\", \"mean\": \"14.99ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"54.70us\", \"mean\": \"251.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"203.11us\", \"mean\": \"109.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"19.66us\", \"mean\": \"98.28us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"828.51us\", \"mean\": \"16.94ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177263, \"mean\": 0.09000000000000002}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.744588044272499, \"value\": 36.0, \"mean\": 32.07407407407407}} (export_time=179.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:23,472] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.50s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2032 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:25,722] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.25s, sent 2 reward messages to agent: reward=7.0 reward_min=2.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:25,855] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8137.0 vnc_pixels_ps[total]=42842.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:25,860] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"15.87ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.91ms\", \"mean\": \"1.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"13.37us\", \"mean\": \"43.19us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"445.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"239.22us\", \"mean\": \"8.72ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"52.72us\", \"mean\": \"244.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"326.77us\", \"mean\": \"133.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.74us\", \"mean\": \"95.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"729.13us\", \"mean\": \"16.95ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.0615528128088303, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 3.1895663237081817, \"value\": 43.0, \"mean\": 38.56}} (export_time=169.52us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,639] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=477us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,639] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,640] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.92s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,640] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,640] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,640] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 32->33, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,641] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,641] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,641] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=33\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,642] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,643] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:29,703] init detected end of child process 12502 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:29,731] init detected end of child process 12517 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:29,737] init detected end of child process 12721 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:29,742] init detected end of child process 12726 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:29,767] init detected end of child process 12748 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:53:29 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:53:29 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:53:29 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,914] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:29,914] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:53:29 [info] 68#68: *171 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:53:29 [info] 68#68: *172 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:53:29 [info] 68#68: *173 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:53:29 [info] 68#68: *170 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:30,077] init detected end of child process 12505 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:30,077] init detected end of child process 12513 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:30,077] init detected end of child process 12514 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:53:30,077] init detected end of child process 12516 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:30,138] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:31,707] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.57s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:31,707] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:36,903] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,399] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,399] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,399] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,400] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,406] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,406] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:53:37 I0508 21:53:37.406818 13162 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:53:37 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::35180\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:53:37 I0508 21:53:37.408185 13162 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:37,525] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:38,876] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['137us', '64us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:38,876] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:38,876] [play_vexpect] vexpect macro complete in 1.435872s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:53:39 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::35180 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 83.106 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.1592 KiB (1:16.107 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 24 rects, 929.28 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.65987 MiB (1:1.33284 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 34 rects, 1.02414 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.68113 MiB (1:1.45729 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,101] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 33->33, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,101] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,101] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=32->33, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,102] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.46s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,103] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=35.0 episode_count=20 episode_duration=33.30\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,104] [INFO:universe.wrappers.logger] Stats for the past 13.25s: vnc_updates_ps=1.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1923.9 vnc_pixels_ps[total]=11613.8 reward_lag=None rewarder_message_lag=None fps=17.21\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,119] [INFO:gym_controlplane.reward.reward] First score parsed: score=14. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:39,119] [INFO:universe.pyprofile] [pyprofile] period=13.26s timers={\"rewarder.sleep\": {\"calls\": 227, \"std\": \"1.02ms\", \"mean\": \"15.90ms\"}, \"reward.parsing.score\": {\"calls\": 18, \"std\": \"3.28ms\", \"mean\": \"1.14ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.09ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 54, \"std\": \"17.46us\", \"mean\": \"50.02us\"}, \"rewarder.compute_reward\": {\"calls\": 228, \"std\": \"1.15ms\", \"mean\": \"472.44us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.83us\", \"mean\": \"63.14us\"}, \"reward.parsing.gameover\": {\"calls\": 18, \"std\": \"124.96us\", \"mean\": \"334.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 228, \"std\": \"389.99us\", \"mean\": \"159.00us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 18, \"std\": \"25.19us\", \"mean\": \"100.45us\"}, \"rewarder.frame\": {\"calls\": 228, \"std\": \"1.21ms\", \"mean\": \"16.86ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 228, \"std\": 1.2806864030197502, \"mean\": 0.15789473684210528}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 48, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 17, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 18, \"std\": 8.249579113843055, \"value\": 10, \"mean\": 43.05555555555556}} (export_time=145.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:40,622] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=11.0 reward_min=2.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:42,138] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:43,654] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=9.0 reward_min=2.0 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:44,121] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19005.0 vnc_pixels_ps[total]=81196.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:44,121] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"928.10us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 30, \"std\": \"2.47ms\", \"mean\": \"1.45ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 90, \"std\": \"23.32us\", \"mean\": \"35.99us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"923.19us\", \"mean\": \"383.93us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"1.69ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"958.58us\", \"mean\": \"5.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 30, \"std\": \"98.59us\", \"mean\": \"202.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.33us\", \"mean\": \"93.56us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 30, \"std\": \"18.61us\", \"mean\": \"69.75us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"94.63us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 2.258317958127243, \"mean\": 3.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.3000553658766364, \"mean\": 0.09966777408637871}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 90, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 30, \"std\": 5.6164782191518325, \"value\": 31.0, \"mean\": 21.799999999999994}} (export_time=170.23us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:45,171] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2019 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:47,988] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:49,137] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8370.5 vnc_pixels_ps[total]=44609.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:49,138] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"692.07us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.00ms\", \"mean\": \"970.42us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.89us\", \"mean\": \"40.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"677.77us\", \"mean\": \"315.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.65ms\", \"mean\": \"5.99ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"102.92us\", \"mean\": \"223.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.54us\", \"mean\": \"90.52us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"27.95us\", \"mean\": \"77.94us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.37us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0954451150103321, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.0863787375415282}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.3272296189953179, \"value\": 37.0, \"mean\": 34.807692307692314}} (export_time=130.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:49,138] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1915 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:54,154] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.2 vnc_pixels_ps[total]=44017.9 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:54,154] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"213.66us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"94.32us\", \"mean\": \"302.41us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.60us\", \"mean\": \"41.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"191.57us\", \"mean\": \"283.36us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.81us\", \"mean\": \"238.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.28us\", \"mean\": \"99.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.56us\", \"mean\": \"89.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"45.81us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=92.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:54,154] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:59,171] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5953.9 vnc_pixels_ps[total]=44176.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:59,171] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"183.26us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"61.89us\", \"mean\": \"277.46us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.30us\", \"mean\": \"37.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"167.26us\", \"mean\": \"275.03us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"61.09us\", \"mean\": \"212.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.22us\", \"mean\": \"94.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.60us\", \"mean\": \"82.96us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.68us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=120.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:53:59,171] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:00,988] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.82s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:04,188] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.3 vnc_pixels_ps[total]=44289.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:04,188] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"804.11us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.57ms\", \"mean\": \"885.15us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.24us\", \"mean\": \"53.38us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"798.25us\", \"mean\": \"389.17us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"94.18us\", \"mean\": \"303.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.96us\", \"mean\": \"116.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.85us\", \"mean\": \"104.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.50us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.5108304655560003, \"value\": 40.0, \"mean\": 38.75000000000001}} (export_time=146.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:04,189] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.20s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1901 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:09,204] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.9 vnc_pixels_ps[total]=44023.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:09,205] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"250.41us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"92.72us\", \"mean\": \"338.97us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.47us\", \"mean\": \"50.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"219.59us\", \"mean\": \"340.81us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"116.48us\", \"mean\": \"285.25us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.80us\", \"mean\": \"113.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.93us\", \"mean\": \"99.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.60us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910307}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=115.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:09,205] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:14,221] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.4 vnc_pixels_ps[total]=45932.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:14,222] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"273.12us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"94.38us\", \"mean\": \"393.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.80us\", \"mean\": \"59.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"248.65us\", \"mean\": \"352.04us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"112.37us\", \"mean\": \"334.88us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.20us\", \"mean\": \"115.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.91us\", \"mean\": \"113.25us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.60us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=210.29us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:14,222] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1726 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:19,237] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.3 vnc_pixels_ps[total]=44025.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:19,238] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"303.05us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"122.23us\", \"mean\": \"374.46us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"35.29us\", \"mean\": \"61.56us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"256.05us\", \"mean\": \"331.92us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"168.87us\", \"mean\": \"339.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.75us\", \"mean\": \"109.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"34.74us\", \"mean\": \"110.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.85us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=106.10us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:19,238] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:24,254] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.2 vnc_pixels_ps[total]=44017.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:24,255] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"257.65us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"130.54us\", \"mean\": \"357.01us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.17us\", \"mean\": \"50.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"236.06us\", \"mean\": \"314.35us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"120.49us\", \"mean\": \"278.86us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.58us\", \"mean\": \"105.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"34.98us\", \"mean\": \"104.47us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.80us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289037}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=164.99us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:24,255] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:29,271] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.3 vnc_pixels_ps[total]=44179.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:29,272] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"274.30us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"105.95us\", \"mean\": \"384.85us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.52us\", \"mean\": \"56.34us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"250.23us\", \"mean\": \"357.16us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.95us\", \"mean\": \"319.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.10us\", \"mean\": \"118.18us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.64us\", \"mean\": \"110.61us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.77us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=127.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:29,272] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:54:31 [info] 68#68: *175 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:54:31 [info] 68#68: *176 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:54:31 [info] 68#68: *177 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:34,287] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.7 vnc_pixels_ps[total]=44183.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:34,287] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"349.76us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"67.78us\", \"mean\": \"261.49us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.47us\", \"mean\": \"35.07us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"170.72us\", \"mean\": \"275.38us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"68.74us\", \"mean\": \"198.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"65.26us\", \"mean\": \"101.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.82us\", \"mean\": \"74.07us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"281.10us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=79.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:34,288] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:39,305] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.5 vnc_pixels_ps[total]=44335.0 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:39,305] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"321.21us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"129.63us\", \"mean\": \"333.88us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.16us\", \"mean\": \"46.89us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"229.41us\", \"mean\": \"315.06us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"154.80us\", \"mean\": \"285.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.90us\", \"mean\": \"103.69us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.39us\", \"mean\": \"96.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"224.26us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=202.42us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:39,306] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,321] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5976.0 vnc_pixels_ps[total]=44346.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,321] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"280.46us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"125.48us\", \"mean\": \"357.87us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.64us\", \"mean\": \"50.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"220.44us\", \"mean\": \"341.70us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"105.29us\", \"mean\": \"286.30us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.63us\", \"mean\": \"115.08us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"34.29us\", \"mean\": \"104.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.19us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=116.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,321] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,854] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=364us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,854] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,855] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,855] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,855] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 33->34, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,855] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,856] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,856] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=34\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,856] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,857] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:44,871] init detected end of child process 12880 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:44,880] init detected end of child process 12895 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:44,880] init detected end of child process 13105 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:54:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:44,900] init detected end of child process 13128 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:54:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:54:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,931] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:44,931] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:45,019] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:45,177] init detected end of child process 12883 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:45,177] init detected end of child process 12891 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:45,177] init detected end of child process 12892 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:54:45,177] init detected end of child process 12894 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:46,303] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:46,304] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:49,853] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,411] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,411] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,411] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'fine_quality_level': 50, 'encoding': 'zrle', 'subsample_level': 2, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,411] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,422] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,422] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:54:50 I0508 21:54:50.422931 13691 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:54:50 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::35520\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:54:50 I0508 21:54:50.424237 13691 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:50,544] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:54,594] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:54,794] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['227us', '129us', '115us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:54,795] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:54,795] [play_vexpect] vexpect macro complete in 4.338761s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:54:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::35520 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9639 KiB (1:15.7015 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 18 rects, 860.16 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.46195 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 33 rects, 956.439 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.48408 MiB (1:1.46892 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,005] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 34->34, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,005] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,006] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=33->34, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,006] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.68s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,006] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=30.0 episode_count=25 episode_duration=75.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,007] [INFO:universe.wrappers.logger] Stats for the past 10.69s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=833.1 vnc_pixels_ps[total]=2965.6 reward_lag=None rewarder_message_lag=None fps=3.09\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,018] [INFO:gym_controlplane.reward.reward] First score parsed: score=20. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:54:55,019] [INFO:universe.pyprofile] [pyprofile] period=10.70s timers={\"rewarder.sleep\": {\"calls\": 32, \"std\": \"286.93us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"4.57ms\", \"mean\": \"2.27ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.27ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"11.27us\", \"mean\": \"22.84us\"}, \"rewarder.compute_reward\": {\"calls\": 33, \"std\": \"2.07ms\", \"mean\": \"665.87us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"23.89us\", \"mean\": \"51.42us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"194.05us\", \"mean\": \"278.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 33, \"std\": \"34.63us\", \"mean\": \"96.00us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"29.25us\", \"mean\": \"57.03us\"}, \"rewarder.frame\": {\"calls\": 33, \"std\": \"2.52ms\", \"mean\": \"16.32ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 33, \"std\": 5.558572413194531, \"mean\": 1.0909090909090908}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 13.416407864998739, \"value\": 10, \"mean\": 34.0}} (export_time=130.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:00,023] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18836.1 vnc_pixels_ps[total]=101803.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:00,023] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"784.59us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"80.65us\", \"mean\": \"252.72us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"15.91us\", \"mean\": \"36.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"162.69us\", \"mean\": \"272.33us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"81.43us\", \"mean\": \"209.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.69us\", \"mean\": \"97.89us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.21us\", \"mean\": \"77.63us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"183.31us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 10.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 20.0, \"mean\": 20.0}} (export_time=92.27us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:00,024] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=10 reward_min=0 reward_max=10 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:01,356] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.33s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:02,856] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.50s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:04,373] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:05,040] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9479.8 vnc_pixels_ps[total]=47022.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:05,040] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.99ms\", \"mean\": \"1.31ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"13.95us\", \"mean\": \"32.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"362.04us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.13ms\", \"mean\": \"7.39ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"62.54us\", \"mean\": \"181.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.61us\", \"mean\": \"97.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"23.23us\", \"mean\": \"68.10us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.17us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.09302325581395347}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 1.8152061990235564, \"value\": 25.0, \"mean\": 22.464285714285715}} (export_time=83.21us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:09,814] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.44s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:10,046] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6790.7 vnc_pixels_ps[total]=44546.0 reward_lag=None rewarder_message_lag=None fps=59.94\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:10,047] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"258.15us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"4.24ms\", \"mean\": \"1.18ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"32.15us\", \"mean\": \"48.04us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.29ms\", \"mean\": \"368.75us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.77ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"20.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"168.64us\", \"mean\": \"271.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"40.76us\", \"mean\": \"97.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"39.28us\", \"mean\": \"93.80us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"330.02us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.08000000000000002}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.20412414523193137, \"value\": 26.0, \"mean\": 25.041666666666668}} (export_time=229.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:11,330] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2000 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:12,629] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=9.0 reward_min=9.0 reward_max=9.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:14,362] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 3 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:15,062] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=6.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=11673.4 vnc_pixels_ps[total]=45906.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:15,063] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.75ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"4.79ms\", \"mean\": \"2.92ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"13.38us\", \"mean\": \"41.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.72ms\", \"mean\": \"542.89us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 7, \"std\": \"2.55ms\", \"mean\": \"10.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"47.79us\", \"mean\": \"231.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"181.60us\", \"mean\": \"102.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"17.98us\", \"mean\": \"83.17us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"284.12us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 3.101458950082625, \"mean\": 2.5714285714285716}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.32150669654720326, \"mean\": 0.09966777408637871}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 7.1154500651490515, \"value\": 44.0, \"mean\": 35.49999999999999}} (export_time=107.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:15,879] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:20,079] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6796.8 vnc_pixels_ps[total]=44609.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:20,080] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"850.40us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.40ms\", \"mean\": \"761.08us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"9.72us\", \"mean\": \"36.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"806.58us\", \"mean\": \"326.20us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"34.44us\", \"mean\": \"209.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"346.95us\", \"mean\": \"111.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"17.93us\", \"mean\": \"82.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"255.88us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.6902530516863504, \"value\": 47.0, \"mean\": 46.70833333333333}} (export_time=157.83us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:20,080] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.20s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1887 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:25,096] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5970.7 vnc_pixels_ps[total]=44227.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:25,097] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"724.19us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"39.57us\", \"mean\": \"286.41us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"10.52us\", \"mean\": \"40.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"548.09us\", \"mean\": \"323.81us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"41.99us\", \"mean\": \"229.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"521.12us\", \"mean\": \"134.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"16.74us\", \"mean\": \"88.40us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"390.71us\", \"mean\": \"16.84ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 47.0, \"mean\": 47.0}} (export_time=175.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:25,097] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:29,212] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.12s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:30,112] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6445.9 vnc_pixels_ps[total]=41896.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:30,114] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.03ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.34ms\", \"mean\": \"818.81us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"32.17us\", \"mean\": \"50.95us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"723.10us\", \"mean\": \"329.39us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"136.04us\", \"mean\": \"283.46us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"71.25us\", \"mean\": \"87.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"32.85us\", \"mean\": \"99.77us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"757.46us\", \"mean\": \"16.95ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910305}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.38069349381344, \"value\": 48.0, \"mean\": 47.166666666666664}} (export_time=153.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,796] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=486us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,797] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,797] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.58s, sent 2 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,797] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,797] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,797] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 34->35, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,798] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,798] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,798] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=35\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,798] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,798] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:32,812] init detected end of child process 13416 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:32,827] init detected end of child process 13431 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:32,835] init detected end of child process 13640 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:32,852] init detected end of child process 13633 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:32,858] init detected end of child process 13662 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:55:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:55:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:55:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,938] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:32,938] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:33 [info] 68#68: *179 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:33 [info] 68#68: *180 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:33 [info] 68#68: *181 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:33 [info] 68#68: *178 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:33,082] [selenium_wrapper_server] Calling webdriver.Chrome()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:33,189] init detected end of child process 13430 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:33,189] init detected end of child process 13427 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:33,189] init detected end of child process 13428 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:55:33,189] init detected end of child process 13419 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:35,465] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 2.38s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:35,466] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:35,620] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,430] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,430] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,430] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,431] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,439] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,439] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:55:36 I0508 21:55:36.441824 14206 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:55:36 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::35914\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:55:36 I0508 21:55:36.45304 14206 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:36,623] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:40,674] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:44,723] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:45,857] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['276us', '133us', '116us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:45,858] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:45,858] [play_vexpect] vexpect macro complete in 9.377090s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:55:45 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::35914 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.193 KiB (1:10.3217 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27228 MiB (1:2.37079 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,070] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 35->35, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,070] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,071] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=34->35, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,071] [INFO:universe.rewarder.remote] [Rewarder] Over past 13.27s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,072] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=38.0 episode_count=23 episode_duration=51.07\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,073] [INFO:universe.wrappers.logger] Stats for the past 15.96s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1368.6 vnc_pixels_ps[total]=8000.7 reward_lag=None rewarder_message_lag=None fps=10.15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,100] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:46,100] [INFO:universe.pyprofile] [pyprofile] period=15.99s timers={\"rewarder.sleep\": {\"calls\": 161, \"std\": \"830.75us\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"6.77ms\", \"mean\": \"2.15ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"25.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"16.47us\", \"mean\": \"43.19us\"}, \"rewarder.compute_reward\": {\"calls\": 162, \"std\": \"2.19ms\", \"mean\": \"514.07us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"26.39us\", \"mean\": \"67.51us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"147.42us\", \"mean\": \"312.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 162, \"std\": \"167.37us\", \"mean\": \"102.16us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"26.84us\", \"mean\": \"95.64us\"}, \"rewarder.frame\": {\"calls\": 162, \"std\": \"1.35ms\", \"mean\": \"16.88ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 162, \"std\": 3.2264435355664847, \"mean\": 0.33333333333333337}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 10.155927192672127, \"value\": 10, \"mean\": 45.285714285714285}} (export_time=193.60us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:47,504] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.43s, sent 2 reward messages to agent: reward=4.0 reward_min=2 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2095 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:49,237] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *186 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *187 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *188 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *189 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *190 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *191 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *192 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *193 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *194 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:55:50 [info] 70#70: *195 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:51,087] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=13.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26566.8 vnc_pixels_ps[total]=107633.1 reward_lag=None rewarder_message_lag=None fps=59.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:51,104] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.05ms\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.01ms\", \"mean\": \"1.09ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.63ms\", \"mean\": \"10.43ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.02us\", \"mean\": \"37.52us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"961.25us\", \"mean\": \"354.92us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.62ms\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"797.33us\", \"mean\": \"1.69ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"51.26us\", \"mean\": \"211.38us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"228.00us\", \"mean\": \"105.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"14.94us\", \"mean\": \"77.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"950.06us\", \"mean\": \"16.86ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531559}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.248999599679681, \"value\": 15.0, \"mean\": 13.679999999999998}} (export_time=155.21us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:51,104] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.87s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2440 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:53,137] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.03s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:56,104] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6777.1 vnc_pixels_ps[total]=44383.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:56,104] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"407.73us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.21ms\", \"mean\": \"510.27us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.64us\", \"mean\": \"35.73us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"402.81us\", \"mean\": \"297.63us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.91ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"74.93us\", \"mean\": \"201.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"39.14us\", \"mean\": \"99.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"16.18us\", \"mean\": \"74.81us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"19.27us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.07999999999999996}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0179547554081045, \"value\": 17.0, \"mean\": 16.083333333333332}} (export_time=132.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:56,105] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.97s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:55:58,537] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.43s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:01,121] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6783.7 vnc_pixels_ps[total]=44427.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:01,121] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"409.70us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.19ms\", \"mean\": \"526.73us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.98us\", \"mean\": \"38.38us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"398.24us\", \"mean\": \"310.41us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.85ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"75.70us\", \"mean\": \"219.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.40us\", \"mean\": \"104.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.60us\", \"mean\": \"81.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.38us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0179547554081043, \"value\": 19.0, \"mean\": 17.916666666666664}} (export_time=109.20us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:01,121] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.58s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:02,237] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:05,271] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:06,137] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8400.0 vnc_pixels_ps[total]=44837.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:06,138] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"842.34us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.48ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.27us\", \"mean\": \"36.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"838.59us\", \"mean\": \"356.30us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"229.41us\", \"mean\": \"7.65ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"53.18us\", \"mean\": \"205.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"58.48us\", \"mean\": \"97.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"20.29us\", \"mean\": \"75.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.77us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.217355782608345, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609667, \"mean\": 0.08970099667774094}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.7500508743113903, \"value\": 26.0, \"mean\": 20.296296296296298}} (export_time=91.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:07,637] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.37s, sent 3 reward messages to agent: reward=6.0 reward_min=0.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:11,154] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7850.9 vnc_pixels_ps[total]=46553.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:11,154] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"671.39us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.08ms\", \"mean\": \"865.29us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"11.71us\", \"mean\": \"36.54us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"666.37us\", \"mean\": \"330.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"291.82us\", \"mean\": \"7.43ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"52.75us\", \"mean\": \"206.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.39us\", \"mean\": \"99.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"14.97us\", \"mean\": \"75.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.65us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.9128709291752756, \"value\": 28.0, \"mean\": 27.200000000000003}} (export_time=124.93us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:11,155] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.52s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:12,854] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.70s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:14,587] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=5.0 reward_min=5.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:16,044] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.46s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:16,171] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10038.9 vnc_pixels_ps[total]=45299.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:16,171] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.51ms\", \"mean\": \"1.85ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"18.56us\", \"mean\": \"45.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"435.44us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.74ms\", \"mean\": \"8.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"95.65us\", \"mean\": \"257.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.72us\", \"mean\": \"95.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"33.00us\", \"mean\": \"91.88us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.56us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.073644135332772, \"mean\": 2.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395354}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 3.6158089100606636, \"value\": 40.0, \"mean\": 31.5}} (export_time=168.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:19,137] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.09s, sent 4 reward messages to agent: reward=6.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:21,187] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8399.8 vnc_pixels_ps[total]=44836.7 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:21,187] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"686.58us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.05ms\", \"mean\": \"948.05us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"14.91us\", \"mean\": \"32.30us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"682.50us\", \"mean\": \"299.82us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.50ms\", \"mean\": \"6.09ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"63.00us\", \"mean\": \"179.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.93us\", \"mean\": \"86.79us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"19.33us\", \"mean\": \"67.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.52us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.51657508881031, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.280688155258944, \"value\": 48.0, \"mean\": 45.1923076923077}} (export_time=80.35us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:21,188] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.05s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=217us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,854] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 35->36, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,855] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,855] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,855] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=36\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,855] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,855] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:22,871] init detected end of child process 13956 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:22,874] init detected end of child process 13971 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:22,876] init detected end of child process 14174 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:22,877] init detected end of child process 14179 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:22,894] init detected end of child process 14204 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,932] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:22,932] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:22 [info] 70#70: *183 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:22 [info] 70#70: *184 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:22 [info] 70#70: *185 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:22 [info] 70#70: *182 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:23,020] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:23,169] init detected end of child process 13959 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:23,169] init detected end of child process 13967 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:23,169] init detected end of child process 13968 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:23,170] init detected end of child process 13970 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,279] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,279] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,324] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,856] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,857] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,857] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50, 'encoding': 'zrle', 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,857] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,859] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,859] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:56:24 I0508 21:56:24.859402 14749 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:56:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::36172\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:56:24 I0508 21:56:24.865077 14749 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:24,983] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:29,016] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,766] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['210us', '77us', '62us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,767] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,767] [play_vexpect] vexpect macro complete in 7.874151s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:56:32 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::36172 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.216 KiB (1:10.3202 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.2723 MiB (1:2.37075 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,967] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 36->36, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,968] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,968] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=35->36, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,969] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.11s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,969] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=38.0 episode_count=26 episode_duration=46.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,970] [INFO:universe.wrappers.logger] Stats for the past 11.78s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1309.2 vnc_pixels_ps[total]=6797.8 reward_lag=None rewarder_message_lag=None fps=8.57\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,979] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:32,979] [INFO:universe.pyprofile] [pyprofile] period=11.79s timers={\"rewarder.sleep\": {\"calls\": 100, \"std\": \"137.75us\", \"mean\": \"16.30ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.59ms\", \"mean\": \"1.01ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.18ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"7.40us\", \"mean\": \"20.12us\"}, \"rewarder.compute_reward\": {\"calls\": 101, \"std\": \"963.03us\", \"mean\": \"317.89us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"32.29us\", \"mean\": \"40.93us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"88.75us\", \"mean\": \"171.88us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 101, \"std\": \"41.95us\", \"mean\": \"93.35us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"15.94us\", \"mean\": \"48.78us\"}, \"rewarder.frame\": {\"calls\": 101, \"std\": \"1.51ms\", \"mean\": \"16.61ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 101, \"std\": 3.981491834441303, \"mean\": 0.48514851485148514}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 12.016655108639842, \"value\": 10, \"mean\": 44.2}} (export_time=201.23us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:36,086] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.12s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:37,986] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=13.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26356.5 vnc_pixels_ps[total]=106024.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:37,987] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.06ms\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.67ms\", \"mean\": \"1.08ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"20.06us\", \"mean\": \"44.14us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"859.76us\", \"mean\": \"362.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.61ms\", \"mean\": \"9.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"106.16us\", \"mean\": \"250.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.96us\", \"mean\": \"104.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"41.54us\", \"mean\": \"93.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.00us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 2.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531558}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.9797958971132714, \"value\": 15.0, \"mean\": 13.719999999999999}} (export_time=173.81us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:37,987] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.90s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:41,519] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:43,003] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6717.0 vnc_pixels_ps[total]=43992.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:43,003] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"376.53us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.03ms\", \"mean\": \"481.23us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.86us\", \"mean\": \"38.42us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"357.37us\", \"mean\": \"292.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.08ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"110.06us\", \"mean\": \"217.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.59us\", \"mean\": \"100.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.31us\", \"mean\": \"76.33us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.61us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9315329426211422, \"value\": 18.0, \"mean\": 16.458333333333336}} (export_time=85.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:43,003] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.48s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1888 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,769] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=218us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,769] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,769] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.77s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 36->37, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,770] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=37\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,771] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,771] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:44,783] init detected end of child process 14502 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:44,787] init detected end of child process 14517 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:44,788] init detected end of child process 14724 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:44,790] init detected end of child process 14797 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:44,810] init detected end of child process 14746 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:56:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,841] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,841] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:44 [info] 70#70: *197 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:44 [info] 70#70: *198 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:44 [info] 70#70: *199 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:56:44 [info] 70#70: *196 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:44,931] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:45,118] init detected end of child process 14516 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:45,137] init detected end of child process 14505 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:45,137] init detected end of child process 14513 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:56:45,137] init detected end of child process 14514 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:46,187] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:46,187] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:49,727] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,233] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,233] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,233] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,233] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,238] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,239] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:56:50 I0508 21:56:50.239267 15142 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:56:50 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::36350\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:56:50 I0508 21:56:50.241138 15142 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:50,362] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,696] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['224us', '92us', '81us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,696] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,697] [play_vexpect] vexpect macro complete in 2.423856s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:56:52 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::36350 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9453 KiB (1:15.7154 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 22 rects, 892.416 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.55434 MiB (1:1.33285 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 37 rects, 988.695 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.57645 MiB (1:1.46403 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,931] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 37->37, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,932] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,932] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=36->37, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,933] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.16s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,933] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=8.0 episode_count=7 episode_duration=19.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,934] [INFO:universe.wrappers.logger] Stats for the past 9.93s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1659.9 vnc_pixels_ps[total]=8826.7 reward_lag=None rewarder_message_lag=None fps=10.77\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,942] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:52,943] [INFO:universe.pyprofile] [pyprofile] period=9.94s timers={\"rewarder.sleep\": {\"calls\": 106, \"std\": \"229.37us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.28ms\", \"mean\": \"1.00ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"20.65us\", \"mean\": \"33.64us\"}, \"rewarder.compute_reward\": {\"calls\": 107, \"std\": \"884.01us\", \"mean\": \"355.68us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"23.64us\", \"mean\": \"45.38us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"113.77us\", \"mean\": \"253.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 107, \"std\": \"44.52us\", \"mean\": \"92.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"40.36us\", \"mean\": \"76.41us\"}, \"rewarder.frame\": {\"calls\": 107, \"std\": \"1.48ms\", \"mean\": \"16.63ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 107, \"std\": 2.041061472470416, \"mean\": 0.2803738317757009}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 2.5298221281347035, \"value\": 10, \"mean\": 17.2}} (export_time=174.05us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:54,733] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.80s, sent 2 reward messages to agent: reward=5.0 reward_min=2 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.profile': '<2095 bytes>', 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:55,816] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:57,583] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.77s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:57,950] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17321.0 vnc_pixels_ps[total]=83463.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:56:57,950] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"873.00us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.85ms\", \"mean\": \"902.08us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"11.55us\", \"mean\": \"32.50us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"619.18us\", \"mean\": \"324.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"110.03us\", \"mean\": \"5.64ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"52.75us\", \"mean\": \"184.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.09us\", \"mean\": \"92.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"30.68us\", \"mean\": \"77.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"59.14us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.8880189047293428, \"value\": 17.0, \"mean\": 14.26923076923077}} (export_time=154.97us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:00,449] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.87s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:02,649] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.20s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:02,966] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8133.3 vnc_pixels_ps[total]=42855.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:02,967] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"672.15us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.03ms\", \"mean\": \"940.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"9.95us\", \"mean\": \"28.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"666.75us\", \"mean\": \"286.36us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.18ms\", \"mean\": \"5.95ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"45.75us\", \"mean\": \"160.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.97us\", \"mean\": \"80.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"13.18us\", \"mean\": \"64.00us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.12us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0999999999999988, \"value\": 22.0, \"mean\": 19.280000000000005}} (export_time=152.35us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,749] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=226us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.10s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 37->38, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,750] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,751] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=38\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,751] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,751] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:05,764] init detected end of child process 14857 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:05,768] init detected end of child process 14872 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:05,771] init detected end of child process 15074 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:05,773] init detected end of child process 15081 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:05,792] init detected end of child process 15103 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,828] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,828] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:05,918] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:05 [info] 70#70: *201 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:05 [info] 70#70: *202 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:05 [info] 70#70: *203 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:05 [info] 70#70: *200 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:06,157] init detected end of child process 14860 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:06,157] init detected end of child process 14868 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:06,157] init detected end of child process 14869 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:06,157] init detected end of child process 14871 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:07,188] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:07,188] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:10,875] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,393] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,393] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,393] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,393] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,397] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,397] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:11 I0508 21:57:11.39802 15510 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::36586\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:11 I0508 21:57:11.405021 15510 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:11,532] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:14,850] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['388us', '237us', '217us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:14,851] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:14,852] [play_vexpect] vexpect macro complete in 3.420142s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:15 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::36586 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.4248 KiB (1:15.2976 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 21 rects, 900.608 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.57776 MiB (1:1.33286 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 35 rects, 988.695 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.59839 MiB (1:1.45166 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,095] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 38->38, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,096] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,096] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=37->38, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,096] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.35s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,096] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=12.0 episode_count=10 episode_duration=22.16\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,097] [INFO:universe.wrappers.logger] Stats for the past 12.13s: vnc_updates_ps=1.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1607.4 vnc_pixels_ps[total]=9066.4 reward_lag=None rewarder_message_lag=None fps=13.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,107] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:15,108] [INFO:universe.pyprofile] [pyprofile] period=12.14s timers={\"rewarder.sleep\": {\"calls\": 167, \"std\": \"153.97us\", \"mean\": \"16.32ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.41ms\", \"mean\": \"847.80us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.99ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"7.74us\", \"mean\": \"22.35us\"}, \"rewarder.compute_reward\": {\"calls\": 168, \"std\": \"848.81us\", \"mean\": \"273.74us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"27.13us\", \"mean\": \"44.98us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"89.30us\", \"mean\": \"175.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 168, \"std\": \"32.51us\", \"mean\": \"76.08us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"15.55us\", \"mean\": \"54.89us\"}, \"rewarder.frame\": {\"calls\": 168, \"std\": \"1.16ms\", \"mean\": \"16.66ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 168, \"std\": 2.0942982053450074, \"mean\": 0.23809523809523808}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 3.2071349029490928, \"value\": 10, \"mean\": 21.142857142857142}} (export_time=177.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:16,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:17,597] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:19,131] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:20,113] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21943.4 vnc_pixels_ps[total]=96095.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:20,114] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.83ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.69ms\", \"mean\": \"2.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"24.88us\", \"mean\": \"46.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.70ms\", \"mean\": \"512.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.79ms\", \"mean\": \"10.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"125.84us\", \"mean\": \"259.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.50us\", \"mean\": \"89.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"32.37us\", \"mean\": \"91.14us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.50us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 0.6900655593423543, \"mean\": 1.1428571428571428}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.295555860859078, \"mean\": 0.0963455149501661}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 2.448483998646024, \"value\": 18.0, \"mean\": 12.93103448275862}} (export_time=120.64us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:20,431] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:21,497] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:25,130] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8411.6 vnc_pixels_ps[total]=44926.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:25,130] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.10ms\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.31ms\", \"mean\": \"1.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"18.98us\", \"mean\": \"42.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.09ms\", \"mean\": \"371.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.73ms\", \"mean\": \"9.45ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"94.80us\", \"mean\": \"239.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.61us\", \"mean\": \"94.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"37.45us\", \"mean\": \"97.14us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"49.06us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.7927203222605983, \"value\": 23.0, \"mean\": 21.423076923076927}} (export_time=144.96us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:25,130] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,863] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=205us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,863] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,863] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.73s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,863] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 38->39, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=39\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,864] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,865] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:27,884] init detected end of child process 15237 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:27,888] init detected end of child process 15252 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:27,892] init detected end of child process 15461 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:27,892] init detected end of child process 15454 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:27,910] init detected end of child process 15483 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,953] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:27,953] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:28 [info] 70#70: *205 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:28 [info] 70#70: *206 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:28 [info] 70#70: *207 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:28 [info] 70#70: *204 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:28,052] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:28,253] init detected end of child process 15240 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:28,253] init detected end of child process 15248 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:28,253] init detected end of child process 15249 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:28,253] init detected end of child process 15251 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:29,459] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.41s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:29,464] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:33,524] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,201] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,201] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,201] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,202] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,203] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,203] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:34 I0508 21:57:34.20411 15878 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:34 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::36912\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:34 I0508 21:57:34.209019 15878 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:34,366] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,467] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['216us', '113us', '117us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,467] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,468] [play_vexpect] vexpect macro complete in 2.222501s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:36 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::36912 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 17 rects, 917.504 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.62603 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 30 rects, 997.399 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.64511 MiB (1:1.43855 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,638] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 39->39, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,646] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,652] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=38->39, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,656] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.79s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,657] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=14.0 episode_count=14 episode_duration=21.56\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,663] [INFO:universe.wrappers.logger] Stats for the past 11.53s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2106.1 vnc_pixels_ps[total]=10082.0 reward_lag=None rewarder_message_lag=None fps=14.31\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,720] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:36,721] [INFO:universe.pyprofile] [pyprofile] period=11.59s timers={\"rewarder.sleep\": {\"calls\": 164, \"std\": \"487.12us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 15, \"std\": \"14.53ms\", \"mean\": \"4.35ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"35.98ms\", \"mean\": \"30.98ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 45, \"std\": \"9.86us\", \"mean\": \"24.38us\"}, \"rewarder.compute_reward\": {\"calls\": 165, \"std\": \"4.55ms\", \"mean\": \"613.86us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.45us\", \"mean\": \"37.03us\"}, \"reward.parsing.gameover\": {\"calls\": 15, \"std\": \"74.17us\", \"mean\": \"179.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 165, \"std\": \"31.16us\", \"mean\": \"82.08us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 15, \"std\": \"19.25us\", \"mean\": \"56.58us\"}, \"rewarder.frame\": {\"calls\": 165, \"std\": \"1.20ms\", \"mean\": \"16.66ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.33333333333333337}, \"reward.vnc.updates.n\": {\"calls\": 165, \"std\": 2.036710389123799, \"mean\": 0.2424242424242424}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 39, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 15, \"std\": 3.5697138740881105, \"value\": 10, \"mean\": 22.8}} (export_time=139.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:37,689] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=3.0 reward_min=1 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2166 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:41,673] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18480.3 vnc_pixels_ps[total]=87729.1 reward_lag=None rewarder_message_lag=None fps=59.49\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:41,723] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.29ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.34ms\", \"mean\": \"1.52ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"11.64us\", \"mean\": \"42.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.46ms\", \"mean\": \"438.74us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"36.59ms\", \"mean\": \"26.93ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.57ms\", \"mean\": \"15.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"36.11us\", \"mean\": \"234.97us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"591.80us\", \"mean\": \"138.78us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"15.34us\", \"mean\": \"82.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"3.10ms\", \"mean\": \"17.09ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896257, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.268857754044954, \"value\": 14.0, \"mean\": 13.119999999999996}} (export_time=124.93us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:41,723] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.03s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2049 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,540] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=362us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,540] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,540] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,540] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,541] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,541] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 39->40, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,541] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,542] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,543] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=40\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,543] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,545] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:44,577] init detected end of child process 15601 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:44,584] init detected end of child process 15616 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:44,585] init detected end of child process 15818 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:44,586] init detected end of child process 15824 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:44,603] init detected end of child process 15845 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:57:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,674] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,674] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:44 [info] 70#70: *209 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:44 [info] 70#70: *210 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:44 [info] 70#70: *211 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:57:44 [info] 70#70: *208 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:44,819] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:45,049] init detected end of child process 15604 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:45,049] init detected end of child process 15612 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:45,049] init detected end of child process 15613 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:57:45,049] init detected end of child process 15615 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:47,176] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 2.36s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:47,177] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:52,953] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,749] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,749] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,749] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,750] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,756] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,756] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:53 I0508 21:57:53.757299 16232 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:53 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37090\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:57:53 I0508 21:57:53.769015 16232 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:53,958] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,681] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['356us', '239us', '192us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,682] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,682] [play_vexpect] vexpect macro complete in 1.889082s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:57:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37090 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 12.497 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.69043 KiB (1:28.8989 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 19 rects, 892.928 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.55574 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 33 rects, 973.791 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.57496 MiB (1:1.44278 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,931] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 40->40, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,942] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,942] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=39->40, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.40s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,943] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=4.0 episode_count=5 episode_duration=19.28\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,944] [INFO:universe.wrappers.logger] Stats for the past 14.27s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1535.6 vnc_pixels_ps[total]=8971.6 reward_lag=None rewarder_message_lag=None fps=12.12\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,971] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:55,972] [INFO:universe.pyprofile] [pyprofile] period=14.25s timers={\"rewarder.sleep\": {\"calls\": 169, \"std\": \"329.88us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"6.75ms\", \"mean\": \"2.08ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"25.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"11.45us\", \"mean\": \"36.63us\"}, \"rewarder.compute_reward\": {\"calls\": 170, \"std\": \"2.16ms\", \"mean\": \"443.37us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"35.33us\", \"mean\": \"70.17us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"128.33us\", \"mean\": \"273.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 170, \"std\": \"201.18us\", \"mean\": \"99.61us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"19.39us\", \"mean\": \"74.44us\"}, \"rewarder.frame\": {\"calls\": 170, \"std\": \"1.13ms\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 170, \"std\": 1.9299966004705953, \"mean\": 0.22352941176470592}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 1.0690449676496974, \"value\": 10, \"mean\": 13.714285714285714}} (export_time=266.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:57:56,954] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 3 reward messages to agent: reward=4.0 reward_min=1 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:00,953] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17174.4 vnc_pixels_ps[total]=83789.4 reward_lag=None rewarder_message_lag=None fps=59.50\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:00,987] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 297, \"std\": \"1.86ms\", \"mean\": \"15.67ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"7.21ms\", \"mean\": \"2.47ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.44us\", \"mean\": \"58.62us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"2.27ms\", \"mean\": \"624.22us\"}, \"rewarder.sleep.missed\": {\"calls\": 3, \"std\": \"7.83ms\", \"mean\": \"14.48ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.48ms\", \"mean\": \"25.32ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"102.19us\", \"mean\": \"327.65us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"715.22us\", \"mean\": \"216.63us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.17us\", \"mean\": \"106.98us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"2.16ms\", \"mean\": \"17.27ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.271746488194703, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0134958870382644, \"value\": 14.0, \"mean\": 13.374999999999998}} (export_time=204.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:00,987] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.03s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2047 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,605] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=407us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,606] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,612] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.63s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,617] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,621] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,622] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 40->41, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,622] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,627] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,627] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=41\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,627] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,628] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:02,667] init detected end of child process 15955 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:02,679] init detected end of child process 15970 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:02,681] init detected end of child process 16172 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:02,683] init detected end of child process 16177 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:02,717] init detected end of child process 16199 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,782] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,782] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:02 [info] 70#70: *213 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:02 [info] 70#70: *214 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:02 [info] 70#70: *215 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:02 [info] 70#70: *212 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:02,923] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:03,017] init detected end of child process 15958 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:03,017] init detected end of child process 15966 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:03,017] init detected end of child process 15967 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:03,017] init detected end of child process 15969 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:04,174] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:04,175] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:07,735] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,219] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,219] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,219] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'compress_level': 0, 'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,220] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,227] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,227] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:58:08 I0508 21:58:08.22737 16587 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:58:08 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37234\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:58:08 I0508 21:58:08.233118 16587 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:08,355] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,689] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['194us', '140us', '147us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,690] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,690] [play_vexpect] vexpect macro complete in 3.428999s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:58:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37234 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3535 KiB (1:15.3539 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 36 rects, 1.09619 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.13779 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 50 rects, 1.18428 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.15834 MiB (1:1.43057 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,906] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 41->41, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,907] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,907] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=40->41, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,908] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.29s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,908] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=4.0 episode_count=5 episode_duration=15.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,909] [INFO:universe.wrappers.logger] Stats for the past 10.95s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1338.9 vnc_pixels_ps[total]=6750.1 reward_lag=None rewarder_message_lag=None fps=9.13\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,919] [INFO:gym_controlplane.reward.reward] First score parsed: score=16. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:11,920] [INFO:universe.pyprofile] [pyprofile] period=10.93s timers={\"rewarder.sleep\": {\"calls\": 97, \"std\": \"1.07ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"3.10ms\", \"mean\": \"1.24ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.91ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"12.68us\", \"mean\": \"31.79us\"}, \"rewarder.compute_reward\": {\"calls\": 98, \"std\": \"1.64ms\", \"mean\": \"568.30us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"22.27us\", \"mean\": \"46.01us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"617.13us\", \"mean\": \"401.93us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 98, \"std\": \"861.01us\", \"mean\": \"193.18us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"22.61us\", \"mean\": \"69.71us\"}, \"rewarder.frame\": {\"calls\": 98, \"std\": \"606.39us\", \"mean\": \"16.87ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 98, \"std\": 2.7334799206013454, \"mean\": 0.36734693877551017}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 1.2649110640673518, \"value\": 10, \"mean\": 13.6}} (export_time=114.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:13,147] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.24s, sent 3 reward messages to agent: reward=13.0 reward_min=2 reward_max=6 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<2074 bytes>', 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:14,491] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.34s, sent 2 reward messages to agent: reward=6.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:15,775] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=6.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:16,925] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21914.1 vnc_pixels_ps[total]=95744.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:16,925] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.65ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.13ms\", \"mean\": \"2.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"17.85us\", \"mean\": \"39.15us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.48ms\", \"mean\": \"473.59us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"3.59ms\", \"mean\": \"9.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"86.88us\", \"mean\": \"220.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.39us\", \"mean\": \"100.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"24.85us\", \"mean\": \"82.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.80us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.618347187425374, \"mean\": 3.5714285714285716}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2955558608590778, \"mean\": 0.09634551495016608}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 6.3046624392513255, \"value\": 35.0, \"mean\": 25.965517241379306}} (export_time=118.02us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:16,925] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:20,541] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.62s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:21,941] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6990.8 vnc_pixels_ps[total]=44287.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:21,942] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"529.53us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.56ms\", \"mean\": \"730.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"15.69us\", \"mean\": \"36.35us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"522.19us\", \"mean\": \"305.69us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"330.26us\", \"mean\": \"5.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"78.08us\", \"mean\": \"205.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.58us\", \"mean\": \"92.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"25.26us\", \"mean\": \"80.63us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.58us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 2.0816659994661326, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.9790570145063202, \"value\": 40.0, \"mean\": 36.199999999999996}} (export_time=178.81us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:21,942] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.40s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:23,141] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:24,658] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1347, 'rewarder.vnc.updates.pixels': 9824, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:26,391] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:26,958] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9213.8 vnc_pixels_ps[total]=44971.1 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:26,958] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"651.15us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"1.87ms\", \"mean\": \"990.88us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"9.59us\", \"mean\": \"26.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"642.97us\", \"mean\": \"302.47us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"152.41us\", \"mean\": \"5.13ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"40.74us\", \"mean\": \"153.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.32us\", \"mean\": \"85.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"16.34us\", \"mean\": \"66.39us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.48us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.6431676725154984, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.0203488411948576, \"value\": 49.0, \"mean\": 43.74074074074074}} (export_time=87.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:31,975] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5936.8 vnc_pixels_ps[total]=44005.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:31,975] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"196.14us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"79.74us\", \"mean\": \"291.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.58us\", \"mean\": \"40.22us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"186.37us\", \"mean\": \"267.74us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"85.13us\", \"mean\": \"227.65us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.65us\", \"mean\": \"92.23us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"21.95us\", \"mean\": \"86.14us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.36us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 49.0, \"mean\": 49.0}} (export_time=189.07us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:31,976] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.58s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:34,609] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.63s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:36,358] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:36,991] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8370.7 vnc_pixels_ps[total]=44584.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:36,992] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"735.59us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.16ms\", \"mean\": \"1.02ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"17.48us\", \"mean\": \"36.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"726.53us\", \"mean\": \"326.52us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"933.31us\", \"mean\": \"6.51ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"90.54us\", \"mean\": \"208.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.50us\", \"mean\": \"93.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.49us\", \"mean\": \"76.05us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.27us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.6792855623746645, \"value\": 53.0, \"mean\": 50.50000000000001}} (export_time=109.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,741] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=233us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,741] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.38s, sent 3 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 41->42, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=42\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,742] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,743] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:41,753] init detected end of child process 16314 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:41,760] init detected end of child process 16329 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:41,761] init detected end of child process 16531 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:41,763] init detected end of child process 16537 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:41,782] init detected end of child process 16559 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:58:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,816] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,816] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:41,902] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:41 [info] 70#70: *217 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:41 [info] 70#70: *218 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:41 [info] 70#70: *219 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:58:41 [info] 70#70: *216 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:42,097] init detected end of child process 16317 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:42,097] init detected end of child process 16325 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:42,097] init detected end of child process 16326 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:58:42,097] init detected end of child process 16328 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,153] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,154] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,188] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,723] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,723] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,723] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,724] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,733] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,733] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:58:43 I0508 21:58:43.733841 16937 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:58:43 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37376\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:58:43 I0508 21:58:43.736937 16937 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:43,860] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:47,877] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,661] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['289us', '213us', '178us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,661] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,662] [play_vexpect] vexpect macro complete in 6.894524s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:58:50 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37376 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.978 KiB (1:10.3299 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09244 MiB (1:2.76016 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,924] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 42->42, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,925] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,925] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=41->42, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,926] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.18s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,926] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=44.0 episode_count=22 episode_duration=39.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,927] [INFO:universe.wrappers.logger] Stats for the past 13.93s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2413.3 vnc_pixels_ps[total]=15411.9 reward_lag=None rewarder_message_lag=None fps=20.52\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,935] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:50,935] [INFO:universe.pyprofile] [pyprofile] period=13.94s timers={\"rewarder.sleep\": {\"calls\": 285, \"std\": \"138.93us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.52ms\", \"mean\": \"543.67us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.36ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.45us\", \"mean\": \"26.47us\"}, \"rewarder.compute_reward\": {\"calls\": 286, \"std\": \"530.72us\", \"mean\": \"268.41us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.59us\", \"mean\": \"34.77us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"65.98us\", \"mean\": \"170.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 286, \"std\": \"43.14us\", \"mean\": \"100.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.83us\", \"mean\": \"64.05us\"}, \"rewarder.frame\": {\"calls\": 286, \"std\": \"903.09us\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.33333333333333337}, \"reward.vnc.updates.n\": {\"calls\": 286, \"std\": 1.730941934430646, \"mean\": 0.17832167832167833}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 9.167523016653384, \"value\": 10, \"mean\": 52.04347826086956}} (export_time=103.71us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:51,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2150 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:55,643] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.70s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:55,944] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18917.9 vnc_pixels_ps[total]=96768.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:55,945] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"845.94us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.89ms\", \"mean\": \"862.07us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"21.43us\", \"mean\": \"46.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"644.49us\", \"mean\": \"366.20us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.88ms\", \"mean\": \"6.73ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"112.69us\", \"mean\": \"265.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.65us\", \"mean\": \"111.90us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"32.65us\", \"mean\": \"96.61us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.06us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 2.0816659994661326, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.953939201416946, \"value\": 15.0, \"mean\": 10.919999999999998}} (export_time=340.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:58,026] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:58:59,543] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:00,960] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9255.5 vnc_pixels_ps[total]=45360.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:00,961] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"998.96us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.84ms\", \"mean\": \"1.43ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"17.93us\", \"mean\": \"44.21us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"976.72us\", \"mean\": \"434.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.09ms\", \"mean\": \"7.60ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"89.03us\", \"mean\": \"249.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.40us\", \"mean\": \"114.90us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"25.51us\", \"mean\": \"88.20us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.35us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.7748873851023212, \"mean\": 2.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.0897009966777409}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.7953337672144727, \"value\": 26.0, \"mean\": 17.59259259259259}} (export_time=331.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:00,962] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.42s, sent 2 reward messages to agent: reward=7.0 reward_min=0 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:02,793] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.83s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:04,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:05,977] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9275.6 vnc_pixels_ps[total]=45517.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:05,977] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.74ms\", \"mean\": \"1.83ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"22.92us\", \"mean\": \"54.08us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.28ms\", \"mean\": \"495.29us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.06ms\", \"mean\": \"9.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"112.02us\", \"mean\": \"306.41us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.56us\", \"mean\": \"122.35us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"25.06us\", \"mean\": \"103.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"42.27us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.6012815380508714, \"value\": 30.0, \"mean\": 27.88888888888889}} (export_time=204.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:05,978] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1916 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:09,060] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:10,993] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.4 vnc_pixels_ps[total]=44297.1 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:10,994] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"799.60us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.42ms\", \"mean\": \"875.04us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.14us\", \"mean\": \"58.79us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"783.40us\", \"mean\": \"398.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.72ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"103.85us\", \"mean\": \"331.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.52us\", \"mean\": \"118.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"20.89us\", \"mean\": \"108.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.37us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4815434123430752, \"value\": 33.0, \"mean\": 32.333333333333336}} (export_time=129.22us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:10,994] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.93s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:13,393] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.40s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:15,994] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"935.85us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.94ms\", \"mean\": \"934.31us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"24.64us\", \"mean\": \"55.19us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"928.29us\", \"mean\": \"390.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"124.17us\", \"mean\": \"310.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.51us\", \"mean\": \"113.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"24.53us\", \"mean\": \"101.35us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"18.20us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.08333333333333334}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5099019513592792, \"value\": 34.0, \"mean\": 33.48}} (export_time=292.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:15,995] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:16,011] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7013.7 vnc_pixels_ps[total]=46206.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:17,727] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:21,009] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"597.67us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.69ms\", \"mean\": \"733.89us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.61us\", \"mean\": \"53.06us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"568.93us\", \"mean\": \"394.28us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.15ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"102.21us\", \"mean\": \"301.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.91us\", \"mean\": \"122.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.54us\", \"mean\": \"110.72us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.48us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.4869847535576724, \"value\": 35.0, \"mean\": 34.652173913043484}} (export_time=162.60us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:21,010] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.28s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:21,026] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6770.6 vnc_pixels_ps[total]=44307.0 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,660] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=567us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,661] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,661] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.65s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,661] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,661] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,662] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 42->43, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,662] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,662] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,663] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=43\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,663] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,664] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,682] init detected end of child process 16688 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,687] init detected end of child process 16703 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,689] init detected end of child process 16905 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,691] init detected end of child process 16912 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,712] init detected end of child process 16934 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,745] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,746] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:23 [info] 70#70: *221 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:23 [info] 70#70: *222 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:23 [info] 70#70: *223 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:23 [info] 70#70: *220 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:23,832] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,981] init detected end of child process 16691 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,981] init detected end of child process 16699 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,981] init detected end of child process 16700 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:23,981] init detected end of child process 16702 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:25,095] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:25,096] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:28,514] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,024] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,025] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,025] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,025] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,028] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,028] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:59:29 I0508 21:59:29.029147 17340 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:59:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37612\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:59:29 I0508 21:59:29.032039 17340 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:29,152] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,486] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['237us', '82us', '57us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,487] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,487] [play_vexpect] vexpect macro complete in 1.424315s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:59:30 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37612 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 5 rects, 74.914 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  18.5918 KiB (1:15.743 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 36 rects, 1.09619 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.13779 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 45 rects, 1.18286 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.15751 MiB (1:1.42922 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,718] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 43->43, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,719] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,719] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=42->43, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,719] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.06s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,719] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=25.0 episode_count=21 episode_duration=39.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,720] [INFO:universe.wrappers.logger] Stats for the past 9.69s: vnc_updates_ps=1.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2130.6 vnc_pixels_ps[total]=12265.2 reward_lag=None rewarder_message_lag=None fps=16.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,729] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:30,730] [INFO:universe.pyprofile] [pyprofile] period=9.72s timers={\"rewarder.sleep\": {\"calls\": 159, \"std\": \"232.60us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.13ms\", \"mean\": \"913.84us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"21.61us\", \"mean\": \"44.68us\"}, \"rewarder.compute_reward\": {\"calls\": 160, \"std\": \"798.73us\", \"mean\": \"410.45us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"32.20us\", \"mean\": \"58.29us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"201.88us\", \"mean\": \"318.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 160, \"std\": \"49.02us\", \"mean\": \"113.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"32.88us\", \"mean\": \"91.69us\"}, \"rewarder.frame\": {\"calls\": 160, \"std\": \"1.07ms\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 160, \"std\": 1.5205096795267667, \"mean\": 0.20000000000000004}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 6.68153104781061, \"value\": 10, \"mean\": 33.214285714285715}} (export_time=121.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:33,937] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.22s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:35,736] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14939.3 vnc_pixels_ps[total]=80161.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:35,746] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"714.80us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.11ms\", \"mean\": \"883.90us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.77us\", \"mean\": \"40.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"691.56us\", \"mean\": \"336.08us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.84ms\", \"mean\": \"7.14ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"112.92us\", \"mean\": \"226.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.00us\", \"mean\": \"101.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"36.15us\", \"mean\": \"88.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.32us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.4836060651405207, \"value\": 13.0, \"mean\": 11.125000000000002}} (export_time=77.01us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:35,747] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.81s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 1368}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:39,003] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.26s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:40,753] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7340.4 vnc_pixels_ps[total]=42809.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:40,754] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"721.21us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.14ms\", \"mean\": \"446.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"8.90us\", \"mean\": \"26.19us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"358.15us\", \"mean\": \"249.85us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.43ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"32.19us\", \"mean\": \"149.25us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.86us\", \"mean\": \"97.59us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"16.25us\", \"mean\": \"60.84us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.86us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 1.4015801359431266, \"value\": 18.0, \"mean\": 16.347826086956527}} (export_time=168.56us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:40,754] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1914 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,520] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=220us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,520] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,520] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,520] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,520] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 43->44, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,521] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,521] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,521] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=44\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,521] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,521] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,536] init detected end of child process 17058 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,540] init detected end of child process 17073 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,542] init detected end of child process 17275 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,544] init detected end of child process 17282 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,561] init detected end of child process 17304 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 21:59:41 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,600] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,600] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:41,683] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:41 [info] 70#70: *225 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:41 [info] 70#70: *226 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:41 [info] 70#70: *227 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 21:59:41 [info] 70#70: *224 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,925] init detected end of child process 17061 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,925] init detected end of child process 17069 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,925] init detected end of child process 17070 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 21:59:41,925] init detected end of child process 17072 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:42,991] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.31s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:42,991] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,322] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,830] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,830] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,830] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,831] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,832] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,832] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:59:46 I0508 21:59:46.832962 17696 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:59:46 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37758\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 21:59:46 I0508 21:59:46.837034 17696 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:46,964] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:50,981] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,265] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['300us', '168us', '147us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,266] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,266] [play_vexpect] vexpect macro complete in 5.399806s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 21:59:52 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37758 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9268 KiB (1:15.7293 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 44 rects, 1.08649 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.85644 MiB (1:1.45115 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,544] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 44->44, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,544] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,544] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=43->44, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,544] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.79s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,545] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=8.0 episode_count=7 episode_duration=21.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,546] [INFO:universe.wrappers.logger] Stats for the past 11.79s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=866.3 vnc_pixels_ps[total]=3494.5 reward_lag=None rewarder_message_lag=None fps=3.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,556] [INFO:gym_controlplane.reward.reward] First score parsed: score=31. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:52,557] [INFO:universe.pyprofile] [pyprofile] period=11.80s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"243.30us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"3.63ms\", \"mean\": \"1.69ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.84ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"10.91us\", \"mean\": \"21.95us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"1.60ms\", \"mean\": \"480.08us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"23.26us\", \"mean\": \"45.18us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"114.09us\", \"mean\": \"229.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"37.48us\", \"mean\": \"93.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"27.33us\", \"mean\": \"56.31us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.22ms\", \"mean\": \"16.44ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 5.244529328890355, \"mean\": 0.8723404255319149}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 3.265986323710904, \"value\": 10, \"mean\": 16.666666666666668}} (export_time=177.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:55,012] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.47s, sent 5 reward messages to agent: reward=25.0 reward_min=-3.0 reward_max=21 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2090 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:56,745] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:57,562] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22547.3 vnc_pixels_ps[total]=111904.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 21:59:57,563] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.54ms\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.11ms\", \"mean\": \"1.93ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"22.31us\", \"mean\": \"40.45us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.36ms\", \"mean\": \"441.26us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.99ms\", \"mean\": \"10.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"108.64us\", \"mean\": \"228.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.50us\", \"mean\": \"108.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"24.11us\", \"mean\": \"85.20us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.89us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 7.674943772091226, \"mean\": 4.285714285714286}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.0248456731316553, \"value\": 38.0, \"mean\": 34.50000000000001}} (export_time=202.18us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:00,211] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.47s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:02,578] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6807.3 vnc_pixels_ps[total]=44535.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:02,578] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"390.90us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.09ms\", \"mean\": \"469.79us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.35us\", \"mean\": \"31.25us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"362.01us\", \"mean\": \"271.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"75.90us\", \"mean\": \"178.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.83us\", \"mean\": \"91.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.24us\", \"mean\": \"73.17us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.31us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.5108304655560034, \"value\": 43.0, \"mean\": 41.25000000000001}} (export_time=92.74us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:02,579] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.37s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,278] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=216us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,278] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,278] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,278] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,279] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 44->45, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,279] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,279] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,279] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=45\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,279] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,280] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,290] init detected end of child process 17423 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,296] init detected end of child process 17438 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,297] init detected end of child process 17640 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,299] init detected end of child process 17648 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,315] init detected end of child process 17670 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:00:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:00:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:00:03 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,360] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,360] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:03 [info] 70#70: *229 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:03 [info] 70#70: *230 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:03 [info] 70#70: *231 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:03 [info] 70#70: *228 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:03,445] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,689] init detected end of child process 17426 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,689] init detected end of child process 17434 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,689] init detected end of child process 17435 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:00:03,690] init detected end of child process 17437 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:04,669] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.22s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:04,669] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,230] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,752] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,752] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,752] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'subsample_level': 2, 'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,752] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,759] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,759] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:00:08 I0508 22:00:08.759806 18060 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:00:08 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::37900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:00:08 I0508 22:00:08.76209 18060 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:08,887] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,204] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['181us', '93us', '82us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,204] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,205] [play_vexpect] vexpect macro complete in 2.408628s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:00:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::37900 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.9189 KiB (1:15.7352 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 44 rects, 1.08649 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.85643 MiB (1:1.45116 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,444] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 45->45, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,444] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,444] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=44->45, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,444] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.87s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,445] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=33.0 episode_count=11 episode_duration=18.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,446] [INFO:universe.wrappers.logger] Stats for the past 8.87s: vnc_updates_ps=0.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1144.1 vnc_pixels_ps[total]=4611.7 reward_lag=None rewarder_message_lag=None fps=4.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,454] [INFO:gym_controlplane.reward.reward] First score parsed: score=16. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:11,454] [INFO:universe.pyprofile] [pyprofile] period=8.88s timers={\"rewarder.sleep\": {\"calls\": 42, \"std\": \"221.66us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"3.14ms\", \"mean\": \"1.51ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.77ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"17.53us\", \"mean\": \"24.91us\"}, \"rewarder.compute_reward\": {\"calls\": 43, \"std\": \"1.39ms\", \"mean\": \"465.93us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"22.24us\", \"mean\": \"41.88us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"109.88us\", \"mean\": \"235.99us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 43, \"std\": \"32.06us\", \"mean\": \"93.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"31.24us\", \"mean\": \"55.31us\"}, \"rewarder.frame\": {\"calls\": 43, \"std\": \"2.34ms\", \"mean\": \"16.41ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 43, \"std\": 3.656181525089739, \"mean\": 0.6744186046511628}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 13.47219358530748, \"value\": 10, \"mean\": 37.5}} (export_time=116.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:13,245] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.80s, sent 2 reward messages to agent: reward=8.0 reward_min=2.0 reward_max=6 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2072 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:14,778] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:16,078] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:16,461] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20142.9 vnc_pixels_ps[total]=88570.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:16,462] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.48ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.05ms\", \"mean\": \"1.90ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"15.40us\", \"mean\": \"34.02us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.36ms\", \"mean\": \"409.29us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"4.84ms\", \"mean\": \"8.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"70.38us\", \"mean\": \"190.71us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.75us\", \"mean\": \"95.35us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"15.60us\", \"mean\": \"69.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.00us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.9407902170679516, \"mean\": 2.1666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609667, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.516611478423584, \"value\": 23.0, \"mean\": 18.77777777777778}} (export_time=103.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:17,795] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:19,129] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.33s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:21,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.92s, sent 2 reward messages to agent: reward=7.0 reward_min=1.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:21,478] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10890.5 vnc_pixels_ps[total]=45801.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:21,479] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.09ms\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 30, \"std\": \"2.99ms\", \"mean\": \"1.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 90, \"std\": \"13.81us\", \"mean\": \"32.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.09ms\", \"mean\": \"381.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.94ms\", \"mean\": \"6.61ms\"}, \"reward.parsing.gameover\": {\"calls\": 30, \"std\": \"69.59us\", \"mean\": \"182.65us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.83us\", \"mean\": \"88.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 30, \"std\": \"21.05us\", \"mean\": \"66.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.77us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 2.136976056643281, \"mean\": 2.1666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.3000553658766364, \"mean\": 0.0996677740863787}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 90, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 30, \"std\": 5.190730021964113, \"value\": 36.0, \"mean\": 28.566666666666666}} (export_time=117.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:22,795] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 3 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:24,529] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:26,495] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8657.7 vnc_pixels_ps[total]=46750.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:26,495] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"861.53us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.62ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.34us\", \"mean\": \"39.17us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"856.68us\", \"mean\": \"355.67us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.74ms\", \"mean\": \"7.27ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"82.03us\", \"mean\": \"221.68us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.02us\", \"mean\": \"96.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"23.00us\", \"mean\": \"81.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.20us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.011122916336885, \"value\": 43.0, \"mean\": 39.73076923076923}} (export_time=87.26us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:26,495] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:29,512] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.02s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:31,512] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7618.9 vnc_pixels_ps[total]=44881.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:31,513] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.26ms\", \"mean\": \"1.14ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.47us\", \"mean\": \"37.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"352.43us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"6.29ms\", \"mean\": \"10.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"85.08us\", \"mean\": \"216.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.83us\", \"mean\": \"97.30us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"22.05us\", \"mean\": \"80.85us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.99us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.7071067811865474, \"value\": 45.0, \"mean\": 44.199999999999996}} (export_time=181.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:31,513] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:33,411] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.90s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:36,445] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:36,528] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8407.8 vnc_pixels_ps[total]=44815.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:36,529] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"764.07us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.28ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.91us\", \"mean\": \"36.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"755.24us\", \"mean\": \"349.80us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"734.43us\", \"mean\": \"6.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"62.78us\", \"mean\": \"202.47us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.03us\", \"mean\": \"98.50us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"18.99us\", \"mean\": \"73.61us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.84us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4076712903012756, \"value\": 48.0, \"mean\": 46.69230769230769}} (export_time=117.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:40,362] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.92s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 318, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 2200, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:41,545] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6746.5 vnc_pixels_ps[total]=44093.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:41,546] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"809.30us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.59ms\", \"mean\": \"814.51us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"17.80us\", \"mean\": \"42.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"807.96us\", \"mean\": \"347.87us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"81.61us\", \"mean\": \"238.10us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.15us\", \"mean\": \"105.05us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"23.78us\", \"mean\": \"85.12us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.98us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531569}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.40824829046386285, \"value\": 53.0, \"mean\": 52.199999999999996}} (export_time=185.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:41,546] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.18s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:46,562] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5937.2 vnc_pixels_ps[total]=44008.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:46,563] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"213.98us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.81us\", \"mean\": \"295.75us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.55us\", \"mean\": \"42.55us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"193.60us\", \"mean\": \"296.57us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"74.91us\", \"mean\": \"240.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.75us\", \"mean\": \"102.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.95us\", \"mean\": \"85.84us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.93us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=184.54us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:46,564] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *236 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *237 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *238 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *239 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *240 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *241 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *242 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *243 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *244 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:00:50 [info] 70#70: *245 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:51,578] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5925.3 vnc_pixels_ps[total]=43955.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:51,579] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"261.55us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"100.64us\", \"mean\": \"327.85us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.67us\", \"mean\": \"47.67us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"205.44us\", \"mean\": \"313.96us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"841.38us\", \"mean\": \"1.11ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"106.15us\", \"mean\": \"266.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.63us\", \"mean\": \"105.99us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.73us\", \"mean\": \"95.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.62us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=172.85us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:51,579] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2123 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:56,595] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.2 vnc_pixels_ps[total]=44017.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:56,596] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"207.87us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"90.21us\", \"mean\": \"327.43us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.62us\", \"mean\": \"45.81us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"202.61us\", \"mean\": \"335.73us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"83.24us\", \"mean\": \"260.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.82us\", \"mean\": \"113.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.84us\", \"mean\": \"96.35us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.57us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910307}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=96.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:00:56,596] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1715 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:01,613] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6222.3 vnc_pixels_ps[total]=46170.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:01,613] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"253.28us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"87.35us\", \"mean\": \"367.96us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.70us\", \"mean\": \"57.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"247.31us\", \"mean\": \"343.04us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"105.86us\", \"mean\": \"317.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.73us\", \"mean\": \"113.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.89us\", \"mean\": \"105.85us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.99us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=261.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:01,614] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1724 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:04 [info] 70#70: *233 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:04 [info] 70#70: *234 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:04 [info] 70#70: *235 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:06,628] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5945.0 vnc_pixels_ps[total]=44108.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:06,629] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"307.61us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"125.90us\", \"mean\": \"366.56us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"17.65us\", \"mean\": \"50.49us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"227.93us\", \"mean\": \"323.39us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"86.24us\", \"mean\": \"286.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.84us\", \"mean\": \"107.56us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"40.99us\", \"mean\": \"108.05us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"31.00us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=144.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:06,629] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:11,645] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.2 vnc_pixels_ps[total]=44178.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:11,646] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"207.42us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"81.56us\", \"mean\": \"320.02us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"15.92us\", \"mean\": \"45.55us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"196.08us\", \"mean\": \"326.09us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"78.51us\", \"mean\": \"259.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.22us\", \"mean\": \"110.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.23us\", \"mean\": \"93.62us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.21us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=196.46us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:11,647] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:16,662] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.5 vnc_pixels_ps[total]=44343.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:16,663] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"236.39us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"86.83us\", \"mean\": \"305.10us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.75us\", \"mean\": \"42.31us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"192.91us\", \"mean\": \"304.45us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"88.52us\", \"mean\": \"241.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.31us\", \"mean\": \"106.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.27us\", \"mean\": \"88.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.14us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 53.0, \"mean\": 53.0}} (export_time=172.85us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:16,663] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,196] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=612us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,196] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,196] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,197] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,197] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,197] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 45->46, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,198] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,198] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,199] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=46\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,200] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,200] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,221] init detected end of child process 17787 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,225] init detected end of child process 17802 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,228] init detected end of child process 18010 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,247] init detected end of child process 18032 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,280] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,280] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:18,364] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,517] init detected end of child process 17790 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,517] init detected end of child process 17798 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,517] init detected end of child process 17799 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:18,517] init detected end of child process 17801 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:19,598] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:19,599] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,019] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,497] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,498] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,498] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,498] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,500] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,500] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:01:23 I0508 22:01:23.500741 18607 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:01:23 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::38194\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:01:23 I0508 22:01:23.505104 18607 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:23,623] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:27,657] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:27,990] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['152us', '61us', '55us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:27,990] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:27,991] [play_vexpect] vexpect macro complete in 4.456550s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:01:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::38194 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.8574 KiB (1:15.7816 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 34 rects, 1.06752 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.05569 MiB (1:1.33281 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 48 rects, 1.15235 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.07625 MiB (1:1.42915 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,196] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 46->46, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,196] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,196] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=45->46, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,197] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.00s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,197] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=43.0 episode_count=35 episode_duration=76.75\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,198] [INFO:universe.wrappers.logger] Stats for the past 11.54s: vnc_updates_ps=0.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1226.6 vnc_pixels_ps[total]=6103.5 reward_lag=None rewarder_message_lag=None fps=8.06\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,208] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:28,208] [INFO:universe.pyprofile] [pyprofile] period=11.55s timers={\"rewarder.sleep\": {\"calls\": 92, \"std\": \"286.85us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 9, \"std\": \"2.86ms\", \"mean\": \"1.25ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.68ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 27, \"std\": \"15.87us\", \"mean\": \"35.59us\"}, \"rewarder.compute_reward\": {\"calls\": 93, \"std\": \"1.07ms\", \"mean\": \"443.88us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"25.16us\", \"mean\": \"69.94us\"}, \"reward.parsing.gameover\": {\"calls\": 9, \"std\": \"262.32us\", \"mean\": \"314.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 93, \"std\": \"44.01us\", \"mean\": \"112.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 9, \"std\": \"35.58us\", \"mean\": \"77.46us\"}, \"rewarder.frame\": {\"calls\": 93, \"std\": \"1.33ms\", \"mean\": \"16.65ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 93, \"std\": 3.217893520562391, \"mean\": 0.41935483870967744}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 8, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 9, \"std\": 14.333333333333332, \"value\": 10, \"mean\": 48.22222222222222}} (export_time=181.67us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:33,214] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18175.8 vnc_pixels_ps[total]=102832.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:33,215] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"690.32us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"119.80us\", \"mean\": \"351.52us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.92us\", \"mean\": \"52.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"221.71us\", \"mean\": \"340.48us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"115.36us\", \"mean\": \"293.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.04us\", \"mean\": \"109.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"32.07us\", \"mean\": \"107.78us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.80us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=141.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:33,215] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=3 reward_min=0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:35,164] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:38,231] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6759.6 vnc_pixels_ps[total]=44282.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:38,231] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"826.97us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.65ms\", \"mean\": \"903.80us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"26.50us\", \"mean\": \"54.77us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"816.79us\", \"mean\": \"370.10us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"134.34us\", \"mean\": \"311.41us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.68us\", \"mean\": \"103.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"32.36us\", \"mean\": \"104.04us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.51us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0072203103706696, \"value\": 15.0, \"mean\": 14.166666666666666}} (export_time=138.28us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:38,231] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.07s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1901 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:42,964] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.73s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:43,248] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7577.4 vnc_pixels_ps[total]=44562.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:43,249] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"661.94us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.95ms\", \"mean\": \"949.83us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.22us\", \"mean\": \"55.20us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"662.48us\", \"mean\": \"419.22us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"684.63us\", \"mean\": \"7.10ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"107.79us\", \"mean\": \"310.38us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.59us\", \"mean\": \"118.35us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.97us\", \"mean\": \"109.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.31us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531565}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.4, \"value\": 17.0, \"mean\": 15.92}} (export_time=200.51us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:48,265] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.3 vnc_pixels_ps[total]=44025.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:48,266] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"319.34us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"135.26us\", \"mean\": \"453.60us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"30.10us\", \"mean\": \"68.99us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"298.64us\", \"mean\": \"426.34us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"149.66us\", \"mean\": \"384.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.77us\", \"mean\": \"136.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"35.18us\", \"mean\": \"130.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.74us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 17.0, \"mean\": 17.0}} (export_time=329.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:48,267] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.30s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,981] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=320us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,981] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,981] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.71s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,981] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,982] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,982] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 46->47, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,982] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,982] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,982] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=47\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,983] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:52,983] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:52,995] init detected end of child process 18326 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:52,999] init detected end of child process 18341 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,004] init detected end of child process 18589 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,005] init detected end of child process 18549 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,018] init detected end of child process 18570 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:01:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:53,057] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:53,057] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:53,144] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:53 [info] 70#70: *247 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:53 [info] 70#70: *248 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:53 [info] 70#70: *249 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:01:53 [info] 70#70: *246 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,317] init detected end of child process 18329 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,317] init detected end of child process 18337 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,317] init detected end of child process 18338 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:01:53,318] init detected end of child process 18340 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:54,396] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:54,397] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:54,861] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,358] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,358] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,358] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,358] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,365] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,365] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:01:55 I0508 22:01:55.365505 18942 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:01:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::38334\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:01:55 I0508 22:01:55.366831 18942 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:55,483] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:01:59,517] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,017] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['174us', '89us', '77us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,018] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,018] [play_vexpect] vexpect macro complete in 6.618900s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:02:02 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::38334 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 331.026 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.79 KiB (1:9.66615 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.2642 MiB (1:2.38515 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,157] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 47->47, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,157] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,158] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=46->47, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,159] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.18s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,159] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=7.0 episode_count=9 episode_duration=33.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,160] [INFO:universe.wrappers.logger] Stats for the past 13.89s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2392.2 vnc_pixels_ps[total]=15268.8 reward_lag=None rewarder_message_lag=None fps=20.44\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,169] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:02,170] [INFO:universe.pyprofile] [pyprofile] period=13.90s timers={\"rewarder.sleep\": {\"calls\": 283, \"std\": \"341.08us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.77ms\", \"mean\": \"765.12us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.88ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"26.13us\", \"mean\": \"58.93us\"}, \"rewarder.compute_reward\": {\"calls\": 284, \"std\": \"661.50us\", \"mean\": \"401.22us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.73us\", \"mean\": \"41.48us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"120.21us\", \"mean\": \"358.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 284, \"std\": \"44.44us\", \"mean\": \"118.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"36.19us\", \"mean\": \"114.30us\"}, \"rewarder.frame\": {\"calls\": 284, \"std\": \"857.45us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 284, \"std\": 1.5036907761674143, \"mean\": 0.1690140845070423}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.4288690166235205, \"value\": 10, \"mean\": 16.708333333333332}} (export_time=176.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:03,509] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.35s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2101 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:05,910] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.40s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:07,177] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18952.3 vnc_pixels_ps[total]=91367.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:07,178] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.52ms\", \"mean\": \"1.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.28us\", \"mean\": \"36.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"835.26us\", \"mean\": \"356.71us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"646.90us\", \"mean\": \"7.70ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"81.00us\", \"mean\": \"206.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.16us\", \"mean\": \"96.88us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"24.21us\", \"mean\": \"78.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.22us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662217, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.1374735838014687, \"value\": 14.0, \"mean\": 12.423076923076922}} (export_time=312.81us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:07,179] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.27s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:08,726] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:12,192] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7583.5 vnc_pixels_ps[total]=44564.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:12,193] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.18ms\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.63ms\", \"mean\": \"1.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"14.12us\", \"mean\": \"30.83us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.15ms\", \"mean\": \"315.54us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"11.97us\", \"mean\": \"13.16ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"68.31us\", \"mean\": \"177.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.68us\", \"mean\": \"86.22us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"17.52us\", \"mean\": \"65.33us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.84us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.9089300556994725, \"value\": 16.0, \"mean\": 15.115384615384615}} (export_time=77.72us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:12,193] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.47s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=217us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 47->48, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,026] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=48\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,027] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,027] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,040] init detected end of child process 18684 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,044] init detected end of child process 18699 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,046] init detected end of child process 18901 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,046] init detected end of child process 18908 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,064] init detected end of child process 18933 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:13 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:13 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:13 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,102] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,102] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:13,188] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:13 [info] 70#70: *251 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:13 [info] 70#70: *252 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:13 [info] 70#70: *253 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:13 [info] 70#70: *250 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,429] init detected end of child process 18687 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,429] init detected end of child process 18695 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,429] init detected end of child process 18696 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:13,430] init detected end of child process 18698 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:14,490] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.30s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:14,490] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:14,525] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,017] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,017] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,017] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,017] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,019] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,019] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:02:15 I0508 22:02:15.019723 19298 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:02:15 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::38476\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:02:15 I0508 22:02:15.021478 19298 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:15,140] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:19,190] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:23,224] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,007] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['249us', '135us', '119us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,008] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,008] [play_vexpect] vexpect macro complete in 8.954547s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:02:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::38476 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.048 KiB (1:10.325 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09251 MiB (1:2.75999 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,222] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 48->48, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,222] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,223] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=47->48, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,223] [INFO:universe.rewarder.remote] [Rewarder] Over past 12.03s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,223] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=6.0 episode_count=9 episode_duration=22.06\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,224] [INFO:universe.wrappers.logger] Stats for the past 12.03s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=843.2 vnc_pixels_ps[total]=3398.7 reward_lag=None rewarder_message_lag=None fps=4.24\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,233] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:24,233] [INFO:universe.pyprofile] [pyprofile] period=12.04s timers={\"rewarder.sleep\": {\"calls\": 50, \"std\": \"233.31us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"3.54ms\", \"mean\": \"1.83ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"17.31us\", \"mean\": \"25.92us\"}, \"rewarder.compute_reward\": {\"calls\": 51, \"std\": \"1.30ms\", \"mean\": \"427.01us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"24.49us\", \"mean\": \"42.84us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"98.98us\", \"mean\": \"263.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 51, \"std\": \"36.31us\", \"mean\": \"99.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"36.34us\", \"mean\": \"60.08us\"}, \"rewarder.frame\": {\"calls\": 51, \"std\": \"2.18ms\", \"mean\": \"16.46ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 51, \"std\": 5.176947393370488, \"mean\": 0.803921568627451}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 2.6832815729997477, \"value\": 10, \"mean\": 14.8}} (export_time=157.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:26,541] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.32s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2086 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:29,241] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20271.1 vnc_pixels_ps[total]=112635.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:29,242] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.08ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.97ms\", \"mean\": \"910.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"40.62us\", \"mean\": \"50.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"903.57us\", \"mean\": \"380.52us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.31ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"121.52us\", \"mean\": \"273.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.39us\", \"mean\": \"114.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.93us\", \"mean\": \"91.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.77us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5107539184552491, \"value\": 12.0, \"mean\": 11.500000000000002}} (export_time=233.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:29,242] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.70s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1884 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:31,991] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:33,507] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=6.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:34,258] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9223.2 vnc_pixels_ps[total]=45115.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:34,258] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.45ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.25ms\", \"mean\": \"2.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"16.92us\", \"mean\": \"59.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.45ms\", \"mean\": \"531.18us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.93ms\", \"mean\": \"11.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"74.51us\", \"mean\": \"332.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.40us\", \"mean\": \"123.51us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"24.18us\", \"mean\": \"111.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.46us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.3038404810405297, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.63009104735538, \"value\": 19.0, \"mean\": 13.925925925925926}} (export_time=218.39us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:34,807] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=7.0 reward_min=0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1914 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:36,324] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:37,840] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:39,274] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10045.2 vnc_pixels_ps[total]=45387.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:39,274] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"972.98us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.85ms\", \"mean\": \"1.91ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"20.36us\", \"mean\": \"45.06us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.34ms\", \"mean\": \"462.18us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"178.10us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"4.18ms\", \"mean\": \"8.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"100.64us\", \"mean\": \"253.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.18us\", \"mean\": \"106.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"31.81us\", \"mean\": \"87.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"37.25us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.632993161855452, \"mean\": 2.666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395345}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 4.815511752571417, \"value\": 37.0, \"mean\": 29.321428571428573}} (export_time=165.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:39,275] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.43s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2029 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:40,724] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,040] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=263us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.32s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 48->49, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,041] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=49\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,042] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,042] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,055] init detected end of child process 19047 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,058] init detected end of child process 19062 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,059] init detected end of child process 19271 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,060] init detected end of child process 19264 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,074] init detected end of child process 19296 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:02:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,115] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,115] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:44,203] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:44 [info] 70#70: *255 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:44 [info] 70#70: *256 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:44 [info] 70#70: *257 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:02:44 [info] 70#70: *254 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,429] init detected end of child process 19050 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,429] init detected end of child process 19058 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,429] init detected end of child process 19059 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:02:44,429] init detected end of child process 19061 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,438] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,438] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,474] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,970] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,970] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,970] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'encoding': 'zrle', 'fine_quality_level': 50, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,970] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,973] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:45,973] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:02:45 I0508 22:02:45.973491 19668 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:02:45 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::38634\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:02:45 I0508 22:02:45.975066 19668 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:46,097] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:50,147] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:53,881] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['176us', '88us', '79us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:53,881] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:53,882] [play_vexpect] vexpect macro complete in 7.874967s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:02:53 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::38634 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.204 KiB (1:10.321 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27229 MiB (1:2.37077 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,067] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 49->49, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,067] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,068] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=48->49, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,068] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.03s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,068] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=29.0 episode_count=17 episode_duration=29.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,069] [INFO:universe.wrappers.logger] Stats for the past 14.79s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2795.1 vnc_pixels_ps[total]=14367.0 reward_lag=None rewarder_message_lag=None fps=19.40\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,079] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:54,079] [INFO:universe.pyprofile] [pyprofile] period=14.80s timers={\"rewarder.sleep\": {\"calls\": 286, \"std\": \"479.40us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.18ms\", \"mean\": \"971.64us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.14ms\", \"mean\": \"6.31ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"7.58us\", \"mean\": \"23.95us\"}, \"rewarder.compute_reward\": {\"calls\": 287, \"std\": \"765.46us\", \"mean\": \"292.70us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"17.56us\", \"mean\": \"39.90us\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"62.80us\", \"mean\": \"162.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 287, \"std\": \"36.80us\", \"mean\": \"87.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"12.63us\", \"mean\": \"55.35us\"}, \"rewarder.frame\": {\"calls\": 287, \"std\": \"908.84us\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5773502691896257, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 287, \"std\": 2.0211112584509197, \"mean\": 0.20209059233449478}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 5.750941951831311, \"value\": 10, \"mean\": 37.36}} (export_time=111.10us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:59,086] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18176.6 vnc_pixels_ps[total]=102801.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:59,088] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"684.80us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"120.35us\", \"mean\": \"312.37us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"25.51us\", \"mean\": \"47.15us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"262.00us\", \"mean\": \"308.78us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"129.65us\", \"mean\": \"267.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.67us\", \"mean\": \"106.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.41us\", \"mean\": \"95.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.93us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910305}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=290.87us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:02:59,089] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:04,102] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6234.6 vnc_pixels_ps[total]=46191.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:04,102] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"352.45us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.35us\", \"mean\": \"260.23us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.80us\", \"mean\": \"35.05us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"168.05us\", \"mean\": \"276.64us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"73.93us\", \"mean\": \"198.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.18us\", \"mean\": \"99.05us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.81us\", \"mean\": \"76.49us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"71.67us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=99.90us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:04,102] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:05,135] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:09,118] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7598.3 vnc_pixels_ps[total]=44722.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:09,119] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"772.92us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.40ms\", \"mean\": \"962.96us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"21.28us\", \"mean\": \"38.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"767.89us\", \"mean\": \"320.55us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.74ms\", \"mean\": \"8.52ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"101.62us\", \"mean\": \"215.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.18us\", \"mean\": \"89.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.50us\", \"mean\": \"78.07us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.47us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 4.932882862316247, \"mean\": 3.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 4.8104053883222795, \"value\": 23.0, \"mean\": 19.159999999999997}} (export_time=114.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:09,119] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.98s, sent 2 reward messages to agent: reward=9.0 reward_min=0 reward_max=9.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:14,135] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.3 vnc_pixels_ps[total]=44018.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:14,135] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"194.33us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"88.85us\", \"mean\": \"267.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"15.57us\", \"mean\": \"38.76us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"172.91us\", \"mean\": \"279.01us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"82.66us\", \"mean\": \"221.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.97us\", \"mean\": \"94.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.38us\", \"mean\": \"79.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.50us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 23.0, \"mean\": 23.0}} (export_time=83.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:14,135] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:17,918] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.78s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:19,151] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6531.3 vnc_pixels_ps[total]=42418.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:19,152] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"357.14us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 22, \"std\": \"1.15ms\", \"mean\": \"454.02us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 66, \"std\": \"11.23us\", \"mean\": \"26.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"350.10us\", \"mean\": \"235.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.39ms\"}, \"reward.parsing.gameover\": {\"calls\": 22, \"std\": \"38.07us\", \"mean\": \"147.39us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.68us\", \"mean\": \"87.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 22, \"std\": \"10.92us\", \"mean\": \"58.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.51us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26071713009871506, \"mean\": 0.07308970099667773}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 22, \"std\": 0.4289320272288875, \"value\": 24.0, \"mean\": 23.22727272727273}} (export_time=120.40us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:19,152] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.23s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:24,169] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5879.6 vnc_pixels_ps[total]=43525.3 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:24,170] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"151.52us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"53.95us\", \"mean\": \"224.53us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.08us\", \"mean\": \"28.91us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"156.97us\", \"mean\": \"232.18us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"59.54us\", \"mean\": \"165.30us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.06us\", \"mean\": \"85.56us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.47us\", \"mean\": \"65.84us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.83us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=224.35us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:24,170] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:29,186] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.9 vnc_pixels_ps[total]=44184.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:29,187] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"246.22us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"70.78us\", \"mean\": \"317.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"13.96us\", \"mean\": \"44.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"203.41us\", \"mean\": \"340.57us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"64.29us\", \"mean\": \"253.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.76us\", \"mean\": \"115.72us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.48us\", \"mean\": \"90.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.51us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=243.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:29,187] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:34,202] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5965.8 vnc_pixels_ps[total]=44231.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:34,202] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"256.33us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"81.43us\", \"mean\": \"283.37us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.22us\", \"mean\": \"37.60us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"182.37us\", \"mean\": \"277.01us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"83.50us\", \"mean\": \"215.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.18us\", \"mean\": \"99.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.00us\", \"mean\": \"80.55us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.10us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=90.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:34,203] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:39,219] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5985.4 vnc_pixels_ps[total]=44382.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:39,220] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"195.91us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"70.18us\", \"mean\": \"265.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.76us\", \"mean\": \"37.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"181.01us\", \"mean\": \"280.31us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"98.63us\", \"mean\": \"210.86us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.98us\", \"mean\": \"95.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"21.01us\", \"mean\": \"83.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.53us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=240.09us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:39,221] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:44,235] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6162.9 vnc_pixels_ps[total]=45712.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:44,235] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"340.03us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"105.69us\", \"mean\": \"319.42us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.24us\", \"mean\": \"44.51us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"217.66us\", \"mean\": \"296.08us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"109.76us\", \"mean\": \"252.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.18us\", \"mean\": \"90.92us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"30.29us\", \"mean\": \"96.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"153.38us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=104.19us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:44,236] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:03:45 [info] 70#70: *259 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:03:45 [info] 70#70: *260 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:03:45 [info] 70#70: *261 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:49,236] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5972.8 vnc_pixels_ps[total]=44316.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:49,237] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"470.45us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"47.54us\", \"mean\": \"277.94us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.19us\", \"mean\": \"37.79us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"394.80us\", \"mean\": \"294.29us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"50.15us\", \"mean\": \"213.33us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"358.01us\", \"mean\": \"113.10us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"13.27us\", \"mean\": \"83.38us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"241.53us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2665063620734804, \"mean\": 0.07666666666666669}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=150.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:49,237] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:54,253] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.6 vnc_pixels_ps[total]=44020.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:54,254] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"291.99us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"40.18us\", \"mean\": \"271.97us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.52us\", \"mean\": \"39.83us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"176.30us\", \"mean\": \"266.89us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"68.48us\", \"mean\": \"219.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"86.71us\", \"mean\": \"86.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"12.03us\", \"mean\": \"84.63us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"145.58us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=157.83us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:54,254] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:59,268] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5987.1 vnc_pixels_ps[total]=44431.3 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:59,272] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"284.36us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"42.33us\", \"mean\": \"289.46us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"11.52us\", \"mean\": \"41.19us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"286.22us\", \"mean\": \"294.83us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"46.27us\", \"mean\": \"233.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"79.42us\", \"mean\": \"92.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"12.23us\", \"mean\": \"87.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"127.50us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=114.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:03:59,272] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:04,285] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5944.1 vnc_pixels_ps[total]=44101.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:04,286] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"334.82us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"41.48us\", \"mean\": \"300.51us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.35us\", \"mean\": \"42.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"172.73us\", \"mean\": \"276.50us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"48.13us\", \"mean\": \"241.66us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"18.72us\", \"mean\": \"84.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"13.87us\", \"mean\": \"90.54us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"91.18us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=146.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:04,286] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1715 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:09,302] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.2 vnc_pixels_ps[total]=44017.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:09,303] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"254.42us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"49.02us\", \"mean\": \"298.70us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.45us\", \"mean\": \"43.58us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"182.11us\", \"mean\": \"285.92us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"60.74us\", \"mean\": \"243.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.71us\", \"mean\": \"90.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"13.96us\", \"mean\": \"89.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"163.76us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=155.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:09,303] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1714 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:14,318] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.2 vnc_pixels_ps[total]=44186.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:14,319] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"275.44us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"43.24us\", \"mean\": \"292.19us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.93us\", \"mean\": \"42.77us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"220.77us\", \"mean\": \"286.38us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"54.63us\", \"mean\": \"240.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"148.60us\", \"mean\": \"95.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"13.75us\", \"mean\": \"90.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"116.00us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=143.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:14,319] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,068] [ERROR:gym_controlplane.reward.reward] RESET CAUSE: No non-zero rewards were generated since 1525816997.92 (60.15s ago), which exceeds the configured timeout of 60.00s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 49->50, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,069] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,070] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=50\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,070] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,070] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,087] init detected end of child process 19419 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,101] init detected end of child process 19434 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,101] init detected end of child process 19643 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,120] init detected end of child process 19665 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:04:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:04:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:04:18 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,202] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,202] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:18,341] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,401] init detected end of child process 19430 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,401] init detected end of child process 19422 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,401] init detected end of child process 19431 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:04:18,401] init detected end of child process 19433 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:19,693] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.35s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:19,698] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:19,760] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,579] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,579] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,579] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,579] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,597] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,597] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:04:20 I0508 22:04:20.609127 20210 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:04:20 I0508 22:04:20.611285 20210 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:04:20 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::39274\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:20,793] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:24,827] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:28,885] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,244] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['202us', '123us', '107us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,244] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,244] [play_vexpect] vexpect macro complete in 8.598308s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:04:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::39274 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 17 rects, 397.074 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.408 KiB (1:10.3137 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 790.879 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27249 MiB (1:2.37118 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,524] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 50->50, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,524] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,524] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=49->50, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,525] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.46s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,525] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=14.0 episode_count=21 episode_duration=95.46\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,526] [INFO:universe.wrappers.logger] Stats for the past 15.21s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1538.5 vnc_pixels_ps[total]=11416.0 reward_lag=None rewarder_message_lag=None fps=14.86\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,551] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:29,554] [INFO:universe.pyprofile] [pyprofile] period=15.23s timers={\"rewarder.sleep\": {\"calls\": 225, \"std\": \"253.02us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 19, \"std\": \"5.39ms\", \"mean\": \"1.54ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"23.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 57, \"std\": \"16.49us\", \"mean\": \"39.96us\"}, \"rewarder.compute_reward\": {\"calls\": 226, \"std\": \"1.87ms\", \"mean\": \"409.13us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 3, \"std\": \"25.01us\", \"mean\": \"73.27us\"}, \"reward.parsing.gameover\": {\"calls\": 19, \"std\": \"78.47us\", \"mean\": \"247.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 226, \"std\": \"58.68us\", \"mean\": \"91.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 19, \"std\": \"23.42us\", \"mean\": \"84.25us\"}, \"rewarder.frame\": {\"calls\": 226, \"std\": \"1.02ms\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 226, \"std\": 2.2725760207111896, \"mean\": 0.23008849557522132}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 19, \"std\": 3.2118202741878648, \"value\": 10, \"mean\": 23.263157894736842}} (export_time=229.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:33,725] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.20s, sent 3 reward messages to agent: reward=4.0 reward_min=1 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2097 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:34,541] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26075.6 vnc_pixels_ps[total]=100023.6 reward_lag=None rewarder_message_lag=None fps=59.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:34,558] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 298, \"std\": \"938.60us\", \"mean\": \"15.82ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.04ms\", \"mean\": \"1.73ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.80us\", \"mean\": \"49.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.30ms\", \"mean\": \"484.42us\"}, \"rewarder.sleep.missed\": {\"calls\": 3, \"std\": \"8.20ms\", \"mean\": \"5.27ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.30ms\", \"mean\": \"11.59ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"60.88us\", \"mean\": \"275.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"288.53us\", \"mean\": \"136.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"21.51us\", \"mean\": \"103.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"17.10ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.380476142847617, \"mean\": 2.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.43969686527576407, \"value\": 14.0, \"mean\": 13.12}} (export_time=148.30us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:35,675] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 3 reward messages to agent: reward=7.0 reward_min=0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2040 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:39,558] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7590.1 vnc_pixels_ps[total]=44562.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:39,559] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"846.78us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.71ms\", \"mean\": \"1.08ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"15.42us\", \"mean\": \"42.01us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"848.08us\", \"mean\": \"362.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.78ms\", \"mean\": \"9.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"73.88us\", \"mean\": \"237.69us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.21us\", \"mean\": \"99.53us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"22.35us\", \"mean\": \"89.98us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"19.19us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2717464881947031, \"mean\": 0.08}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.8681147322824334, \"value\": 22.0, \"mean\": 21.33333333333333}} (export_time=273.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:39,560] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.89s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:41,091] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:44,574] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8311.3 vnc_pixels_ps[total]=44084.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:44,575] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"965.26us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.87ms\", \"mean\": \"1.13ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"13.27us\", \"mean\": \"30.44us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"948.93us\", \"mean\": \"329.42us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.44ms\", \"mean\": \"7.94ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"66.02us\", \"mean\": \"174.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"36.65us\", \"mean\": \"89.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"18.66us\", \"mean\": \"69.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.21us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.315045523677691, \"value\": 25.0, \"mean\": 24.037037037037035}} (export_time=82.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:44,575] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:46,958] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:48,475] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:49,592] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9470.5 vnc_pixels_ps[total]=46950.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:49,593] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.92ms\", \"mean\": \"1.46ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"23.55us\", \"mean\": \"45.42us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.00ms\", \"mean\": \"415.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.36ms\", \"mean\": \"7.73ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"117.81us\", \"mean\": \"253.99us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.17us\", \"mean\": \"102.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"33.55us\", \"mean\": \"89.95us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.57us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.5166114784235836, \"value\": 34.0, \"mean\": 30.77777777777778}} (export_time=266.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:49,593] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:50,858] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.26s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:52,187] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.33s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:54,609] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10929.6 vnc_pixels_ps[total]=46137.9 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:54,610] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.50ms\", \"mean\": \"15.85ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.03ms\", \"mean\": \"2.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"29.25us\", \"mean\": \"63.87us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.49ms\", \"mean\": \"609.78us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.86ms\", \"mean\": \"9.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"139.32us\", \"mean\": \"353.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.65us\", \"mean\": \"131.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"36.14us\", \"mean\": \"122.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.36us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 6.477065767180457, \"mean\": 4.571428571428571}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2955558608590778, \"mean\": 0.09634551495016608}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 13.186610614839172, \"value\": 66.0, \"mean\": 45.62068965517242}} (export_time=301.60us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:54,611] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.42s, sent 3 reward messages to agent: reward=26.0 reward_min=0 reward_max=18.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:59,625] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5991.4 vnc_pixels_ps[total]=44351.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:59,626] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"313.44us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"139.19us\", \"mean\": \"355.81us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.92us\", \"mean\": \"47.84us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"236.33us\", \"mean\": \"346.64us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"114.05us\", \"mean\": \"268.84us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.84us\", \"mean\": \"116.31us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"56.57us\", \"mean\": \"111.78us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.42us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 66.0, \"mean\": 66.0}} (export_time=192.17us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:04:59,627] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:01,475] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.85s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:04,641] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7578.9 vnc_pixels_ps[total]=44571.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:04,642] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.14ms\", \"mean\": \"1.31ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"35.15us\", \"mean\": \"65.47us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"476.64us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.86ms\", \"mean\": \"11.19ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"145.21us\", \"mean\": \"359.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.01us\", \"mean\": \"125.93us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"33.09us\", \"mean\": \"116.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.74us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.4177446878757833, \"value\": 69.0, \"mean\": 67.47999999999999}} (export_time=156.88us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:04,642] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.17s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:06,675] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.03s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:09,658] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6797.4 vnc_pixels_ps[total]=44613.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:09,659] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"478.64us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.30ms\", \"mean\": \"651.65us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.84us\", \"mean\": \"53.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"463.65us\", \"mean\": \"385.90us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"80.41us\", \"mean\": \"304.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.12us\", \"mean\": \"119.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.57us\", \"mean\": \"111.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.02us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.017954755408104, \"value\": 71.0, \"mean\": 70.08333333333333}} (export_time=174.76us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:09,659] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.98s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:14,675] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.2 vnc_pixels_ps[total]=44295.7 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:14,676] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"643.35us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.92ms\", \"mean\": \"749.64us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.29us\", \"mean\": \"49.97us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"627.17us\", \"mean\": \"384.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.35ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"98.78us\", \"mean\": \"279.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.30us\", \"mean\": \"116.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.99us\", \"mean\": \"104.90us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.04us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.3269776053940758, \"value\": 74.0, \"mean\": 73.24999999999999}} (export_time=220.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:14,676] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:19,676] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"272.40us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"95.54us\", \"mean\": \"376.83us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.84us\", \"mean\": \"54.21us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"230.34us\", \"mean\": \"387.51us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"85.23us\", \"mean\": \"303.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"47.29us\", \"mean\": \"129.69us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"30.12us\", \"mean\": \"111.23us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"22.69us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2717464881947029, \"mean\": 0.08000000000000004}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=197.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:19,676] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:19,694] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6189.4 vnc_pixels_ps[total]=45917.9 reward_lag=None rewarder_message_lag=None fps=59.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:19 [info] 70#70: *263 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:19 [info] 70#70: *264 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:19 [info] 70#70: *265 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:24,692] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"369.65us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"107.00us\", \"mean\": \"437.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.13us\", \"mean\": \"62.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"276.17us\", \"mean\": \"410.12us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"84.83us\", \"mean\": \"347.96us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.03us\", \"mean\": \"137.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"32.70us\", \"mean\": \"127.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"113.18us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=378.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:24,692] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1724 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:24,708] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5978.2 vnc_pixels_ps[total]=44362.8 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:29,708] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"291.09us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"77.74us\", \"mean\": \"422.36us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.50us\", \"mean\": \"62.96us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"256.65us\", \"mean\": \"408.04us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"70.89us\", \"mean\": \"353.93us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.72us\", \"mean\": \"133.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.84us\", \"mean\": \"123.96us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.23us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289037}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=193.60us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:29,708] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:29,725] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.0 vnc_pixels_ps[total]=44023.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:34,708] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"271.26us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"90.89us\", \"mean\": \"414.05us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.82us\", \"mean\": \"58.76us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"255.96us\", \"mean\": \"378.37us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"91.71us\", \"mean\": \"339.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"48.41us\", \"mean\": \"125.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.48us\", \"mean\": \"122.00us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"20.08us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.0766666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=382.66us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:34,710] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:34,741] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5996.4 vnc_pixels_ps[total]=44503.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:39,724] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"327.96us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"111.26us\", \"mean\": \"429.67us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.74us\", \"mean\": \"65.10us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"267.55us\", \"mean\": \"399.18us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"106.46us\", \"mean\": \"361.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.77us\", \"mean\": \"131.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"36.66us\", \"mean\": \"126.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.30us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=203.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:39,725] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:39,758] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:44,741] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"270.53us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"118.09us\", \"mean\": \"421.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.48us\", \"mean\": \"63.22us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"255.97us\", \"mean\": \"387.31us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"122.26us\", \"mean\": \"355.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.27us\", \"mean\": \"128.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"35.53us\", \"mean\": \"122.46us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.20us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=192.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:44,741] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:44,775] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.9 vnc_pixels_ps[total]=44338.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:49,742] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"271.73us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"79.81us\", \"mean\": \"409.75us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.33us\", \"mean\": \"60.69us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"256.73us\", \"mean\": \"385.49us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"88.21us\", \"mean\": \"344.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"44.58us\", \"mean\": \"124.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.29us\", \"mean\": \"118.43us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"37.59us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2665063620734803, \"mean\": 0.07666666666666677}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=352.62us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:49,742] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:49,791] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6213.2 vnc_pixels_ps[total]=46100.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *266 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *267 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *268 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *269 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *270 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *271 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *272 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *273 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *274 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:05:50 [info] 70#70: *275 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:54,759] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"294.26us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"94.68us\", \"mean\": \"438.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.94us\", \"mean\": \"62.16us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"264.54us\", \"mean\": \"393.49us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"2.58ms\", \"mean\": \"2.11ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"80.06us\", \"mean\": \"350.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.17us\", \"mean\": \"129.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.48us\", \"mean\": \"128.90us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.04us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910307}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=207.42us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:54,759] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2129 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:54,808] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.3 vnc_pixels_ps[total]=44018.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:59,774] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"271.11us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"96.78us\", \"mean\": \"373.17us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.53us\", \"mean\": \"53.47us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"226.72us\", \"mean\": \"342.00us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"100.04us\", \"mean\": \"300.57us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.77us\", \"mean\": \"115.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.74us\", \"mean\": \"108.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.32us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 74.0, \"mean\": 74.0}} (export_time=129.22us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:59,774] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1725 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:05:59,824] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6026.6 vnc_pixels_ps[total]=44735.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,226] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=930us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,226] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,227] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,227] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,227] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,228] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 50->51, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,229] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,230] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,230] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=51\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,231] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,232] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,253] init detected end of child process 19964 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,261] init detected end of child process 19979 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,263] init detected end of child process 20186 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,279] init detected end of child process 20208 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:06:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:06:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:06:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,317] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,317] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:01,403] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,577] init detected end of child process 19967 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,577] init detected end of child process 19975 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,577] init detected end of child process 19976 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:06:01,577] init detected end of child process 19978 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:02,638] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:02,638] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,164] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,665] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,665] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,665] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,666] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,668] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,668] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:06:06 I0508 22:06:06.669096 20784 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:06:06 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::39688\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:06:06 I0508 22:06:06.678358 20784 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:06,800] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,117] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['154us', '70us', '61us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,117] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,117] [play_vexpect] vexpect macro complete in 1.413058s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:06:08 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::39688 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 83.106 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.1572 KiB (1:16.1085 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 39 rects, 1.08507 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.8556 MiB (1:1.44967 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,347] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 51->51, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,347] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,347] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=50->51, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,347] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.12s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,347] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=64.0 episode_count=41 episode_duration=98.82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,348] [INFO:universe.wrappers.logger] Stats for the past 8.52s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1500.0 vnc_pixels_ps[total]=7097.1 reward_lag=None rewarder_message_lag=None fps=9.97\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,360] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:08,360] [INFO:universe.pyprofile] [pyprofile] period=8.59s timers={\"rewarder.sleep\": {\"calls\": 87, \"std\": \"390.03us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 8, \"std\": \"3.53ms\", \"mean\": \"1.98ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.47ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 24, \"std\": \"29.83us\", \"mean\": \"62.10us\"}, \"rewarder.compute_reward\": {\"calls\": 88, \"std\": \"1.34ms\", \"mean\": \"582.37us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"99.73us\", \"mean\": \"103.35us\"}, \"reward.parsing.gameover\": {\"calls\": 8, \"std\": \"348.06us\", \"mean\": \"518.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 88, \"std\": \"49.71us\", \"mean\": \"129.93us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 8, \"std\": \"63.29us\", \"mean\": \"143.71us\"}, \"rewarder.frame\": {\"calls\": 88, \"std\": \"1.22ms\", \"mean\": \"16.65ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 88, \"std\": 2.24655779884998, \"mean\": 0.3181818181818182}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 7, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 8, \"std\": 22.627416997969522, \"value\": 10, \"mean\": 66.0}} (export_time=151.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:09,831] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.48s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2067 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:11,132] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:13,364] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=15839.0 vnc_pixels_ps[total]=82144.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:13,365] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.17ms\", \"mean\": \"1.09ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.15us\", \"mean\": \"37.70us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"965.81us\", \"mean\": \"333.85us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"6.64ms\", \"mean\": \"9.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"79.53us\", \"mean\": \"210.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.00us\", \"mean\": \"97.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"22.89us\", \"mean\": \"74.88us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"33.99us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519465, \"mean\": 1.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.8395809226599664, \"value\": 14.0, \"mean\": 11.916666666666666}} (export_time=123.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:13,365] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.23s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1930 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:17,198] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.83s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:18,382] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6749.7 vnc_pixels_ps[total]=44180.0 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:18,383] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"390.07us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.14ms\", \"mean\": \"515.58us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.89us\", \"mean\": \"40.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"389.24us\", \"mean\": \"321.33us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.60ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"75.92us\", \"mean\": \"229.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.09us\", \"mean\": \"105.08us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.58us\", \"mean\": \"80.98us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.78us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4148511169990527, \"value\": 15.0, \"mean\": 14.208333333333336}} (export_time=360.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:18,384] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.19s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:20,015] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.63s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:21,531] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:23,048] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:23,398] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10930.5 vnc_pixels_ps[total]=45927.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:23,398] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.60ms\", \"mean\": \"1.98ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"15.66us\", \"mean\": \"34.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.27ms\", \"mean\": \"438.13us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.87ms\", \"mean\": \"8.00ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"74.50us\", \"mean\": \"194.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.44us\", \"mean\": \"99.51us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"22.63us\", \"mean\": \"70.10us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.05us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.3451854182690985, \"mean\": 2.142857142857143}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395351}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 4.218252101718295, \"value\": 30.0, \"mean\": 21.64285714285714}} (export_time=130.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:26,531] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:28,048] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1396, 'rewarder.vnc.updates.pixels': 9928, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:28,407] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"791.11us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.76ms\", \"mean\": \"1.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"14.70us\", \"mean\": \"35.29us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"941.05us\", \"mean\": \"362.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.36ms\", \"mean\": \"7.47ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"70.95us\", \"mean\": \"202.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"44.31us\", \"mean\": \"92.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"21.91us\", \"mean\": \"72.71us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"25.27us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177274, \"mean\": 0.08999999999999998}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.022538041142747, \"value\": 33.0, \"mean\": 30.74074074074074}} (export_time=122.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:28,415] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9299.1 vnc_pixels_ps[total]=45533.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:30,848] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.80s, sent 3 reward messages to agent: reward=7.0 reward_min=0.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:32,598] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:33,414] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.00ms\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.67ms\", \"mean\": \"953.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"10.51us\", \"mean\": \"33.02us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"831.80us\", \"mean\": \"321.04us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"5.05ms\", \"mean\": \"8.81ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"45.58us\", \"mean\": \"187.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.68us\", \"mean\": \"93.72us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"16.89us\", \"mean\": \"70.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.06us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.217355782608345, \"mean\": 2.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.637549367626445, \"value\": 44.0, \"mean\": 39.04}} (export_time=97.04us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:33,431] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7618.8 vnc_pixels_ps[total]=44789.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:34,314] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:36,698] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:38,414] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"701.82us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.02ms\", \"mean\": \"1.07ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"24.37us\", \"mean\": \"33.53us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"698.80us\", \"mean\": \"320.39us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"352.47us\", \"mean\": \"5.55ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"78.95us\", \"mean\": \"184.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.52us\", \"mean\": \"89.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"14.61us\", \"mean\": \"66.31us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"17.96us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.8708286933869707, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2866599257717727, \"mean\": 0.08999999999999998}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.39725043841494, \"value\": 54.0, \"mean\": 48.18518518518519}} (export_time=114.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:38,415] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1913 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:38,448] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8939.7 vnc_pixels_ps[total]=47147.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:41,037] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.62s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 5482, 'rewarder.vnc.updates.pixels': 10968, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:42,331] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.29s, sent 3 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:43,415] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"846.99us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"2.34ms\", \"mean\": \"1.30ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"15.01us\", \"mean\": \"31.31us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"837.88us\", \"mean\": \"332.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"447.31us\", \"mean\": \"5.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"63.27us\", \"mean\": \"176.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"39.92us\", \"mean\": \"79.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"16.64us\", \"mean\": \"63.10us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"21.98us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0954451150103321, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2913850368290183, \"mean\": 0.09333333333333337}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.417966262494337, \"value\": 60.0, \"mean\": 55.92857142857144}} (export_time=98.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:43,415] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:43,465] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10077.3 vnc_pixels_ps[total]=45540.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:45,165] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 3 reward messages to agent: reward=9.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:47,315] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:48,431] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"818.54us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.48ms\", \"mean\": \"1.07ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"12.88us\", \"mean\": \"32.44us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"810.88us\", \"mean\": \"317.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.84ms\", \"mean\": \"7.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"59.41us\", \"mean\": \"185.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.42us\", \"mean\": \"86.50us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.19us\", \"mean\": \"70.85us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.19us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.5811388300841898, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.788989339969143, \"value\": 70.0, \"mean\": 67.53846153846155}} (export_time=107.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:48,431] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.12s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:48,481] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8352.4 vnc_pixels_ps[total]=44430.0 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:52,081] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.65s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:53,448] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"649.82us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"1.96ms\", \"mean\": \"927.53us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"11.94us\", \"mean\": \"31.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"648.05us\", \"mean\": \"305.08us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"828.69us\", \"mean\": \"5.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"54.56us\", \"mean\": \"175.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.01us\", \"mean\": \"85.94us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"17.85us\", \"mean\": \"67.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.73us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.0863787375415282}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.8338972450995514, \"value\": 73.0, \"mean\": 71.15384615384615}} (export_time=96.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:53,448] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1907 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:53,498] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8445.8 vnc_pixels_ps[total]=45036.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:55,548] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.10s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:57,714] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:58,448] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"751.56us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.19ms\", \"mean\": \"1.13ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.94us\", \"mean\": \"31.63us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"751.92us\", \"mean\": \"323.87us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"519.08us\", \"mean\": \"6.02ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"58.92us\", \"mean\": \"176.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"44.45us\", \"mean\": \"91.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"17.02us\", \"mean\": \"66.02us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"24.79us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2866599257717727, \"mean\": 0.08999999999999998}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.5284575022493585, \"value\": 78.0, \"mean\": 75.48148148148147}} (export_time=158.07us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:06:58,515] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9115.1 vnc_pixels_ps[total]=44203.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,181] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=218us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,181] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.47s, sent 3 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 51->52, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,182] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=52\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,183] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,183] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,198] init detected end of child process 20500 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,203] init detected end of child process 20515 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,205] init detected end of child process 20717 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,207] init detected end of child process 20723 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,222] init detected end of child process 20745 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:07:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:07:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:07:01 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,265] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,265] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:07:01 [info] 70#70: *277 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:07:01 [info] 70#70: *278 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:07:01 [info] 70#70: *279 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:07:01 [info] 70#70: *276 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:01,354] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,501] init detected end of child process 20503 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,501] init detected end of child process 20511 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,501] init detected end of child process 20512 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:07:01,501] init detected end of child process 20514 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:02,583] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:02,584] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:05,975] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,475] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,475] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,475] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7, 'compress_level': 0, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,475] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,477] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,477] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:07:06 I0508 22:07:06.47803 21336 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:07:06 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::39914\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:07:06 I0508 22:07:06.488811 21336 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:06,607] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:10,640] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:10,957] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['147us', '65us', '57us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:10,957] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:10,957] [play_vexpect] vexpect macro complete in 4.444118s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:07:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::39914 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.4131 KiB (1:15.3068 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 43 rects, 1.0783 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.85496 MiB (1:1.44095 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,168] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 52->52, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,168] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,169] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=51->52, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,169] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,169] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=69.0 episode_count=46 episode_duration=62.82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,170] [INFO:universe.wrappers.logger] Stats for the past 12.65s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1626.7 vnc_pixels_ps[total]=9320.1 reward_lag=None rewarder_message_lag=None fps=12.72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,182] [INFO:gym_controlplane.reward.reward] First score parsed: score=22. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:11,182] [INFO:universe.pyprofile] [pyprofile] period=12.73s timers={\"rewarder.sleep\": {\"calls\": 164, \"std\": \"150.36us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.88ms\", \"mean\": \"985.18us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.84ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"12.17us\", \"mean\": \"26.56us\"}, \"rewarder.compute_reward\": {\"calls\": 165, \"std\": \"965.95us\", \"mean\": \"318.32us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"17.17us\", \"mean\": \"40.61us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"78.88us\", \"mean\": \"191.62us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 165, \"std\": \"37.04us\", \"mean\": \"101.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"20.16us\", \"mean\": \"57.53us\"}, \"rewarder.frame\": {\"calls\": 165, \"std\": \"1.16ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.33333333333333337}, \"reward.vnc.updates.n\": {\"calls\": 165, \"std\": 2.731965659307665, \"mean\": 0.2909090909090909}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 18.422394398791255, \"value\": 10, \"mean\": 74.0}} (export_time=141.62us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:14,686] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.52s, sent 4 reward messages to agent: reward=19.0 reward_min=2 reward_max=12 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2134 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:15,753] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:16,188] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22100.2 vnc_pixels_ps[total]=102763.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:16,189] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.34ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"3.00ms\", \"mean\": \"1.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"19.03us\", \"mean\": \"44.42us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.10ms\", \"mean\": \"459.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.14ms\", \"mean\": \"7.52ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"89.90us\", \"mean\": \"253.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.08us\", \"mean\": \"111.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"36.21us\", \"mean\": \"97.00us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"260.86us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 4.277849927241487, \"mean\": 4.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2955558608590778, \"mean\": 0.09634551495016612}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 2.691438716473407, \"value\": 32.0, \"mean\": 26.620689655172413}} (export_time=211.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:18,137] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 3 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1347, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 9824, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:20,320] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:21,203] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9504.1 vnc_pixels_ps[total]=47127.7 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:21,203] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"15.96ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.69ms\", \"mean\": \"1.87ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"23.38us\", \"mean\": \"53.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.26ms\", \"mean\": \"506.11us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"769.59us\", \"mean\": \"10.13ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"122.18us\", \"mean\": \"301.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.95us\", \"mean\": \"126.69us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"27.26us\", \"mean\": \"102.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.50us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.0488088481701516, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.200103597664399, \"value\": 41.0, \"mean\": 35.92592592592593}} (export_time=137.81us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:26,221] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.0 vnc_pixels_ps[total]=44177.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:26,222] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"254.48us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"105.64us\", \"mean\": \"376.63us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"17.85us\", \"mean\": \"52.90us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"256.13us\", \"mean\": \"381.99us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"85.03us\", \"mean\": \"299.38us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.94us\", \"mean\": \"128.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.15us\", \"mean\": \"110.90us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.55us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 41.0, \"mean\": 41.0}} (export_time=202.66us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:26,222] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.90s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:29,637] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.41s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:30,881] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.24s, sent 2 reward messages to agent: reward=9.0 reward_min=3.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:31,236] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9248.9 vnc_pixels_ps[total]=45269.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:31,237] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.26ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.59ms\", \"mean\": \"1.84ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.06us\", \"mean\": \"55.25us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"541.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.91ms\", \"mean\": \"9.77ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"106.08us\", \"mean\": \"310.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.18us\", \"mean\": \"134.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"34.36us\", \"mean\": \"113.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.01us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.16794833886788, \"mean\": 2.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774085}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.587728372075411, \"value\": 53.0, \"mean\": 43.22222222222222}} (export_time=184.77us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:33,103] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.22s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:36,254] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6746.8 vnc_pixels_ps[total]=44222.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:36,255] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"851.28us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.72ms\", \"mean\": \"895.98us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.85us\", \"mean\": \"49.10us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"847.49us\", \"mean\": \"386.66us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.13ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"101.51us\", \"mean\": \"278.88us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.26us\", \"mean\": \"115.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.16us\", \"mean\": \"103.35us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.95us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0072203103706707, \"value\": 57.0, \"mean\": 56.166666666666664}} (export_time=315.90us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:36,256] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.15s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:39,153] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.90s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:40,670] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:41,269] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8402.3 vnc_pixels_ps[total]=44850.2 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:41,270] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.42ms\", \"mean\": \"1.59ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.08us\", \"mean\": \"58.94us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"480.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.58ms\", \"mean\": \"10.23ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"86.23us\", \"mean\": \"331.46us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.09us\", \"mean\": \"124.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"28.12us\", \"mean\": \"114.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.02us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.6627132598904033, \"value\": 62.0, \"mean\": 58.26923076923078}} (export_time=100.37us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:46,286] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.4 vnc_pixels_ps[total]=44019.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:46,286] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"279.31us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"160.25us\", \"mean\": \"343.66us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"76.49us\", \"mean\": \"58.34us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"246.63us\", \"mean\": \"308.79us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"181.11us\", \"mean\": \"299.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.32us\", \"mean\": \"106.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"40.07us\", \"mean\": \"100.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.15us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 62.0, \"mean\": 62.0}} (export_time=82.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:46,287] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.62s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:48,920] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.63s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:51,303] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7598.3 vnc_pixels_ps[total]=44722.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:51,304] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.03ms\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.14ms\", \"mean\": \"1.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"22.79us\", \"mean\": \"51.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"417.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.55ms\", \"mean\": \"10.99ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"115.76us\", \"mean\": \"292.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.23us\", \"mean\": \"111.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"30.48us\", \"mean\": \"106.00us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.19us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.7242500732382213, \"value\": 68.0, \"mean\": 64.3076923076923}} (export_time=130.41us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:51,304] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1913 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:56,320] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.3 vnc_pixels_ps[total]=45932.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:56,321] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"280.84us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"113.02us\", \"mean\": \"401.24us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.92us\", \"mean\": \"57.50us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"260.78us\", \"mean\": \"369.39us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.75us\", \"mean\": \"322.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.61us\", \"mean\": \"118.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.81us\", \"mean\": \"115.48us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.59us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 68.0, \"mean\": 68.0}} (export_time=265.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:56,322] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1724 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:07:59,536] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.21s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:01,337] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6777.3 vnc_pixels_ps[total]=44457.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:01,337] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"723.08us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.03ms\", \"mean\": \"807.35us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.22us\", \"mean\": \"59.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"659.26us\", \"mean\": \"410.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"102.80us\", \"mean\": \"333.10us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.79us\", \"mean\": \"118.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.76us\", \"mean\": \"112.96us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"240.75us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.481543412343074, \"value\": 69.0, \"mean\": 68.33333333333334}} (export_time=190.26us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:01,338] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.80s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:02 [info] 70#70: *281 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:02 [info] 70#70: *282 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:02 [info] 70#70: *283 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:03,870] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.53s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:06,353] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.3 vnc_pixels_ps[total]=44296.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:06,353] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"934.82us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.97ms\", \"mean\": \"980.97us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"26.18us\", \"mean\": \"58.53us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"920.42us\", \"mean\": \"409.48us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.40ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"135.76us\", \"mean\": \"329.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.52us\", \"mean\": \"113.16us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.42us\", \"mean\": \"107.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.46us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5089773777040532, \"value\": 70.0, \"mean\": 69.45833333333334}} (export_time=176.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:06,354] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.48s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:07,554] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:10,153] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:11,370] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10056.6 vnc_pixels_ps[total]=45380.9 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:11,371] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.19ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.39ms\", \"mean\": \"2.33ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"25.31us\", \"mean\": \"50.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.51ms\", \"mean\": \"542.86us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"253.44us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.89ms\", \"mean\": \"10.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"133.62us\", \"mean\": \"284.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"65.44us\", \"mean\": \"120.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"30.98us\", \"mean\": \"98.50us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.64us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.1430335024428686, \"value\": 77.0, \"mean\": 73.14814814814817}} (export_time=197.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:11,371] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2030 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:16,386] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5959.1 vnc_pixels_ps[total]=44140.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:16,387] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"247.08us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"127.37us\", \"mean\": \"294.21us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.56us\", \"mean\": \"37.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"197.39us\", \"mean\": \"285.13us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"115.81us\", \"mean\": \"214.44us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.47us\", \"mean\": \"99.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"32.23us\", \"mean\": \"88.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.58us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.1213203435596424, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.8643121965600933, \"value\": 80.0, \"mean\": 79.7391304347826}} (export_time=94.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:16,387] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1784 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,936] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=330us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,937] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,937] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.55s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,937] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,937] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,937] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 52->53, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,938] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,938] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,938] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=53\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,938] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:18,938] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:18,951] init detected end of child process 21050 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:18,962] init detected end of child process 21065 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:18,962] init detected end of child process 21273 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:18,988] init detected end of child process 21295 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:19,044] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:19,044] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:19,140] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:19,249] init detected end of child process 21053 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:19,249] init detected end of child process 21061 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:19,249] init detected end of child process 21062 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:19,249] init detected end of child process 21064 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:20,555] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.41s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:20,560] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:25,624] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,395] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,395] [play_vexpect] Using the golang VNC implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,396] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,396] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,399] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,400] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:08:26 I0508 22:08:26.400185 21864 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:08:26 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::40462\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:08:26 I0508 22:08:26.402385 21864 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:26,576] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,577] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['248us', '148us', '133us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,577] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,578] [play_vexpect] vexpect macro complete in 4.141221s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:08:30 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::40462 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 15 rects, 868.352 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.48532 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 948.247 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.5044 MiB (1:1.44449 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,821] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 53->53, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,821] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,824] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=52->53, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,824] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.89s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,824] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=70.0 episode_count=41 episode_duration=79.66\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,826] [INFO:universe.wrappers.logger] Stats for the past 14.44s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1419.6 vnc_pixels_ps[total]=8151.3 reward_lag=None rewarder_message_lag=None fps=10.67\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,842] [INFO:gym_controlplane.reward.reward] First score parsed: score=13. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:30,843] [INFO:universe.pyprofile] [pyprofile] period=14.46s timers={\"rewarder.sleep\": {\"calls\": 153, \"std\": \"168.67us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"4.19ms\", \"mean\": \"1.36ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.72ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"11.24us\", \"mean\": \"27.60us\"}, \"rewarder.compute_reward\": {\"calls\": 154, \"std\": \"1.42ms\", \"mean\": \"350.77us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.90us\", \"mean\": \"48.60us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"108.88us\", \"mean\": \"207.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 154, \"std\": \"29.20us\", \"mean\": \"82.74us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"20.65us\", \"mean\": \"71.18us\"}, \"rewarder.frame\": {\"calls\": 154, \"std\": \"1.19ms\", \"mean\": \"16.66ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 154, \"std\": 3.148234860189459, \"mean\": 0.33766233766233766}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 18.708286933869708, \"value\": 10, \"mean\": 75.0}} (export_time=194.31us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:31,877] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2085 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:33,394] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=4.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:35,544] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:35,827] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=13.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29503.6 vnc_pixels_ps[total]=109673.9 reward_lag=None rewarder_message_lag=None fps=59.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:35,845] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.77ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.83ms\", \"mean\": \"2.59ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"11.23us\", \"mean\": \"36.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.70ms\", \"mean\": \"484.14us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.49ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.75ms\", \"mean\": \"11.30ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"48.97us\", \"mean\": \"209.46us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"58.86us\", \"mean\": \"82.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"13.36us\", \"mean\": \"72.75us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"319.41us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.1126972805283737, \"mean\": 2.2857142857142856}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.295555860859078, \"mean\": 0.0963455149501661}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 3.878385220833829, \"value\": 25.0, \"mean\": 17.551724137931032}} (export_time=183.34us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:37,061] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 4 reward messages to agent: reward=6.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2031 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:39,270] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.21s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:40,837] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9192.4 vnc_pixels_ps[total]=44703.1 reward_lag=None rewarder_message_lag=None fps=59.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:40,861] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.59ms\", \"mean\": \"15.87ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"6.19ms\", \"mean\": \"2.70ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"12.06us\", \"mean\": \"42.65us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"2.00ms\", \"mean\": \"523.49us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.43ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"6.74ms\", \"mean\": \"15.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"47.12us\", \"mean\": \"240.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"310.36us\", \"mean\": \"117.54us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"15.93us\", \"mean\": \"83.58us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"1.05ms\", \"mean\": \"17.00ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28181605677298194, \"mean\": 0.08666666666666671}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.8643699803997738, \"value\": 34.0, \"mean\": 31.269230769230763}} (export_time=174.52us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:40,861] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.59s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2027 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:41,894] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:43,445] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:45,845] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8416.6 vnc_pixels_ps[total]=43054.0 reward_lag=None rewarder_message_lag=None fps=59.91\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:45,862] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 297, \"std\": \"1.21ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"6.13ms\", \"mean\": \"2.77ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"12.61us\", \"mean\": \"44.44us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"2.06ms\", \"mean\": \"572.22us\"}, \"rewarder.sleep.missed\": {\"calls\": 3, \"std\": \"1.13ms\", \"mean\": \"2.75ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.61ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"46.15us\", \"mean\": \"248.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"600.30us\", \"mean\": \"161.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"11.68us\", \"mean\": \"83.46us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"732.28us\", \"mean\": \"16.93ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2818160567729816, \"mean\": 0.08666666666666671}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.6552945357246798, \"value\": 39.0, \"mean\": 36.500000000000014}} (export_time=206.23us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:45,866] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.42s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2033 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=509us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 53->54, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,618] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,619] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,619] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=54\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,619] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,620] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:46,636] init detected end of child process 21593 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:46,667] init detected end of child process 21608 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:46,668] init detected end of child process 21810 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:46,672] init detected end of child process 21815 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:46,696] init detected end of child process 21838 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:08:46 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,780] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,781] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:46 [info] 70#70: *285 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:46 [info] 70#70: *286 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:46 [info] 70#70: *287 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:08:46 [info] 70#70: *284 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:46,941] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:47,004] init detected end of child process 21607 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:47,005] init detected end of child process 21596 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:47,005] init detected end of child process 21604 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:08:47,005] init detected end of child process 21605 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:48,355] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.41s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:48,355] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:53,850] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,698] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,698] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,698] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,699] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,721] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,721] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:08:54 I0508 22:08:54.724884 22247 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:08:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::40674\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:08:54 I0508 22:08:54.72951 22247 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:54,907] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:56,808] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['232us', '117us', '103us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:56,808] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:56,809] [play_vexpect] vexpect macro complete in 2.044368s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:08:56 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::40674 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 12.497 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.69043 KiB (1:28.8989 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 22 rects, 974.848 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.79024 MiB (1:1.33286 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 36 rects, 1.05571 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.80945 MiB (1:1.4336 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,041] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 54->54, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,043] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,043] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=53->54, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,043] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.18s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,044] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=29.0 episode_count=19 episode_duration=26.22\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,045] [INFO:universe.wrappers.logger] Stats for the past 11.20s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=902.9 vnc_pixels_ps[total]=3609.9 reward_lag=None rewarder_message_lag=None fps=4.20\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,067] [INFO:gym_controlplane.reward.reward] First score parsed: score=14. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:57,069] [INFO:universe.pyprofile] [pyprofile] period=11.21s timers={\"rewarder.sleep\": {\"calls\": 45, \"std\": \"873.64us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"8.63ms\", \"mean\": \"3.83ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"21.20ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"16.03us\", \"mean\": \"34.33us\"}, \"rewarder.compute_reward\": {\"calls\": 46, \"std\": \"3.71ms\", \"mean\": \"967.58us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"26.28us\", \"mean\": \"71.09us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"220.34us\", \"mean\": \"353.50us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 46, \"std\": \"798.61us\", \"mean\": \"213.27us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"36.07us\", \"mean\": \"76.93us\"}, \"rewarder.frame\": {\"calls\": 46, \"std\": \"1.34ms\", \"mean\": \"16.56ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 46, \"std\": 3.8300237761146945, \"mean\": 0.673913043478261}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 11.839200423452027, \"value\": 10, \"mean\": 34.166666666666664}} (export_time=222.92us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:58,417] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 3 reward messages to agent: reward=14.0 reward_min=3 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<2081 bytes>', 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:08:59,957] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.54s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:02,056] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19363.7 vnc_pixels_ps[total]=88360.2 reward_lag=None rewarder_message_lag=None fps=59.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:02,072] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.56ms\", \"mean\": \"15.87ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.16ms\", \"mean\": \"1.98ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.23us\", \"mean\": \"46.98us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.39ms\", \"mean\": \"444.35us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.84ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.74ms\", \"mean\": \"10.94ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"65.58us\", \"mean\": \"264.66us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"149.94us\", \"mean\": \"102.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"9.84us\", \"mean\": \"84.78us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"972.69us\", \"mean\": \"16.98ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.1908902300206647, \"mean\": 3.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 5.291647991083539, \"value\": 28.0, \"mean\": 23.807692307692307}} (export_time=140.67us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:02,072] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.12s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2032 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:05,173] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.10s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:06,257] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:07,057] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8517.6 vnc_pixels_ps[total]=45563.4 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:07,073] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.07ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.97ms\", \"mean\": \"1.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"11.71us\", \"mean\": \"41.63us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.31ms\", \"mean\": \"414.74us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"963.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.36ms\", \"mean\": \"11.50ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"40.72us\", \"mean\": \"235.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"300.13us\", \"mean\": \"108.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"10.89us\", \"mean\": \"80.01us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"664.35us\", \"mean\": \"16.91ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2818160567729817, \"mean\": 0.08666666666666671}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.3249092857190676, \"value\": 32.0, \"mean\": 29.65384615384616}} (export_time=198.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:07,990] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2019 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:10,809] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:12,059] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8450.7 vnc_pixels_ps[total]=44971.5 reward_lag=None rewarder_message_lag=None fps=59.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:12,075] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.11ms\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"4.50ms\", \"mean\": \"1.90ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"12.86us\", \"mean\": \"38.74us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.39ms\", \"mean\": \"388.63us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.05ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.19ms\", \"mean\": \"12.95ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"55.64us\", \"mean\": \"218.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"47.14us\", \"mean\": \"80.90us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"12.61us\", \"mean\": \"78.18us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"370.63us\", \"mean\": \"16.82ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.271746488194703, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.119611668015729, \"value\": 38.0, \"mean\": 34.666666666666664}} (export_time=195.74us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:12,076] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.27s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2014 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:15,793] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.72s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:17,076] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7577.6 vnc_pixels_ps[total]=44563.4 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:17,077] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"923.97us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.87ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"13.95us\", \"mean\": \"41.65us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"918.45us\", \"mean\": \"357.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"460.24us\", \"mean\": \"10.27ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"61.34us\", \"mean\": \"236.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.45us\", \"mean\": \"93.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"16.92us\", \"mean\": \"85.36us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"71.82us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.08333333333333336}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.6271629240742266, \"value\": 40.0, \"mean\": 38.32}} (export_time=264.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:17,077] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1928 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:22,093] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6212.6 vnc_pixels_ps[total]=46095.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:22,093] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"265.28us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"77.55us\", \"mean\": \"380.49us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.88us\", \"mean\": \"57.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.68us\", \"mean\": \"361.99us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"89.36us\", \"mean\": \"322.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.26us\", \"mean\": \"120.15us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"21.79us\", \"mean\": \"108.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.27us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=184.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:22,094] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:27,109] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.0 vnc_pixels_ps[total]=44023.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:27,110] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"243.81us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"69.02us\", \"mean\": \"345.25us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.56us\", \"mean\": \"48.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"199.20us\", \"mean\": \"349.02us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"64.73us\", \"mean\": \"275.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.48us\", \"mean\": \"117.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.49us\", \"mean\": \"101.12us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.30us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 40.0, \"mean\": 40.0}} (export_time=154.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:27,110] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1725 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:30,109] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.00s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:31,409] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:32,126] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9235.5 vnc_pixels_ps[total]=45113.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:32,127] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.39ms\", \"mean\": \"1.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.81us\", \"mean\": \"42.55us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"437.82us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.55ms\", \"mean\": \"8.52ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"98.81us\", \"mean\": \"240.11us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.07us\", \"mean\": \"110.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.90us\", \"mean\": \"85.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.42us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.6431676725154984, \"mean\": 2.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 4.37475274026562, \"value\": 51.0, \"mean\": 43.53846153846153}} (export_time=232.46us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:34,426] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.02s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:37,142] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6810.7 vnc_pixels_ps[total]=44616.8 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:37,142] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"663.45us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"2.10ms\", \"mean\": \"773.41us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.97us\", \"mean\": \"47.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"644.47us\", \"mean\": \"368.48us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"81.53us\", \"mean\": \"268.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.61us\", \"mean\": \"117.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.87us\", \"mean\": \"96.11us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.80us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.5107539184552496, \"value\": 55.0, \"mean\": 54.52173913043478}} (export_time=145.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:37,143] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.72s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:41,176] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.03s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:42,159] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6758.8 vnc_pixels_ps[total]=44276.7 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:42,160] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"450.94us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.30ms\", \"mean\": \"606.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.19us\", \"mean\": \"50.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"447.97us\", \"mean\": \"374.83us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.40ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"86.47us\", \"mean\": \"280.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.67us\", \"mean\": \"119.69us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"22.47us\", \"mean\": \"97.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.90us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.38069349381344, \"value\": 56.0, \"mean\": 55.166666666666664}} (export_time=235.56us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:46,576] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.40s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:47,176] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6787.5 vnc_pixels_ps[total]=44536.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:47,177] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"657.63us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.00ms\", \"mean\": \"794.11us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"53.16us\", \"mean\": \"63.90us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"646.38us\", \"mean\": \"418.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.81ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"214.17us\", \"mean\": \"357.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.99us\", \"mean\": \"127.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"21.14us\", \"mean\": \"110.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.59us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.2823298512866407, \"value\": 57.0, \"mean\": 56.08333333333333}} (export_time=226.74us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:09:48 [info] 70#70: *289 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:09:48 [info] 70#70: *290 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:09:48 [info] 70#70: *291 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:52,192] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.8 vnc_pixels_ps[total]=44183.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:52,193] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"280.50us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"80.51us\", \"mean\": \"400.56us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"47.54us\", \"mean\": \"66.83us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"250.33us\", \"mean\": \"377.22us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"189.38us\", \"mean\": \"369.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.73us\", \"mean\": \"123.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.27us\", \"mean\": \"116.33us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.47us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 57.0, \"mean\": 57.0}} (export_time=143.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:52,193] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.62s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:57,209] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6006.4 vnc_pixels_ps[total]=44580.3 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:57,210] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"235.79us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"85.04us\", \"mean\": \"370.86us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.15us\", \"mean\": \"55.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"216.48us\", \"mean\": \"374.87us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"82.15us\", \"mean\": \"311.06us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.25us\", \"mean\": \"125.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.34us\", \"mean\": \"109.63us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.29us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910307}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 57.0, \"mean\": 57.0}} (export_time=117.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:09:57,210] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:02,226] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.4 vnc_pixels_ps[total]=45933.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:02,226] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"252.95us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"47.15us\", \"mean\": \"400.10us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.74us\", \"mean\": \"58.75us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"231.74us\", \"mean\": \"381.15us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"50.33us\", \"mean\": \"334.79us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.69us\", \"mean\": \"127.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"14.01us\", \"mean\": \"115.42us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.89us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 57.0, \"mean\": 57.0}} (export_time=162.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:02,227] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:06,959] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:07,243] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6779.0 vnc_pixels_ps[total]=44373.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:07,257] [INFO:universe.pyprofile] [pyprofile] period=5.03s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"600.23us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.09ms\", \"mean\": \"1.30ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.96us\", \"mean\": \"61.47us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"466.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.59ms\", \"mean\": \"10.77ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"69.10us\", \"mean\": \"345.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.95us\", \"mean\": \"134.89us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.34us\", \"mean\": \"112.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.62us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.2823298512866407, \"value\": 58.0, \"mean\": 57.08333333333333}} (export_time=204.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:08,260] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=4.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:12,260] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8410.7 vnc_pixels_ps[total]=44919.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:12,261] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.11ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.45ms\", \"mean\": \"1.42ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.31us\", \"mean\": \"66.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.11ms\", \"mean\": \"485.77us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"497.10us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"415.57us\", \"mean\": \"12.29ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"84.25us\", \"mean\": \"379.62us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.90us\", \"mean\": \"129.49us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"20.66us\", \"mean\": \"123.18us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"39.16us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.4525839046333942, \"value\": 63.0, \"mean\": 62.12}} (export_time=368.83us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:12,262] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.00s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2018 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:17,276] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.2 vnc_pixels_ps[total]=44024.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:17,277] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"293.66us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"87.43us\", \"mean\": \"407.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.29us\", \"mean\": \"65.62us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"240.74us\", \"mean\": \"380.04us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"101.73us\", \"mean\": \"361.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.52us\", \"mean\": \"123.99us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.38us\", \"mean\": \"119.79us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"34.34us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 63.0, \"mean\": 63.0}} (export_time=205.99us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:17,278] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:22,293] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5996.1 vnc_pixels_ps[total]=44501.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:22,294] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"284.76us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"57.08us\", \"mean\": \"431.45us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.65us\", \"mean\": \"67.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"256.52us\", \"mean\": \"389.09us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"86.57us\", \"mean\": \"373.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.89us\", \"mean\": \"124.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"15.33us\", \"mean\": \"120.83us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.15us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 63.0, \"mean\": 63.0}} (export_time=294.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:22,295] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:27,310] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.0 vnc_pixels_ps[total]=44185.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:27,311] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"329.69us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"115.75us\", \"mean\": \"449.09us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"46.02us\", \"mean\": \"76.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"303.78us\", \"mean\": \"422.16us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"210.56us\", \"mean\": \"426.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.98us\", \"mean\": \"133.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"34.24us\", \"mean\": \"124.72us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.95us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910307}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 63.0, \"mean\": 63.0}} (export_time=200.99us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:27,312] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:32,327] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.6 vnc_pixels_ps[total]=45934.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:32,328] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"329.69us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"87.69us\", \"mean\": \"457.04us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.93us\", \"mean\": \"70.85us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"295.02us\", \"mean\": \"423.22us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"110.08us\", \"mean\": \"397.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.07us\", \"mean\": \"134.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.28us\", \"mean\": \"133.02us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.25us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 63.0, \"mean\": 63.0}} (export_time=338.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:32,329] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1727 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:37,343] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5938.9 vnc_pixels_ps[total]=44020.4 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:37,344] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"381.03us\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"115.41us\", \"mean\": \"500.90us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.32us\", \"mean\": \"75.77us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"298.03us\", \"mean\": \"438.92us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"115.29us\", \"mean\": \"421.26us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"66.51us\", \"mean\": \"140.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.79us\", \"mean\": \"146.03us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.50us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 63.0, \"mean\": 63.0}} (export_time=221.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:37,344] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,826] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=378us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,826] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,827] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.48s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,827] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,827] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,827] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 54->55, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,827] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,828] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,828] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=55\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,828] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,829] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:39,845] init detected end of child process 21966 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:39,850] init detected end of child process 21981 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:39,854] init detected end of child process 22188 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:39,872] init detected end of child process 22209 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:39 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:39 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:39 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,912] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:39,912] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:40,000] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:40,169] init detected end of child process 21969 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:40,169] init detected end of child process 21977 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:40,169] init detected end of child process 21978 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:40,169] init detected end of child process 21980 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:41,230] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:41,231] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:44,842] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,317] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,317] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,317] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,317] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,324] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,324] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:10:45 I0508 22:10:45.324901 22780 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:10:45 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41038\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:10:45 I0508 22:10:45.33392 22780 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:45,447] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,514] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['149us', '61us', '54us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,514] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,515] [play_vexpect] vexpect macro complete in 2.156445s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:10:47 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41038 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 16 rects, 917.504 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.626 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 997.399 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.64508 MiB (1:1.43856 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,711] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 55->55, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,712] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,712] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=54->55, env_state=running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,712] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.89s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,712] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=53.0 episode_count=45 episode_duration=110.67\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,713] [INFO:universe.wrappers.logger] Stats for the past 10.37s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1866.9 vnc_pixels_ps[total]=10539.5 reward_lag=None rewarder_message_lag=None fps=14.47\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,723] [INFO:gym_controlplane.reward.reward] First score parsed: score=15. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:47,724] [INFO:universe.pyprofile] [pyprofile] period=10.38s timers={\"rewarder.sleep\": {\"calls\": 149, \"std\": \"346.12us\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 13, \"std\": \"2.47ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.11ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 39, \"std\": \"34.26us\", \"mean\": \"66.92us\"}, \"rewarder.compute_reward\": {\"calls\": 150, \"std\": \"920.98us\", \"mean\": \"529.27us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"31.34us\", \"mean\": \"65.53us\"}, \"reward.parsing.gameover\": {\"calls\": 13, \"std\": \"137.95us\", \"mean\": \"443.31us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 150, \"std\": \"50.20us\", \"mean\": \"145.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 13, \"std\": \"47.59us\", \"mean\": \"125.33us\"}, \"rewarder.frame\": {\"calls\": 150, \"std\": \"1.20ms\", \"mean\": \"16.68ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 150, \"std\": 1.7296079394362973, \"mean\": 0.21999999999999997}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 33, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 13, \"std\": 14.699555199968572, \"value\": 10, \"mean\": 58.92307692307692}} (export_time=171.18us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *296 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *297 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *298 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *299 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *300 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *301 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *302 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *303 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *304 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:50 [info] 70#70: *305 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:51,563] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.85s, sent 2 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=5 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2097 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:52,729] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16638.3 vnc_pixels_ps[total]=85750.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:52,730] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"777.59us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.07ms\", \"mean\": \"433.14us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"9.35us\", \"mean\": \"26.42us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"347.91us\", \"mean\": \"246.91us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"546.96us\", \"mean\": \"1.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"42.58us\", \"mean\": \"151.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.48us\", \"mean\": \"94.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"14.71us\", \"mean\": \"66.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.19us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910301}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4148511169990527, \"value\": 16.0, \"mean\": 15.208333333333336}} (export_time=105.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:52,730] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.17s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2315 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,529] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=215us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 55->56, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,530] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,531] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=56\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,531] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,531] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,542] init detected end of child process 22508 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,546] init detected end of child process 22523 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,547] init detected end of child process 22733 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,548] init detected end of child process 22725 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,561] init detected end of child process 22754 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:10:53 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,601] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,602] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:53,684] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:53 [info] 70#70: *293 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:53 [info] 70#70: *294 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:53 [info] 70#70: *295 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:10:53 [info] 70#70: *292 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,889] init detected end of child process 22511 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,889] init detected end of child process 22519 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,889] init detected end of child process 22520 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:10:53,889] init detected end of child process 22522 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:54,951] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:54,952] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,396] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,880] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,881] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,881] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,881] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,886] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:58,886] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:10:58 I0508 22:10:58.887023 23148 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:10:58 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41210\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:10:58 I0508 22:10:58.888768 23148 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:10:59,016] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,333] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['154us', '71us', '60us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,333] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,333] [play_vexpect] vexpect macro complete in 1.413344s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:11:00 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41210 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 83.106 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.1592 KiB (1:16.107 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 39 rects, 1.08507 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.8556 MiB (1:1.44967 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,572] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 56->56, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,573] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,573] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=55->56, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,574] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.84s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,575] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=6.0 episode_count=4 episode_duration=12.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,576] [INFO:universe.wrappers.logger] Stats for the past 7.85s: vnc_updates_ps=0.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1286.4 vnc_pixels_ps[total]=5160.8 reward_lag=None rewarder_message_lag=None fps=6.25\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,589] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:00,589] [INFO:universe.pyprofile] [pyprofile] period=7.86s timers={\"rewarder.sleep\": {\"calls\": 48, \"std\": \"262.15us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"5.05ms\", \"mean\": \"2.33ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.47ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"26.15us\", \"mean\": \"30.76us\"}, \"rewarder.compute_reward\": {\"calls\": 49, \"std\": \"2.01ms\", \"mean\": \"553.44us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.60us\", \"mean\": \"38.11us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"134.21us\", \"mean\": \"269.93us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 49, \"std\": \"40.30us\", \"mean\": \"90.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"40.19us\", \"mean\": \"65.92us\"}, \"rewarder.frame\": {\"calls\": 49, \"std\": \"2.18ms\", \"mean\": \"16.45ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 49, \"std\": 3.000708533110184, \"mean\": 0.5306122448979591}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 2.449489742783178, \"value\": 10, \"mean\": 15.0}} (export_time=110.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:02,758] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 3 reward messages to agent: reward=5.0 reward_min=1 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2068 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:04,291] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:05,591] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18004.1 vnc_pixels_ps[total]=79701.0 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:05,609] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.30ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.87ms\", \"mean\": \"1.96ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"22.50us\", \"mean\": \"49.20us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.38ms\", \"mean\": \"481.76us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"4.16ms\", \"mean\": \"8.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"101.25us\", \"mean\": \"276.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.99us\", \"mean\": \"112.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"31.20us\", \"mean\": \"96.97us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"31.58us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8944271909999159, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774091}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.0443794118233494, \"value\": 18.0, \"mean\": 14.22222222222222}} (export_time=277.52us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:05,609] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 2 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 5482, 'rewarder.profile': '<1928 bytes>', 'rewarder.vnc.updates.pixels': 10968, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:06,661] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 2 reward messages to agent: reward=7.0 reward_min=2.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:08,194] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=6.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:10,145] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:10,594] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=12038.9 vnc_pixels_ps[total]=48135.0 reward_lag=None rewarder_message_lag=None fps=59.97\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:10,611] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.68ms\", \"mean\": \"15.90ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.74ms\", \"mean\": \"2.73ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"22.25us\", \"mean\": \"54.96us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.67ms\", \"mean\": \"573.29us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"3.64ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"3.17ms\", \"mean\": \"10.60ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"100.47us\", \"mean\": \"305.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.68us\", \"mean\": \"118.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"22.83us\", \"mean\": \"101.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"206.05us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.7043362064926935, \"mean\": 2.2857142857142856}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774084}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 5.35199725746143, \"value\": 34.0, \"mean\": 28.48148148148148}} (export_time=134.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:11,212] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 3 reward messages to agent: reward=7.0 reward_min=0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2034 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:14,694] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:15,611] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9284.0 vnc_pixels_ps[total]=45587.0 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:15,611] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"777.40us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.22ms\", \"mean\": \"1.17ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"20.39us\", \"mean\": \"36.62us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"772.85us\", \"mean\": \"358.89us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"972.58us\", \"mean\": \"6.06ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"108.59us\", \"mean\": \"209.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"41.75us\", \"mean\": \"98.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.48us\", \"mean\": \"80.61us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"22.36us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.8708286933869707, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177285, \"mean\": 0.09000000000000001}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.2271313297859106, \"value\": 44.0, \"mean\": 42.037037037037045}} (export_time=124.22us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:15,778] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=206us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.60s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 56->57, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,378] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,379] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=57\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,379] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,379] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,395] init detected end of child process 22866 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,398] init detected end of child process 22881 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,400] init detected end of child process 23083 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,403] init detected end of child process 23090 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,418] init detected end of child process 23113 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,458] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,458] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:20 [info] 70#70: *307 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:20 [info] 70#70: *308 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:20 [info] 70#70: *309 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:20 [info] 70#70: *306 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:20,550] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,785] init detected end of child process 22869 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,785] init detected end of child process 22877 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,785] init detected end of child process 22878 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:20,785] init detected end of child process 22880 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:21,776] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:21,777] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:21,813] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,299] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,299] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,299] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,299] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,301] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,301] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:11:22 I0508 22:11:22.301895 23484 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:11:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41346\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:11:22 I0508 22:11:22.309211 23484 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:22,420] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:26,470] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,137] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['268us', '150us', '133us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,138] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,138] [play_vexpect] vexpect macro complete in 5.802841s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:11:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41346 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.037 KiB (1:10.3258 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.0925 MiB (1:2.76001 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,290] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 57->57, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,291] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,291] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=56->57, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,292] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.91s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,292] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=35.0 episode_count=20 episode_duration=27.72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,293] [INFO:universe.wrappers.logger] Stats for the past 12.68s: vnc_updates_ps=1.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2620.8 vnc_pixels_ps[total]=16728.3 reward_lag=None rewarder_message_lag=None fps=22.63\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,305] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:28,306] [INFO:universe.pyprofile] [pyprofile] period=12.69s timers={\"rewarder.sleep\": {\"calls\": 286, \"std\": \"135.08us\", \"mean\": \"16.30ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.29ms\", \"mean\": \"679.57us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"6.30us\", \"mean\": \"22.07us\"}, \"rewarder.compute_reward\": {\"calls\": 287, \"std\": \"773.02us\", \"mean\": \"267.66us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.07us\", \"mean\": \"33.50us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"54.06us\", \"mean\": \"148.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 287, \"std\": \"38.54us\", \"mean\": \"92.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"17.12us\", \"mean\": \"59.27us\"}, \"rewarder.frame\": {\"calls\": 287, \"std\": \"902.39us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.33333333333333337}, \"reward.vnc.updates.n\": {\"calls\": 287, \"std\": 1.4958826071086395, \"mean\": 0.1672473867595819}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 7.1383836923445365, \"value\": 10, \"mean\": 43.49999999999999}} (export_time=106.33us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:29,342] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 2 reward messages to agent: reward=5.0 reward_min=2 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2148 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:33,309] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17778.9 vnc_pixels_ps[total]=88398.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:33,310] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.17ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.57ms\", \"mean\": \"1.10ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"24.89us\", \"mean\": \"51.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"844.59us\", \"mean\": \"408.90us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"680.92us\", \"mean\": \"9.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"115.60us\", \"mean\": \"284.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.78us\", \"mean\": \"116.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"32.05us\", \"mean\": \"109.43us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.37us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.123676058159531, \"value\": 17.0, \"mean\": 15.479999999999997}} (export_time=257.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:33,311] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.97s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:38,325] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5946.1 vnc_pixels_ps[total]=43903.0 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:38,326] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"246.14us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"79.54us\", \"mean\": \"272.67us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.99us\", \"mean\": \"33.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"169.47us\", \"mean\": \"272.30us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"75.25us\", \"mean\": \"190.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.86us\", \"mean\": \"99.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.20us\", \"mean\": \"83.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.82us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 17.0, \"mean\": 17.0}} (export_time=146.63us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:38,326] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1714 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:41,059] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.73s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:42,792] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:43,342] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9243.2 vnc_pixels_ps[total]=45199.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:43,343] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"666.91us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"1.94ms\", \"mean\": \"1.01ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"6.86us\", \"mean\": \"24.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"663.04us\", \"mean\": \"312.25us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"164.90us\", \"mean\": \"5.33ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"23.41us\", \"mean\": \"142.18us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.89us\", \"mean\": \"96.13us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"8.51us\", \"mean\": \"57.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"15.74us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563382, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.0113637278185283, \"value\": 22.0, \"mean\": 18.74074074074074}} (export_time=143.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:44,975] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:46,059] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:48,359] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7555.8 vnc_pixels_ps[total]=44312.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:48,359] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"489.91us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.46ms\", \"mean\": \"671.31us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"15.39us\", \"mean\": \"30.94us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"479.01us\", \"mean\": \"282.54us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"148.19us\", \"mean\": \"5.27ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"60.73us\", \"mean\": \"173.40us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"35.84us\", \"mean\": \"91.59us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.41us\", \"mean\": \"76.55us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.27us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.4966629547095731, \"value\": 27.0, \"mean\": 25.360000000000003}} (export_time=96.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:48,359] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.30s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=255us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 57->58, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,159] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,160] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=58\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,160] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,161] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,175] init detected end of child process 23234 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,179] init detected end of child process 23249 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,182] init detected end of child process 23451 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,183] init detected end of child process 23458 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,199] init detected end of child process 23481 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:49 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:49 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:11:49 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,237] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,237] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:49 [info] 70#70: *311 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:49 [info] 70#70: *312 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:49 [info] 70#70: *313 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:11:49 [info] 70#70: *310 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:49,323] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,521] init detected end of child process 23237 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,521] init detected end of child process 23245 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,521] init detected end of child process 23246 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:11:49,521] init detected end of child process 23248 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:50,586] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:50,586] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,041] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,537] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,538] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,538] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,538] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,545] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,545] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:11:54 I0508 22:11:54.546022 23879 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:11:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41538\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:11:54 I0508 22:11:54.549025 23879 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:54,677] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:56,978] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['292us', '173us', '160us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:56,979] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:56,979] [play_vexpect] vexpect macro complete in 2.400020s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:11:57 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41538 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.874 KiB (1:15.7691 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 998.4 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.85778 MiB (1:1.33283 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 44 rects, 1.09468 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.87982 MiB (1:1.45022 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,247] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 58->58, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,248] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,248] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=57->58, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,248] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.89s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,249] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=17.0 episode_count=14 episode_duration=28.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,249] [INFO:universe.wrappers.logger] Stats for the past 8.89s: vnc_updates_ps=0.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1152.8 vnc_pixels_ps[total]=4689.5 reward_lag=None rewarder_message_lag=None fps=5.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,258] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:11:57,259] [INFO:universe.pyprofile] [pyprofile] period=8.90s timers={\"rewarder.sleep\": {\"calls\": 48, \"std\": \"254.12us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"3.25ms\", \"mean\": \"1.60ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.08ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"21.76us\", \"mean\": \"30.78us\"}, \"rewarder.compute_reward\": {\"calls\": 49, \"std\": \"1.34ms\", \"mean\": \"473.02us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"22.21us\", \"mean\": \"39.02us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"111.85us\", \"mean\": \"261.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 49, \"std\": \"32.26us\", \"mean\": \"89.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"39.91us\", \"mean\": \"72.52us\"}, \"rewarder.frame\": {\"calls\": 49, \"std\": \"2.19ms\", \"mean\": \"16.45ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 49, \"std\": 3.854386140101534, \"mean\": 0.653061224489796}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 6.940220937885671, \"value\": 10, \"mean\": 24.166666666666668}} (export_time=136.14us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:02,266] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16789.8 vnc_pixels_ps[total]=87031.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:02,267] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"641.68us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"100.48us\", \"mean\": \"332.14us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.33us\", \"mean\": \"48.80us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"216.56us\", \"mean\": \"338.22us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"92.79us\", \"mean\": \"277.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.43us\", \"mean\": \"121.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.88us\", \"mean\": \"99.63us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.75us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 12.0, \"mean\": 12.0}} (export_time=197.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:02,267] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=2 reward_min=0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1724 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,982] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=302us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,982] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.72s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 58->59, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,983] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=59\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,984] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:06,984] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:06,995] init detected end of child process 23605 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,000] init detected end of child process 23620 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,002] init detected end of child process 23822 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,004] init detected end of child process 23829 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,019] init detected end of child process 23854 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:07 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:07,057] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:07,057] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:07,144] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:07 [info] 70#70: *315 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:07 [info] 70#70: *316 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:07 [info] 70#70: *317 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:07 [info] 70#70: *314 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,397] init detected end of child process 23608 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,397] init detected end of child process 23616 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,397] init detected end of child process 23617 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:07,397] init detected end of child process 23619 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:08,399] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:08,399] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,204] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,674] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,674] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,674] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,674] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,681] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,681] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:12:12 I0508 22:12:12.681859 24259 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:12:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41680\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:12:12 I0508 22:12:12.68362 24259 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:12,820] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,754] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['171us', '75us', '54us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,754] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,755] [play_vexpect] vexpect macro complete in 1.039560s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:12:13 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41680 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 4 rects, 66.722 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.0781 KiB (1:15.264 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 25 rects, 1.04038 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.97785 MiB (1:1.33285 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 32 rects, 1.10742 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.99463 MiB (1:1.4108 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,963] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 59->59, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,963] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,963] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=58->59, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,964] [INFO:universe.rewarder.remote] [Rewarder] Over past 6.98s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,965] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=2.0 episode_count=3 episode_duration=16.72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,966] [INFO:universe.wrappers.logger] Stats for the past 11.70s: vnc_updates_ps=2.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2871.4 vnc_pixels_ps[total]=18368.3 reward_lag=None rewarder_message_lag=None fps=24.28\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,979] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:13,981] [INFO:universe.pyprofile] [pyprofile] period=11.71s timers={\"rewarder.sleep\": {\"calls\": 283, \"std\": \"202.11us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.56ms\", \"mean\": \"773.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"15.08us\", \"mean\": \"32.77us\"}, \"rewarder.compute_reward\": {\"calls\": 284, \"std\": \"937.57us\", \"mean\": \"311.44us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.32us\", \"mean\": \"48.44us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"89.90us\", \"mean\": \"211.33us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 284, \"std\": \"46.49us\", \"mean\": \"93.05us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.81us\", \"mean\": \"73.51us\"}, \"rewarder.frame\": {\"calls\": 284, \"std\": \"888.15us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 284, \"std\": 0.9264764607692567, \"mean\": 0.1338028169014085}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.40824829046386296, \"value\": 10, \"mean\": 11.916666666666666}} (export_time=211.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:15,932] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:17,449] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:18,982] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17730.3 vnc_pixels_ps[total]=77455.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:18,983] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"886.98us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.48ms\", \"mean\": \"1.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"13.16us\", \"mean\": \"29.68us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"884.01us\", \"mean\": \"350.73us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"1.46ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.81ms\", \"mean\": \"6.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"56.68us\", \"mean\": \"166.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.48us\", \"mean\": \"96.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"19.89us\", \"mean\": \"64.84us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"83.02us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.5811388300841898, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29555586085907787, \"mean\": 0.09634551495016612}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 3.7600440202852363, \"value\": 20.0, \"mean\": 14.068965517241377}} (export_time=84.40us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:18,983] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.profile': '<2020 bytes>', 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:20,066] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:21,616] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:22,899] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:23,999] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10874.5 vnc_pixels_ps[total]=45486.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:23,999] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"847.39us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.37ms\", \"mean\": \"1.45ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"10.07us\", \"mean\": \"26.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"843.56us\", \"mean\": \"338.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"780.12us\", \"mean\": \"5.50ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"37.80us\", \"mean\": \"151.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.57us\", \"mean\": \"88.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"16.49us\", \"mean\": \"63.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.93us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.2535663410560174, \"mean\": 1.2857142857142856}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.1708249800534625, \"value\": 29.0, \"mean\": 25.14814814814815}} (export_time=123.26us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:23,999] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,782] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=209us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,782] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,782] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.78s, sent 2 reward messages to agent: reward=4.0 reward_min=0.0 reward_max=4.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 59->60, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,783] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=60\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,784] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,784] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:27,796] init detected end of child process 23974 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:27,803] init detected end of child process 23989 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:27,808] init detected end of child process 24199 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:27,813] init detected end of child process 24192 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:27,827] init detected end of child process 24223 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:12:27 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,862] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,862] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:27 [info] 70#70: *319 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:27 [info] 70#70: *320 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:27 [info] 70#70: *321 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:12:27 [info] 70#70: *318 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:27,957] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:28,129] init detected end of child process 23977 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:28,129] init detected end of child process 23985 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:28,129] init detected end of child process 23986 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:12:28,129] init detected end of child process 23988 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:29,197] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:29,198] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:32,989] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,482] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,482] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,482] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,482] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,490] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,490] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:12:33 I0508 22:12:33.49088 24620 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:12:33 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41828\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:12:33 I0508 22:12:33.492294 24620 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:33,619] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,587] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['303us', '167us', '214us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,588] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,589] [play_vexpect] vexpect macro complete in 4.064246s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:12:37 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41828 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 20 rects, 950.272 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.71986 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 32 rects, 1.01872 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.73748 MiB (1:1.41973 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,778] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 60->60, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,779] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,779] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=59->60, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,780] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.00s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,780] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=23.0 episode_count=15 episode_duration=23.82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,781] [INFO:universe.wrappers.logger] Stats for the past 13.78s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2048.6 vnc_pixels_ps[total]=12660.7 reward_lag=None rewarder_message_lag=None fps=16.54\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,790] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:37,791] [INFO:universe.pyprofile] [pyprofile] period=13.79s timers={\"rewarder.sleep\": {\"calls\": 227, \"std\": \"147.21us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 20, \"std\": \"1.90ms\", \"mean\": \"645.97us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 60, \"std\": \"7.82us\", \"mean\": \"22.88us\"}, \"rewarder.compute_reward\": {\"calls\": 228, \"std\": \"678.78us\", \"mean\": \"280.22us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.50us\", \"mean\": \"40.97us\"}, \"reward.parsing.gameover\": {\"calls\": 20, \"std\": \"70.74us\", \"mean\": \"160.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 228, \"std\": \"39.41us\", \"mean\": \"98.70us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 20, \"std\": \"31.27us\", \"mean\": \"62.87us\"}, \"rewarder.frame\": {\"calls\": 228, \"std\": \"1.00ms\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 2.3094010767585034, \"mean\": 1.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 228, \"std\": 2.6579880902372297, \"mean\": 0.25877192982456143}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 19, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 20, \"std\": 5.195899192733884, \"value\": 10, \"mean\": 31.449999999999996}} (export_time=155.21us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:39,797] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.02s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2147 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:42,797] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25081.7 vnc_pixels_ps[total]=104509.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:42,798] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.08ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.84ms\", \"mean\": \"868.32us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.25us\", \"mean\": \"41.22us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"869.48us\", \"mean\": \"382.01us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.71ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"99.22us\", \"mean\": \"234.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.87us\", \"mean\": \"120.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.20us\", \"mean\": \"87.88us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.54us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.035909510816206, \"value\": 14.0, \"mean\": 12.166666666666668}} (export_time=246.29us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:42,799] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:43,913] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.11s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:45,448] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:47,814] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9256.3 vnc_pixels_ps[total]=45272.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:47,815] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"839.36us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.72ms\", \"mean\": \"1.70ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.77us\", \"mean\": \"49.75us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"467.41us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"437.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"5.01ms\", \"mean\": \"9.07ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"109.85us\", \"mean\": \"280.41us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.00us\", \"mean\": \"118.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"31.11us\", \"mean\": \"95.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"52.95us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.1547005383792521, \"value\": 17.0, \"mean\": 15.444444444444443}} (export_time=81.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:47,815] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.37s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2005 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:50,215] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.40s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:51,281] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:52,831] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7835.4 vnc_pixels_ps[total]=46476.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:52,832] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"916.28us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.85ms\", \"mean\": \"1.14ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.48us\", \"mean\": \"46.95us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"906.91us\", \"mean\": \"415.60us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.22ms\", \"mean\": \"10.01ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"100.51us\", \"mean\": \"263.86us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.97us\", \"mean\": \"119.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.43us\", \"mean\": \"99.40us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.64us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0214368964029694, \"value\": 21.0, \"mean\": 19.720000000000002}} (export_time=219.82us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:52,832] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:57,057] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.22s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:57,848] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7594.4 vnc_pixels_ps[total]=44553.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:12:57,849] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"885.40us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.71ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.53us\", \"mean\": \"50.52us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"867.07us\", \"mean\": \"401.42us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"516.21us\", \"mean\": \"9.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"117.49us\", \"mean\": \"283.42us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.82us\", \"mean\": \"112.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.57us\", \"mean\": \"96.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.08us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.823756276622986, \"value\": 27.0, \"mean\": 21.750000000000004}} (export_time=328.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:00,397] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.34s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=262us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 60->61, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,581] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,582] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=61\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,582] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,583] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,597] init detected end of child process 24340 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,601] init detected end of child process 24355 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,603] init detected end of child process 24563 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,604] init detected end of child process 24557 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,620] init detected end of child process 24585 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:02 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,663] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,663] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:02,747] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:02 [info] 70#70: *323 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:02 [info] 70#70: *324 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:02 [info] 70#70: *325 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:02 [info] 70#70: *322 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,989] init detected end of child process 24343 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,989] init detected end of child process 24351 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,989] init detected end of child process 24352 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:02,990] init detected end of child process 24354 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:03,979] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:03,979] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,016] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,507] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,508] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,508] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'encoding': 'zrle', 'fine_quality_level': 50, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,508] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,514] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,514] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:04 I0508 22:13:04.514925 24954 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:13:04 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::41968\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:04 I0508 22:13:04.516348 24954 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:04,632] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:08,665] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:12,682] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,632] [play_vexpect] Handled error.VExpectTimeout: Error: vexpect has been looking for the same states for 10s: [ready0, ready1, ready2] (old plausible states: []) (runtime: 10.083568s)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:13:14 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::41968 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 11 rects, 394.496 kpixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  148.573 KiB (1:10.3729 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 18 rects, 787.793 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09093 MiB (1:2.7549 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,819] [INFO:root] [EnvController] RESET CAUSE: VExpect failed with returncode 10, which means it timed out internally. Going to trigger a reset.\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,819] [INFO:root] [EnvController] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,819] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 61->62, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:13:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,871] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,871] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,871] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,880] init detected end of child process 24704 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,883] init detected end of child process 24719 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,887] init detected end of child process 24928 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,889] init detected end of child process 25008 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,889] init detected end of child process 24921 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:14,902] init detected end of child process 24951 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:14,993] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:15 [info] 70#70: *326 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:15 [info] 70#70: *327 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:15 [info] 70#70: *328 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:15 [info] 70#70: *329 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:15,313] init detected end of child process 24707 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:15,313] init detected end of child process 24715 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:15,313] init detected end of child process 24716 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:13:15,314] init detected end of child process 24718 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:16,248] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:16,249] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:20 I0508 22:13:20.516475 62 gymvnc.go:374] [0:127.0.0.1:5900] update queue max of 60 reached; pausing further updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:35 [info] 70#70: *330 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:35 [info] 70#70: *331 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:35 [info] 70#70: *332 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:13:35 [info] 70#70: *333 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,207] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,691] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,691] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,691] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,691] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,693] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,693] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:35 I0508 22:13:35.693557 25369 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:13:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42140\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:35 I0508 22:13:35.694715 25369 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:35,821] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:39,871] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,288] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['142us', '77us', '55us'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,288] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,289] [play_vexpect] vexpect macro complete in 4.561588s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:13:40 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42140 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 6 rects, 668 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            180 B (1:15.2444 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 11.448 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.50195 KiB (1:29.7815 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 68.274 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  18.0225 KiB (1:14.8031 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 17 rects, 819.2 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.34471 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 32 rects, 899.59 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.36395 MiB (1:1.45182 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,493] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 62->62, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,493] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,494] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=60->62, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,494] [INFO:universe.rewarder.remote] [Rewarder] Over past 37.91s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,494] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=20.0 episode_count=16 episode_duration=62.71\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:13:40 I0508 22:13:40.495499 62 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,495] [INFO:universe.wrappers.logger] Stats for the past 42.65s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=882.3 vnc_pixels_ps[total]=5042.9 reward_lag=None rewarder_message_lag=None fps=6.68\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,507] [INFO:universe.pyprofile] [pyprofile] period=42.66s timers={\"rewarder.sleep\": {\"calls\": 284, \"std\": \"730.82us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.03ms\", \"mean\": \"1.20ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"134.87us\", \"mean\": \"10.69ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"20.25us\", \"mean\": \"39.24us\"}, \"rewarder.compute_reward\": {\"calls\": 285, \"std\": \"1.00ms\", \"mean\": \"416.64us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.60us\", \"mean\": \"37.51us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"103.50us\", \"mean\": \"245.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 285, \"std\": \"48.46us\", \"mean\": \"117.14us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.37us\", \"mean\": \"84.36us\"}, \"rewarder.frame\": {\"calls\": 285, \"std\": \"898.87us\", \"mean\": \"16.73ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 285, \"std\": 3.618828941226179, \"mean\": 0.2947368421052632}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 1.5322617553657494, \"value\": 30.0, \"mean\": 28.43478260869565}} (export_time=105.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:40,517] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:42,478] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.98s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2154 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:44,445] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:45,511] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=17.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=34460.1 vnc_pixels_ps[total]=159202.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:45,512] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.49ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.71ms\", \"mean\": \"1.93ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"3.21ms\", \"mean\": \"8.70ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"19.67us\", \"mean\": \"43.78us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.29ms\", \"mean\": \"446.67us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 3, \"std\": \"12.74us\", \"mean\": \"34.33us\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"100.85us\", \"mean\": \"255.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.29us\", \"mean\": \"101.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"27.95us\", \"mean\": \"88.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.78us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774083}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.841992800294027, \"value\": 18.0, \"mean\": 13.999999999999998}} (export_time=127.79us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:45,512] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2069 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:47,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:50,528] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7017.4 vnc_pixels_ps[total]=46110.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:50,529] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"680.08us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.15ms\", \"mean\": \"720.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.66us\", \"mean\": \"40.30us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"672.92us\", \"mean\": \"324.99us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"93.02us\", \"mean\": \"228.42us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.56us\", \"mean\": \"101.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.47us\", \"mean\": \"82.97us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.69us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.9261736493723098, \"value\": 22.0, \"mean\": 20.66666666666666}} (export_time=129.94us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:50,529] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:55,545] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.3 vnc_pixels_ps[total]=44180.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:55,546] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"218.02us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"89.14us\", \"mean\": \"314.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"17.96us\", \"mean\": \"44.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"201.01us\", \"mean\": \"300.00us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"94.97us\", \"mean\": \"254.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.69us\", \"mean\": \"102.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.69us\", \"mean\": \"91.98us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.49us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 22.0, \"mean\": 22.0}} (export_time=183.58us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:55,546] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:58,095] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.55s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:13:59,371] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:00,562] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8467.9 vnc_pixels_ps[total]=45208.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:00,563] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"897.80us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.65ms\", \"mean\": \"1.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.89us\", \"mean\": \"41.21us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"879.99us\", \"mean\": \"390.24us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.07ms\", \"mean\": \"8.02ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"84.82us\", \"mean\": \"232.91us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.40us\", \"mean\": \"106.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"24.67us\", \"mean\": \"85.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.76us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.5053749852292089, \"value\": 26.0, \"mean\": 23.11538461538462}} (export_time=273.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:00,563] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.19s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:02,212] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.65s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:05,578] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7578.8 vnc_pixels_ps[total]=44570.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:05,579] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"668.41us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.98ms\", \"mean\": \"882.43us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"18.61us\", \"mean\": \"47.59us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"649.40us\", \"mean\": \"373.77us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.26ms\", \"mean\": \"6.97ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"90.30us\", \"mean\": \"269.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.98us\", \"mean\": \"109.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.72us\", \"mean\": \"93.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.43us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.8164965809277236, \"value\": 28.0, \"mean\": 27.400000000000002}} (export_time=212.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:05,580] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.37s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:10,595] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.7 vnc_pixels_ps[total]=44021.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:10,595] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"247.87us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"74.78us\", \"mean\": \"353.99us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.53us\", \"mean\": \"52.70us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"213.91us\", \"mean\": \"335.03us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"90.37us\", \"mean\": \"294.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.24us\", \"mean\": \"114.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"21.18us\", \"mean\": \"102.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.26us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=138.76us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:10,596] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:15,611] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.2 vnc_pixels_ps[total]=44340.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:15,612] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"239.58us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"93.85us\", \"mean\": \"344.70us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.99us\", \"mean\": \"51.81us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"208.96us\", \"mean\": \"348.26us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"100.36us\", \"mean\": \"290.89us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.20us\", \"mean\": \"117.92us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.76us\", \"mean\": \"100.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.23us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=112.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:15,612] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:20,629] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.0 vnc_pixels_ps[total]=44177.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:20,629] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"232.49us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"104.31us\", \"mean\": \"357.95us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.58us\", \"mean\": \"51.50us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"229.01us\", \"mean\": \"351.41us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.52us\", \"mean\": \"290.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.84us\", \"mean\": \"117.50us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.74us\", \"mean\": \"104.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.94us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=203.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:20,630] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:25,645] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6213.1 vnc_pixels_ps[total]=46100.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:25,645] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"282.64us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"123.47us\", \"mean\": \"348.93us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"25.63us\", \"mean\": \"51.94us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.29us\", \"mean\": \"350.49us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"141.11us\", \"mean\": \"294.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.10us\", \"mean\": \"117.54us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.88us\", \"mean\": \"100.60us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.90us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=162.60us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:25,646] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:30,662] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.6 vnc_pixels_ps[total]=44020.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:30,662] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"226.22us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"105.86us\", \"mean\": \"324.02us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.74us\", \"mean\": \"44.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"198.07us\", \"mean\": \"331.08us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"91.10us\", \"mean\": \"249.81us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.52us\", \"mean\": \"112.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.67us\", \"mean\": \"93.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.54us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 28.0, \"mean\": 28.0}} (export_time=173.09us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:30,663] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,295] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=305us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,295] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,295] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,295] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 62->63, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=63\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,296] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,297] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,309] init detected end of child process 25071 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,314] init detected end of child process 25086 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,316] init detected end of child process 25292 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,335] init detected end of child process 25315 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,381] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,381] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:34,467] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:14:34 [info] 70#70: *334 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,665] init detected end of child process 25074 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,665] init detected end of child process 25082 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,665] init detected end of child process 25083 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:34,666] init detected end of child process 25085 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:35,749] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:35,750] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,505] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,985] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,985] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,985] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,985] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,987] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:39,987] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:14:39 I0508 22:14:39.987863 25904 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:14:39 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42366\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:14:39 I0508 22:14:39.989702 25904 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:40,110] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,226] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['147us', '68us', '58us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,227] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,227] [play_vexpect] vexpect macro complete in 1.205668s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:14:41 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42366 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 4 rects, 66.722 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.0781 KiB (1:15.264 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 16 rects, 917.504 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.626 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 24 rects, 995.984 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.64425 MiB (1:1.43695 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,485] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 63->63, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,486] [INFO:root] [Rewarder] Unblocking since env reset finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,486] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=62->63, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,486] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.19s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,487] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=18.0 episode_count=22 episode_duration=60.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,487] [INFO:universe.wrappers.logger] Stats for the past 10.83s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2515.2 vnc_pixels_ps[total]=15490.9 reward_lag=None rewarder_message_lag=None fps=20.23\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,498] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:41,498] [INFO:universe.pyprofile] [pyprofile] period=10.84s timers={\"rewarder.sleep\": {\"calls\": 218, \"std\": \"251.96us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 18, \"std\": \"2.19ms\", \"mean\": \"858.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.46ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 54, \"std\": \"21.07us\", \"mean\": \"44.28us\"}, \"rewarder.compute_reward\": {\"calls\": 219, \"std\": \"760.04us\", \"mean\": \"391.82us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"13.37us\", \"mean\": \"44.62us\"}, \"reward.parsing.gameover\": {\"calls\": 18, \"std\": \"103.60us\", \"mean\": \"285.96us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 219, \"std\": \"46.85us\", \"mean\": \"118.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 18, \"std\": \"36.01us\", \"mean\": \"95.33us\"}, \"rewarder.frame\": {\"calls\": 219, \"std\": \"993.06us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 219, \"std\": 1.5054256530573829, \"mean\": 0.17808219178082196}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 48, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 17, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 18, \"std\": 4.242640687119285, \"value\": 10, \"mean\": 27.0}} (export_time=116.83us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:43,138] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.65s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2087 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:46,503] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14880.8 vnc_pixels_ps[total]=79925.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:46,504] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"896.69us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.70ms\", \"mean\": \"721.81us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.60us\", \"mean\": \"55.24us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"566.15us\", \"mean\": \"386.22us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.37ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"107.60us\", \"mean\": \"310.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.96us\", \"mean\": \"122.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.85us\", \"mean\": \"112.19us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.82us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.49453535504684004, \"value\": 13.0, \"mean\": 12.625}} (export_time=113.01us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:46,504] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.37s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1893 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:51,521] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.0 vnc_pixels_ps[total]=44016.2 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:51,522] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"270.67us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"129.65us\", \"mean\": \"384.19us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"23.42us\", \"mean\": \"53.61us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"263.48us\", \"mean\": \"345.16us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"119.27us\", \"mean\": \"304.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.60us\", \"mean\": \"117.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"35.56us\", \"mean\": \"107.25us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.56us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 13.0, \"mean\": 13.0}} (export_time=259.88us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:51,522] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1715 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,203] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=311us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,204] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,204] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,204] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,204] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,204] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 63->64, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,205] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,205] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,205] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=64\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,205] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,206] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,220] init detected end of child process 25622 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,225] init detected end of child process 25637 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,233] init detected end of child process 25846 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,233] init detected end of child process 25893 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,248] init detected end of child process 25871 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:55 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:55 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:14:55 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,280] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,281] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:14:55 [info] 70#70: *336 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:14:55 [info] 70#70: *337 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:14:55 [info] 70#70: *338 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:14:55 [info] 70#70: *335 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:55,369] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,609] init detected end of child process 25625 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,609] init detected end of child process 25633 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,609] init detected end of child process 25634 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:14:55,610] init detected end of child process 25636 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:56,619] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:56,620] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,029] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,523] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,524] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,524] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'compress_level': 0, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,524] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,529] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,529] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:14:57 I0508 22:14:57.529645 26239 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:14:57 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42482\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:14:57 I0508 22:14:57.537283 26239 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:14:57,647] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:01,697] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,130] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['155us', '62us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,131] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,131] [play_vexpect] vexpect macro complete in 7.567858s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:05 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42482 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 131.153 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3193 KiB (1:31.3954 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 331.282 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.985 KiB (1:9.65961 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08477 MiB (1:2.7806 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,319] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 64->64, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,319] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,320] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=63->64, env_state=running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,320] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.12s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,320] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=4.0 episode_count=6 episode_duration=23.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,321] [INFO:universe.wrappers.logger] Stats for the past 13.80s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2260.6 vnc_pixels_ps[total]=12164.3 reward_lag=None rewarder_message_lag=None fps=16.09\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,330] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:05,330] [INFO:universe.pyprofile] [pyprofile] period=13.81s timers={\"rewarder.sleep\": {\"calls\": 221, \"std\": \"1.08ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 20, \"std\": \"3.53ms\", \"mean\": \"1.52ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.50ms\", \"mean\": \"10.99ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 60, \"std\": \"28.00us\", \"mean\": \"57.79us\"}, \"rewarder.compute_reward\": {\"calls\": 222, \"std\": \"1.22ms\", \"mean\": \"497.78us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"17.36us\", \"mean\": \"40.85us\"}, \"reward.parsing.gameover\": {\"calls\": 20, \"std\": \"124.79us\", \"mean\": \"356.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 222, \"std\": \"56.79us\", \"mean\": \"126.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 20, \"std\": \"50.00us\", \"mean\": \"119.46us\"}, \"rewarder.frame\": {\"calls\": 222, \"std\": \"988.35us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.33333333333333337}, \"reward.vnc.updates.n\": {\"calls\": 222, \"std\": 2.1601950052159893, \"mean\": 0.22972972972972971}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 20, \"std\": 0.9459053029269173, \"value\": 10, \"mean\": 13.5}} (export_time=123.02us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:10,337] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17771.6 vnc_pixels_ps[total]=99952.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:10,337] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"623.92us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"104.76us\", \"mean\": \"261.41us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.30us\", \"mean\": \"37.94us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"183.71us\", \"mean\": \"274.12us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"125.83us\", \"mean\": \"216.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.07us\", \"mean\": \"103.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"36.13us\", \"mean\": \"81.40us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.89us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 11.0, \"mean\": 11.0}} (export_time=97.51us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:10,338] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=1 reward_min=0 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:11,554] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,220] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=216us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 64->65, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,221] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=65\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,222] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,222] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,232] init detected end of child process 25980 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,236] init detected end of child process 25995 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,237] init detected end of child process 26197 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,239] init detected end of child process 26204 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,252] init detected end of child process 26230 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,290] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,291] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:14 [info] 70#70: *340 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:14 [info] 70#70: *341 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:14 [info] 70#70: *342 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:14 [info] 70#70: *339 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:14,378] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,605] init detected end of child process 25983 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,605] init detected end of child process 25991 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,605] init detected end of child process 25992 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:14,605] init detected end of child process 25994 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:15,609] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:15,610] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,026] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,506] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,507] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,507] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,507] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,509] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,509] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:19 I0508 22:15:19.509668 26626 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:19 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42652\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:19 I0508 22:15:19.513117 26626 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:19,638] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:21,972] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['184us', '60us', '53us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:21,972] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:21,972] [play_vexpect] vexpect macro complete in 2.429362s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42652 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3535 KiB (1:15.3539 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 34 rects, 1.05933 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.03225 MiB (1:1.33281 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 47 rects, 1.13597 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.05134 MiB (1:1.42033 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,197] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 65->65, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,197] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,198] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=64->65, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,198] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.98s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,198] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=5.0 episode_count=5 episode_duration=16.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,200] [INFO:universe.wrappers.logger] Stats for the past 11.86s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2687.4 vnc_pixels_ps[total]=13790.6 reward_lag=None rewarder_message_lag=None fps=19.73\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,208] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:22,208] [INFO:universe.pyprofile] [pyprofile] period=11.87s timers={\"rewarder.sleep\": {\"calls\": 233, \"std\": \"581.07us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 21, \"std\": \"2.33ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.17ms\", \"mean\": \"6.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 63, \"std\": \"9.52us\", \"mean\": \"23.16us\"}, \"rewarder.compute_reward\": {\"calls\": 234, \"std\": \"834.33us\", \"mean\": \"317.58us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"14.56us\", \"mean\": \"34.45us\"}, \"reward.parsing.gameover\": {\"calls\": 21, \"std\": \"61.87us\", \"mean\": \"156.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 234, \"std\": \"39.66us\", \"mean\": \"95.77us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 21, \"std\": \"17.08us\", \"mean\": \"57.55us\"}, \"rewarder.frame\": {\"calls\": 234, \"std\": \"1.00ms\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 234, \"std\": 1.5239128124924013, \"mean\": 0.18376068376068377}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 57, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 21, \"std\": 1.912365774935031, \"value\": 10, \"mean\": 13.428571428571429}} (export_time=166.18us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:23,333] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.13s, sent 3 reward messages to agent: reward=7.0 reward_min=0 reward_max=4 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2143 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:26,865] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:27,215] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19079.9 vnc_pixels_ps[total]=86601.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:27,215] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.18ms\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.91ms\", \"mean\": \"1.36ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.80us\", \"mean\": \"37.37us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.00ms\", \"mean\": \"381.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.18ms\", \"mean\": \"7.32ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"112.66us\", \"mean\": \"211.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.89us\", \"mean\": \"103.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"25.09us\", \"mean\": \"82.78us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.24us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.6431676725154984, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774094}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.4847110845708347, \"value\": 19.0, \"mean\": 16.407407407407405}} (export_time=83.45us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=209us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.17s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,032] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 65->66, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,033] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,033] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,033] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=66\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,033] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,033] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,048] init detected end of child process 26348 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,052] init detected end of child process 26363 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,054] init detected end of child process 26565 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,057] init detected end of child process 26572 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,072] init detected end of child process 26594 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,113] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,113] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:30 [info] 70#70: *344 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:30 [info] 70#70: *345 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:30 [info] 70#70: *346 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:30 [info] 70#70: *343 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:30,198] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,437] init detected end of child process 26351 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,438] init detected end of child process 26359 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,438] init detected end of child process 26360 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:30,438] init detected end of child process 26362 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:31,430] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:31,431] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,095] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,566] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,566] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,567] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,567] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,574] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,574] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:35 I0508 22:15:35.574506 26990 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42786\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:35 I0508 22:15:35.582408 26990 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:35,701] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,769] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['331us', '192us', '169us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,770] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,770] [play_vexpect] vexpect macro complete in 2.162536s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:37 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42786 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 17 rects, 966.656 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.76668 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 30 rects, 1.04655 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.78576 MiB (1:1.43322 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,966] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 66->66, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,967] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,967] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=65->66, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,967] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.94s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,967] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=9.0 episode_count=7 episode_duration=15.77\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,968] [INFO:universe.wrappers.logger] Stats for the past 10.75s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2045.9 vnc_pixels_ps[total]=11986.8 reward_lag=None rewarder_message_lag=None fps=15.81\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,976] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:37,977] [INFO:universe.pyprofile] [pyprofile] period=10.76s timers={\"rewarder.sleep\": {\"calls\": 169, \"std\": \"135.13us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"1.90ms\", \"mean\": \"726.70us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"11.73us\", \"mean\": \"25.58us\"}, \"rewarder.compute_reward\": {\"calls\": 170, \"std\": \"691.58us\", \"mean\": \"280.98us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.69us\", \"mean\": \"40.57us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"76.95us\", \"mean\": \"184.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 170, \"std\": \"45.39us\", \"mean\": \"97.27us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"21.90us\", \"mean\": \"61.22us\"}, \"rewarder.frame\": {\"calls\": 170, \"std\": \"1.15ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 170, \"std\": 1.9299966004705953, \"mean\": 0.22352941176470587}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 2.4053511772118195, \"value\": 10, \"mean\": 18.357142857142858}} (export_time=169.75us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:39,368] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.40s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:42,634] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.27s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:42,984] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18563.6 vnc_pixels_ps[total]=88547.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:42,985] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.47ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.83ms\", \"mean\": \"1.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"18.99us\", \"mean\": \"44.24us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"421.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.91ms\", \"mean\": \"10.80ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"97.24us\", \"mean\": \"251.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.63us\", \"mean\": \"110.63us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.57us\", \"mean\": \"89.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.68us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4142135623730951, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.2985198674467207, \"value\": 18.0, \"mean\": 13.384615384615383}} (export_time=127.55us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,001] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5910.9 vnc_pixels_ps[total]=43763.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,001] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"195.09us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"106.90us\", \"mean\": \"268.32us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"23.46us\", \"mean\": \"34.77us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"172.31us\", \"mean\": \"268.41us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"120.91us\", \"mean\": \"196.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.90us\", \"mean\": \"105.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.20us\", \"mean\": \"77.96us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.10us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 18.0, \"mean\": 18.0}} (export_time=76.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,002] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.37s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=214us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 66->67, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,768] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,769] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,769] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=67\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,769] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,769] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:48,781] init detected end of child process 26706 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:48,785] init detected end of child process 26721 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:48,788] init detected end of child process 26923 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:48,791] init detected end of child process 26929 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:48,803] init detected end of child process 26951 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:15:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,845] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,846] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:48,929] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:48 [info] 70#70: *348 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:48 [info] 70#70: *349 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:48 [info] 70#70: *350 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:48 [info] 70#70: *347 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:49,165] init detected end of child process 26709 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:49,165] init detected end of child process 26717 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:49,165] init detected end of child process 26718 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:15:49,165] init detected end of child process 26720 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,193] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,194] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,271] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *355 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *356 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *357 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *358 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *359 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *360 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *361 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *362 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *363 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:15:50 [info] 70#70: *364 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,766] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,766] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,766] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,766] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,773] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,773] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:50 I0508 22:15:50.773607 27325 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:50 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::42936\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:15:50 I0508 22:15:50.774865 27325 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:50,891] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:54,941] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:58,992] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,626] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['337us', '190us', '170us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,626] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,627] [play_vexpect] vexpect macro complete in 8.819709s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:15:59 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::42936 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.234 KiB (1:10.3189 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09269 MiB (1:2.76043 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,868] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 67->67, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,868] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,869] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=66->67, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,869] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.87s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,869] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=8.0 episode_count=7 episode_duration=21.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,870] [INFO:universe.wrappers.logger] Stats for the past 11.87s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=865.1 vnc_pixels_ps[total]=3505.6 reward_lag=None rewarder_message_lag=None fps=3.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,877] [INFO:gym_controlplane.reward.reward] First score parsed: score=19. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:15:59,878] [INFO:universe.pyprofile] [pyprofile] period=11.88s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"191.96us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"2.58ms\", \"mean\": \"1.24ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.70us\", \"mean\": \"45.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"51.39us\", \"mean\": \"107.27us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"7.70us\", \"mean\": \"18.07us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"1.14ms\", \"mean\": \"410.68us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"1.13ms\", \"mean\": \"1.48ms\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"115.00us\", \"mean\": \"203.25us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.32ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"20.52us\", \"mean\": \"46.29us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.22ms\", \"mean\": \"16.44ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 5.535772155535472, \"mean\": 0.9148936170212765}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 3.265986323710904, \"value\": 10, \"mean\": 16.666666666666668}} (export_time=156.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:01,337] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.47s, sent 2 reward messages to agent: reward=10.0 reward_min=1.0 reward_max=9 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2500 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:04,587] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.25s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:04,886] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21817.2 vnc_pixels_ps[total]=112169.8 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:04,887] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"15.96ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.81ms\", \"mean\": \"1.42ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"21.38us\", \"mean\": \"61.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"937.07us\", \"mean\": \"476.95us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.39ms\", \"mean\": \"8.44ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"105.63us\", \"mean\": \"345.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.20us\", \"mean\": \"136.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.72us\", \"mean\": \"115.87us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.58us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 3.862210075418823, \"mean\": 3.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0360180178613365, \"value\": 23.0, \"mean\": 20.36}} (export_time=94.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:06,753] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:09,903] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7619.6 vnc_pixels_ps[total]=44813.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:09,903] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"709.71us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.15ms\", \"mean\": \"893.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.64us\", \"mean\": \"35.57us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"702.79us\", \"mean\": \"325.96us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"724.08us\", \"mean\": \"7.66ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"98.39us\", \"mean\": \"201.45us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.33us\", \"mean\": \"102.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.51us\", \"mean\": \"85.47us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.44us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.825741858350553, \"value\": 27.0, \"mean\": 25.0}} (export_time=159.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:09,903] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.15s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,636] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=230us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,636] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,636] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,636] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,636] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,637] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 67->68, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,637] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,637] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,637] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=68\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,637] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,638] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:11,650] init detected end of child process 27074 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:11,655] init detected end of child process 27089 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:11,658] init detected end of child process 27291 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:11,659] init detected end of child process 27298 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:11,677] init detected end of child process 27323 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:16:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:16:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:16:11 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,719] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,719] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:16:11 [info] 70#70: *352 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:16:11 [info] 70#70: *353 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:16:11 [info] 70#70: *354 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:16:11 [info] 70#70: *351 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:11,808] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:12,029] init detected end of child process 27077 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:12,029] init detected end of child process 27085 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:12,029] init detected end of child process 27086 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:16:12,029] init detected end of child process 27088 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,024] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.22s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,025] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,060] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,517] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,518] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,518] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2, 'encoding': 'zrle', 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,518] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,521] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,521] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:16:13 I0508 22:16:13.521635 27692 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:16:13 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::43046\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:16:13 I0508 22:16:13.525063 27692 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:13,648] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:17,681] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:21,731] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:22,749] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['480us', '270us', '247us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:22,750] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:22,751] [play_vexpect] vexpect macro complete in 9.195958s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:16:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::43046 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 13 rects, 284.044 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            750 B (1:1515.11 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 9 rects, 128.521 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3047 KiB (1:30.7973 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 29 rects, 1.02959 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  290.798 KiB (1:13.8315 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 15 rects, 580.096 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.6604 MiB (1:1.33285 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 66 rects, 2.02225 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.96102 MiB (1:3.93419 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,021] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 68->68, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,022] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,022] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=67->68, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,023] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.39s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,023] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=17.0 episode_count=9 episode_duration=23.15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,024] [INFO:universe.wrappers.logger] Stats for the past 13.12s: vnc_updates_ps=0.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1163.8 vnc_pixels_ps[total]=6012.9 reward_lag=None rewarder_message_lag=None fps=8.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,031] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:23,032] [INFO:universe.pyprofile] [pyprofile] period=13.13s timers={\"rewarder.sleep\": {\"calls\": 104, \"std\": \"157.61us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.25ms\", \"mean\": \"915.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.14ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"6.85us\", \"mean\": \"20.15us\"}, \"rewarder.compute_reward\": {\"calls\": 105, \"std\": \"849.33us\", \"mean\": \"316.70us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.28us\", \"mean\": \"39.54us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"92.58us\", \"mean\": \"172.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 105, \"std\": \"35.44us\", \"mean\": \"91.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"19.27us\", \"mean\": \"57.17us\"}, \"rewarder.frame\": {\"calls\": 105, \"std\": \"1.48ms\", \"mean\": \"16.62ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 105, \"std\": 3.710642056149376, \"mean\": 0.4476190476190476}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 5.375872022286245, \"value\": 10, \"mean\": 25.3}} (export_time=211.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:24,590] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.57s, sent 2 reward messages to agent: reward=6.0 reward_min=2 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2098 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:28,040] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20279.3 vnc_pixels_ps[total]=112613.9 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:28,040] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"707.29us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.25ms\", \"mean\": \"535.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.19us\", \"mean\": \"39.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"416.56us\", \"mean\": \"306.26us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.07ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"94.15us\", \"mean\": \"223.41us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.70us\", \"mean\": \"100.09us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.92us\", \"mean\": \"82.49us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.35us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 3.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.9781414201873606, \"value\": 16.0, \"mean\": 14.5}} (export_time=158.07us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:28,041] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.45s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1889 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:33,056] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7013.8 vnc_pixels_ps[total]=46207.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:33,057] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"596.78us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.83ms\", \"mean\": \"641.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.52us\", \"mean\": \"37.61us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"585.03us\", \"mean\": \"313.36us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.07ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"103.26us\", \"mean\": \"214.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.64us\", \"mean\": \"105.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"29.81us\", \"mean\": \"80.41us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.46us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.4082482904638619, \"value\": 17.0, \"mean\": 16.8}} (export_time=144.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:33,057] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1904 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:34,806] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:37,407] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:38,073] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8451.3 vnc_pixels_ps[total]=45053.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:38,073] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.83ms\", \"mean\": \"1.24ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.14us\", \"mean\": \"37.38us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"902.51us\", \"mean\": \"342.87us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.80ms\", \"mean\": \"8.11ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"78.74us\", \"mean\": \"211.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.15us\", \"mean\": \"88.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"20.53us\", \"mean\": \"75.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"534.64us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117918, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.707106781186547, \"value\": 19.0, \"mean\": 17.8}} (export_time=104.19us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:41,523] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.12s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1916 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:43,040] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:43,090] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7598.2 vnc_pixels_ps[total]=44722.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:43,091] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"862.61us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.64ms\", \"mean\": \"1.14ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"25.13us\", \"mean\": \"53.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"860.11us\", \"mean\": \"388.48us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"759.15us\", \"mean\": \"9.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"125.31us\", \"mean\": \"302.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.07us\", \"mean\": \"102.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"33.49us\", \"mean\": \"103.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.20us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.47609522856952213, \"value\": 23.0, \"mean\": 22.32}} (export_time=262.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:45,939] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.90s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:48,107] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8400.9 vnc_pixels_ps[total]=44842.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:48,107] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"755.13us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.65ms\", \"mean\": \"1.50ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.03us\", \"mean\": \"39.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.17ms\", \"mean\": \"413.18us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"294.69us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.00ms\", \"mean\": \"10.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"99.95us\", \"mean\": \"222.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.30us\", \"mean\": \"101.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.76us\", \"mean\": \"83.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.52us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4234303095528935, \"value\": 27.0, \"mean\": 25.115384615384613}} (export_time=153.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:48,108] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2005 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:49,756] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.65s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:53,123] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6726.1 vnc_pixels_ps[total]=44063.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:53,124] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"830.83us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.70ms\", \"mean\": \"831.87us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.81us\", \"mean\": \"38.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"822.15us\", \"mean\": \"355.42us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"75.53us\", \"mean\": \"216.93us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.88us\", \"mean\": \"106.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.12us\", \"mean\": \"85.02us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.26us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519465, \"mean\": 1.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.5510632164580795, \"value\": 31.0, \"mean\": 29.83333333333333}} (export_time=183.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:53,125] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.37s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1912 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:56,024] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.90s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:57,540] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:58,140] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8454.7 vnc_pixels_ps[total]=45159.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:16:58,140] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"773.54us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.73ms\", \"mean\": \"1.60ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"26.10us\", \"mean\": \"50.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.21ms\", \"mean\": \"420.03us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"208.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.05ms\", \"mean\": \"10.52ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"128.29us\", \"mean\": \"286.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.95us\", \"mean\": \"101.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.51us\", \"mean\": \"93.77us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.48us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.4282856857085688, \"value\": 35.0, \"mean\": 31.96}} (export_time=94.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:03,157] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5953.8 vnc_pixels_ps[total]=44176.3 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:03,157] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"205.46us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"93.92us\", \"mean\": \"288.66us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.24us\", \"mean\": \"40.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"186.55us\", \"mean\": \"282.14us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"109.44us\", \"mean\": \"229.88us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.31us\", \"mean\": \"98.99us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.77us\", \"mean\": \"82.13us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.40us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=119.21us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:03,157] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.62s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:08,173] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5995.5 vnc_pixels_ps[total]=44496.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:08,174] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"186.79us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"89.40us\", \"mean\": \"241.51us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"29.81us\", \"mean\": \"33.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"180.92us\", \"mean\": \"241.94us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"108.37us\", \"mean\": \"184.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"75.11us\", \"mean\": \"90.92us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.07us\", \"mean\": \"69.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.40us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=131.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:08,175] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:17:13 [info] 70#70: *366 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:17:13 [info] 70#70: *367 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:17:13 [info] 70#70: *368 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:13,190] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6212.1 vnc_pixels_ps[total]=46092.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:13,190] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"633.55us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"61.36us\", \"mean\": \"245.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.42us\", \"mean\": \"31.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"565.52us\", \"mean\": \"264.78us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"58.18us\", \"mean\": \"182.89us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"546.92us\", \"mean\": \"109.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"17.80us\", \"mean\": \"71.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"160.45us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=144.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:13,191] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1725 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,723] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=251us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,723] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,724] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.53s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,724] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,724] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,724] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 68->69, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,724] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,725] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,725] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=69\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,725] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,726] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:17,743] init detected end of child process 27444 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:17,757] init detected end of child process 27459 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:17,757] init detected end of child process 27667 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:17,760] init detected end of child process 27748 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:17,779] init detected end of child process 27689 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:17:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:17:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:17:17 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,838] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,839] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:17:17 [info] 70#70: *365 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:17,968] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:18,057] init detected end of child process 27458 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:18,057] init detected end of child process 27447 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:18,057] init detected end of child process 27455 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:17:18,057] init detected end of child process 27456 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:19,332] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.36s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:19,332] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,126] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,932] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,932] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,932] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,933] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,943] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:25,943] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:17:25 I0508 22:17:25.944522 28258 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:17:25 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::43648\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:17:25 I0508 22:17:25.954588 28258 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:26,153] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:27,920] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['223us', '118us', '123us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:27,921] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:27,921] [play_vexpect] vexpect macro complete in 1.940883s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:17:27 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::43648 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 4 rects, 19.857 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 2.70508 KiB (1:28.6917 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 22 rects, 909.312 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.60269 MiB (1:1.33285 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 37 rects, 997.535 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.6229 MiB (1:1.45096 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,083] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 69->69, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,091] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,091] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=68->69, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,091] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.37s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,092] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=25.0 episode_count=26 episode_duration=65.07\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,094] [INFO:universe.wrappers.logger] Stats for the past 14.90s: vnc_updates_ps=1.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2184.7 vnc_pixels_ps[total]=13909.0 reward_lag=None rewarder_message_lag=None fps=18.32\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,130] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:28,130] [INFO:universe.pyprofile] [pyprofile] period=14.94s timers={\"rewarder.sleep\": {\"calls\": 272, \"std\": \"160.64us\", \"mean\": \"16.31ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"6.99ms\", \"mean\": \"1.68ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"33.53ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"8.66us\", \"mean\": \"27.79us\"}, \"rewarder.compute_reward\": {\"calls\": 273, \"std\": \"2.21ms\", \"mean\": \"353.62us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.22us\", \"mean\": \"47.49us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"70.70us\", \"mean\": \"187.55us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 273, \"std\": \"22.61us\", \"mean\": \"72.52us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"16.04us\", \"mean\": \"66.21us\"}, \"rewarder.frame\": {\"calls\": 273, \"std\": \"895.02us\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 273, \"std\": 1.5326212946294209, \"mean\": 0.17216117216117216}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 5.212860351426868, \"value\": 10, \"mean\": 33.91304347826087}} (export_time=190.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:33,099] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=10.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=16988.9 vnc_pixels_ps[total]=88469.8 reward_lag=None rewarder_message_lag=None fps=59.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:33,132] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"847.43us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.71ms\", \"mean\": \"642.73us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.16us\", \"mean\": \"43.84us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"635.82us\", \"mean\": \"363.54us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"23.84ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"57.97us\", \"mean\": \"248.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"322.45us\", \"mean\": \"138.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.94us\", \"mean\": \"94.41us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"1.48ms\", \"mean\": \"16.93ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.43588989435406755, \"value\": 12.0, \"mean\": 11.759999999999998}} (export_time=149.01us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:33,133] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.04s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1983 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:34,783] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.65s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:35,882] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:38,115] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7582.3 vnc_pixels_ps[total]=44499.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:38,149] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"859.02us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.71ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.54us\", \"mean\": \"42.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"854.28us\", \"mean\": \"368.21us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.54ms\", \"mean\": \"8.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"97.83us\", \"mean\": \"240.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.97us\", \"mean\": \"108.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.18us\", \"mean\": \"94.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.35us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.8805466023105097, \"value\": 14.0, \"mean\": 13.083333333333329}} (export_time=151.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:38,149] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.27s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:39,549] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.40s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:41,500] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:43,132] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9255.0 vnc_pixels_ps[total]=45266.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:43,165] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.11ms\", \"mean\": \"1.52ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"18.83us\", \"mean\": \"44.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.04ms\", \"mean\": \"414.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.54ms\", \"mean\": \"7.71ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"93.56us\", \"mean\": \"250.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.15us\", \"mean\": \"107.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"33.09us\", \"mean\": \"93.52us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.30us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.386195679382409, \"value\": 19.0, \"mean\": 16.80769230769231}} (export_time=125.17us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:43,166] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:45,849] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.68s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:48,149] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7598.5 vnc_pixels_ps[total]=44724.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:48,166] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"966.90us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.00ms\", \"mean\": \"1.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.15us\", \"mean\": \"54.92us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"964.18us\", \"mean\": \"424.67us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"5.00ms\", \"mean\": \"10.15ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"79.01us\", \"mean\": \"307.68us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"40.93us\", \"mean\": \"115.63us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.08us\", \"mean\": \"111.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"20.41us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27684719634237054, \"mean\": 0.08333333333333334}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.7999999999999994, \"value\": 21.0, \"mean\": 20.160000000000004}} (export_time=211.24us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:48,166] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.32s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1942 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:53,166] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.9 vnc_pixels_ps[total]=44022.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:53,167] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"273.73us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"107.83us\", \"mean\": \"404.19us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.10us\", \"mean\": \"58.94us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"256.73us\", \"mean\": \"380.00us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.79us\", \"mean\": \"332.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"47.99us\", \"mean\": \"128.92us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.39us\", \"mean\": \"116.85us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"20.23us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2665063620734803, \"mean\": 0.07666666666666677}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 21.0, \"mean\": 21.0}} (export_time=157.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:53,167] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:54,716] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.55s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:56,466] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:57,549] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:58,183] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10065.9 vnc_pixels_ps[total]=45546.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:58,183] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.47ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"4.12ms\", \"mean\": \"2.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"28.87us\", \"mean\": \"57.67us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.46ms\", \"mean\": \"550.08us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.33ms\", \"mean\": \"10.26ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"141.43us\", \"mean\": \"321.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.54us\", \"mean\": \"121.23us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"41.25us\", \"mean\": \"106.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.45us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.09302325581395346}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 1.5600841111499189, \"value\": 26.0, \"mean\": 23.714285714285715}} (export_time=136.14us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:17:58,850] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:01,033] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:03,185] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7621.6 vnc_pixels_ps[total]=44860.4 reward_lag=None rewarder_message_lag=None fps=59.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:03,186] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"872.25us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.05ms\", \"mean\": \"1.52ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.69us\", \"mean\": \"55.07us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.29ms\", \"mean\": \"465.36us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"469.92us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.37ms\", \"mean\": \"14.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"110.66us\", \"mean\": \"307.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"65.99us\", \"mean\": \"124.29us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.31us\", \"mean\": \"100.96us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"29.57us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 1.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423705, \"mean\": 0.08333333333333336}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.5811388300841913, \"value\": 33.0, \"mean\": 31.799999999999997}} (export_time=234.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:03,187] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2021 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:06,667] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:08,200] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7016.7 vnc_pixels_ps[total]=46226.3 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:08,201] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"361.85us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.12ms\", \"mean\": \"977.79us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.40us\", \"mean\": \"51.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"970.24us\", \"mean\": \"409.21us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"192.88us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.39ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"108.48us\", \"mean\": \"287.33us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"58.85us\", \"mean\": \"122.56us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"34.27us\", \"mean\": \"103.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.25us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.8330302779823364, \"value\": 37.0, \"mean\": 34.12}} (export_time=170.71us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:08,201] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2001 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:13,217] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.8 vnc_pixels_ps[total]=44021.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:13,218] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"278.21us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"90.91us\", \"mean\": \"390.70us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.79us\", \"mean\": \"56.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"248.10us\", \"mean\": \"382.57us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"97.74us\", \"mean\": \"324.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.71us\", \"mean\": \"131.27us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.84us\", \"mean\": \"113.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.80us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=214.34us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:13,219] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:18,233] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.8 vnc_pixels_ps[total]=44344.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:18,233] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"262.67us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"102.19us\", \"mean\": \"276.17us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.82us\", \"mean\": \"37.96us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"182.92us\", \"mean\": \"282.10us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.49us\", \"mean\": \"216.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.34us\", \"mean\": \"99.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"29.59us\", \"mean\": \"82.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.97us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=128.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:18,234] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:18:19 [info] 70#70: *370 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:18:19 [info] 70#70: *371 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:18:19 [info] 70#70: *372 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=218us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.65s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 69->70, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,883] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,884] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,884] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=70\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,884] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,884] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:22,895] init detected end of child process 27976 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:22,899] init detected end of child process 27991 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:22,901] init detected end of child process 28199 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:22,918] init detected end of child process 28225 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:18:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:18:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:18:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,952] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:22,952] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:23,037] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:18:23 [info] 70#70: *369 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:23,249] init detected end of child process 27979 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:23,249] init detected end of child process 27987 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:23,249] init detected end of child process 27988 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:18:23,249] init detected end of child process 27990 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,302] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,303] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,370] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,888] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,888] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,888] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,889] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,891] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:24,891] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:18:24 I0508 22:18:24.891501 28781 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:18:24 I0508 22:18:24.893487 28781 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:18:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::43852\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:25,013] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:29,063] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,797] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['194us', '102us', '90us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,797] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,798] [play_vexpect] vexpect macro complete in 7.872751s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:18:32 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::43852 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.227 KiB (1:10.3195 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27231 MiB (1:2.37073 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,993] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 70->70, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,994] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,994] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=69->70, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,994] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.11s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,994] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=27.0 episode_count=29 episode_duration=64.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:32,995] [INFO:universe.wrappers.logger] Stats for the past 14.76s: vnc_updates_ps=1.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2197.9 vnc_pixels_ps[total]=13942.9 reward_lag=None rewarder_message_lag=None fps=18.97\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:33,007] [INFO:gym_controlplane.reward.reward] First score parsed: score=20. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:33,007] [INFO:universe.pyprofile] [pyprofile] period=14.77s timers={\"rewarder.sleep\": {\"calls\": 279, \"std\": \"179.20us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"2.21ms\", \"mean\": \"701.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.68ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"30.09us\", \"mean\": \"30.46us\"}, \"rewarder.compute_reward\": {\"calls\": 280, \"std\": \"737.41us\", \"mean\": \"289.28us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.41us\", \"mean\": \"34.65us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"115.82us\", \"mean\": \"190.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 280, \"std\": \"43.38us\", \"mean\": \"93.31us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.90us\", \"mean\": \"63.46us\"}, \"rewarder.frame\": {\"calls\": 280, \"std\": \"923.28us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 280, \"std\": 2.045013166961669, \"mean\": 0.20000000000000007}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 5.629889179541019, \"value\": 10, \"mean\": 35.82608695652174}} (export_time=160.93us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:34,378] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 2 reward messages to agent: reward=11.0 reward_min=1.0 reward_max=10 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2099 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:38,012] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19271.0 vnc_pixels_ps[total]=105186.4 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:38,013] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"895.84us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.64ms\", \"mean\": \"648.23us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.63us\", \"mean\": \"45.73us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"516.76us\", \"mean\": \"358.34us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.85ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"100.50us\", \"mean\": \"260.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.85us\", \"mean\": \"117.14us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.48us\", \"mean\": \"95.50us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.98us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 6.363961030678928, \"mean\": 5.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.470471968896964, \"value\": 21.0, \"mean\": 20.695652173913047}} (export_time=242.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:38,013] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:42,395] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.38s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:43,028] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7579.7 vnc_pixels_ps[total]=44577.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:43,029] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.87ms\", \"mean\": \"1.45ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.77us\", \"mean\": \"50.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"433.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"822.20us\", \"mean\": \"13.73ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"119.17us\", \"mean\": \"287.30us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.54us\", \"mean\": \"116.77us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.64us\", \"mean\": \"98.21us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.81us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.3316624790355395, \"value\": 22.0, \"mean\": 21.12}} (export_time=97.75us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:48,029] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"232.94us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"116.81us\", \"mean\": \"322.02us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"34.42us\", \"mean\": \"47.88us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"218.12us\", \"mean\": \"307.77us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"194.60us\", \"mean\": \"279.90us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"41.83us\", \"mean\": \"104.97us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.32us\", \"mean\": \"95.01us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"19.59us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470293, \"mean\": 0.08000000000000006}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.40824829046386274, \"value\": 24.0, \"mean\": 23.916666666666668}} (export_time=113.96us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:48,029] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.63s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1790 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:48,045] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6253.5 vnc_pixels_ps[total]=46410.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:53,045] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"190.84us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"83.67us\", \"mean\": \"253.64us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.37us\", \"mean\": \"36.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"161.37us\", \"mean\": \"256.69us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"96.11us\", \"mean\": \"203.97us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.61us\", \"mean\": \"91.56us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.24us\", \"mean\": \"74.35us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.52us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289038}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 24.0, \"mean\": 24.0}} (export_time=108.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:53,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:53,062] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5945.1 vnc_pixels_ps[total]=44108.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:55,812] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.77s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:58,045] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"450.91us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.27ms\", \"mean\": \"591.27us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.45us\", \"mean\": \"46.97us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"442.92us\", \"mean\": \"340.45us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.21ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"80.64us\", \"mean\": \"267.66us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"54.27us\", \"mean\": \"107.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.17us\", \"mean\": \"93.75us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"21.22us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.08000000000000004}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5036101551853345, \"value\": 25.0, \"mean\": 24.416666666666668}} (export_time=186.68us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:58,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.23s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:18:58,078] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6674.9 vnc_pixels_ps[total]=43629.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:03,045] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"250.20us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"119.84us\", \"mean\": \"382.49us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.10us\", \"mean\": \"53.53us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"235.18us\", \"mean\": \"349.71us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"105.39us\", \"mean\": \"305.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"43.81us\", \"mean\": \"117.34us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.45us\", \"mean\": \"112.06us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"18.85us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.0766666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 25.0, \"mean\": 25.0}} (export_time=226.74us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:03,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:03,095] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5953.9 vnc_pixels_ps[total]=44177.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:08,045] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"280.54us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"119.83us\", \"mean\": \"411.38us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.64us\", \"mean\": \"61.32us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"259.22us\", \"mean\": \"362.35us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"136.04us\", \"mean\": \"348.19us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.87us\", \"mean\": \"119.51us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"34.22us\", \"mean\": \"120.65us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"22.99us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.0766666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 25.0, \"mean\": 25.0}} (export_time=234.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:08,046] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:08,111] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:13,062] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"278.17us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"118.84us\", \"mean\": \"406.07us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.34us\", \"mean\": \"58.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"251.25us\", \"mean\": \"355.72us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"109.30us\", \"mean\": \"324.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.75us\", \"mean\": \"118.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.52us\", \"mean\": \"117.49us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.73us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 25.0, \"mean\": 25.0}} (export_time=249.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:13,063] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:13,128] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.1 vnc_pixels_ps[total]=44016.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:18,078] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"279.05us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"124.26us\", \"mean\": \"399.49us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.41us\", \"mean\": \"56.85us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"251.67us\", \"mean\": \"357.25us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"93.95us\", \"mean\": \"320.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.81us\", \"mean\": \"115.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.27us\", \"mean\": \"113.55us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.53us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 25.0, \"mean\": 25.0}} (export_time=220.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:18,079] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:18,147] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.4 vnc_pixels_ps[total]=45933.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,779] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=911us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,780] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,780] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.70s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,781] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,782] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,782] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 70->71, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,782] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,782] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,783] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=71\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,784] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,784] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:21,803] init detected end of child process 28522 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:21,811] init detected end of child process 28537 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:21,813] init detected end of child process 28739 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:21,815] init detected end of child process 28746 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:21,830] init detected end of child process 28772 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,870] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,871] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:21 [info] 70#70: *374 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:21 [info] 70#70: *375 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:21 [info] 70#70: *376 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:21 [info] 70#70: *373 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:21,963] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:22,121] init detected end of child process 28525 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:22,121] init detected end of child process 28533 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:22,121] init detected end of child process 28534 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:22,121] init detected end of child process 28536 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:23,241] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:23,241] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:26,669] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,161] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,161] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,161] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,162] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,163] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,163] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:19:27 I0508 22:19:27.164094 29340 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:19:27 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::44104\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:19:27 I0508 22:19:27.18165 29340 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:27,299] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,599] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['154us', '62us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,600] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,600] [play_vexpect] vexpect macro complete in 1.396009s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:19:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::44104 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 5 rects, 74.914 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  18.6514 KiB (1:15.6928 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 24 rects, 921.088 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.63643 MiB (1:1.33284 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 33 rects, 1.00776 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.65622 MiB (1:1.44742 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,863] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 71->71, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,864] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,864] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=70->71, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,865] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.08s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,865] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=15.0 episode_count=15 episode_duration=55.87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,866] [INFO:universe.wrappers.logger] Stats for the past 10.72s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2404.9 vnc_pixels_ps[total]=14637.3 reward_lag=None rewarder_message_lag=None fps=20.43\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,874] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:28,874] [INFO:universe.pyprofile] [pyprofile] period=10.80s timers={\"rewarder.sleep\": {\"calls\": 222, \"std\": \"315.02us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 19, \"std\": \"1.60ms\", \"mean\": \"744.59us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 57, \"std\": \"32.67us\", \"mean\": \"56.97us\"}, \"rewarder.compute_reward\": {\"calls\": 223, \"std\": \"662.33us\", \"mean\": \"405.89us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"43.03us\", \"mean\": \"72.60us\"}, \"reward.parsing.gameover\": {\"calls\": 19, \"std\": \"293.84us\", \"mean\": \"377.25us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 223, \"std\": \"42.77us\", \"mean\": \"113.94us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 19, \"std\": \"40.10us\", \"mean\": \"103.70us\"}, \"rewarder.frame\": {\"calls\": 223, \"std\": \"800.20us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 223, \"std\": 1.2305941229860535, \"mean\": 0.16143497757847539}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 51, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 19, \"std\": 3.4412360080584263, \"value\": 10, \"mean\": 24.210526315789473}} (export_time=148.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:29,898] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2102 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:33,882] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14966.0 vnc_pixels_ps[total]=80389.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:33,883] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"694.43us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.03ms\", \"mean\": \"545.21us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.86us\", \"mean\": \"47.42us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"378.36us\", \"mean\": \"364.56us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.12ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"95.81us\", \"mean\": \"269.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.56us\", \"mean\": \"120.15us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.67us\", \"mean\": \"96.25us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.75us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.8846517369293828, \"value\": 12.0, \"mean\": 11.500000000000002}} (export_time=225.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:33,884] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.99s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:38,899] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.0 vnc_pixels_ps[total]=44023.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:38,900] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"298.89us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"87.87us\", \"mean\": \"386.35us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.98us\", \"mean\": \"56.84us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"249.47us\", \"mean\": \"368.64us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"97.03us\", \"mean\": \"322.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"64.02us\", \"mean\": \"124.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.59us\", \"mean\": \"111.64us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"50.29us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 12.0, \"mean\": 12.0}} (export_time=190.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:38,900] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:43,916] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5958.3 vnc_pixels_ps[total]=44170.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:43,917] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"259.61us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.06us\", \"mean\": \"362.63us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.35us\", \"mean\": \"50.88us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"226.36us\", \"mean\": \"352.36us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"65.90us\", \"mean\": \"289.76us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.12us\", \"mean\": \"119.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.29us\", \"mean\": \"102.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.49us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 12.0, \"mean\": 12.0}} (export_time=230.79us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:43,917] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:48,932] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.3 vnc_pixels_ps[total]=44296.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:48,933] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"290.34us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.17ms\", \"mean\": \"1.01ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"27.77us\", \"mean\": \"55.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"968.49us\", \"mean\": \"403.11us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"183.58us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.41ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"127.91us\", \"mean\": \"308.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.47us\", \"mean\": \"115.95us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"33.94us\", \"mean\": \"106.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.03us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910305}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 12.0, \"mean\": 12.0}} (export_time=138.28us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:48,933] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,615] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=244us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,615] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,615] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.68s, sent 3 reward messages to agent: reward=6.0 reward_min=0.0 reward_max=3.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,615] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 71->72, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,616] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,617] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:52,632] init detected end of child process 29062 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:52,636] init detected end of child process 29077 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:52,637] init detected end of child process 29284 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:52,637] init detected end of child process 29279 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:52,655] init detected end of child process 29305 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:52 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:52 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:19:52 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,689] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,689] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:52 [info] 70#70: *378 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:52 [info] 70#70: *379 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:52 [info] 70#70: *380 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:19:52 [info] 70#70: *377 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:52,777] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:53,005] init detected end of child process 29065 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:53,005] init detected end of child process 29073 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:53,005] init detected end of child process 29074 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:19:53,006] init detected end of child process 29076 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,039] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,040] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,083] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,563] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,563] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,563] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,564] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,571] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,572] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:19:54 I0508 22:19:54.572264 29669 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:19:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::44240\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:19:54 I0508 22:19:54.57369 29669 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:54,693] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:19:58,726] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:02,793] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,560] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['154us', '64us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,560] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,560] [play_vexpect] vexpect macro complete in 8.954724s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:20:03 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::44240 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.045 KiB (1:10.3252 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27213 MiB (1:2.37029 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,769] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 72->72, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,770] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,770] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=71->72, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,770] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.16s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,771] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=8.0 episode_count=9 episode_duration=34.91\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,772] [INFO:universe.wrappers.logger] Stats for the past 14.84s: vnc_updates_ps=1.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2091.7 vnc_pixels_ps[total]=11231.1 reward_lag=None rewarder_message_lag=None fps=14.96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,781] [INFO:gym_controlplane.reward.reward] First score parsed: score=18. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:03,781] [INFO:universe.pyprofile] [pyprofile] period=14.85s timers={\"rewarder.sleep\": {\"calls\": 221, \"std\": \"853.28us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 20, \"std\": \"3.02ms\", \"mean\": \"1.34ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.28ms\", \"mean\": \"9.72ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 60, \"std\": \"25.00us\", \"mean\": \"52.75us\"}, \"rewarder.compute_reward\": {\"calls\": 222, \"std\": \"1.06ms\", \"mean\": \"451.21us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.02us\", \"mean\": \"45.66us\"}, \"reward.parsing.gameover\": {\"calls\": 20, \"std\": \"108.56us\", \"mean\": \"328.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 222, \"std\": \"47.87us\", \"mean\": \"117.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 20, \"std\": \"38.91us\", \"mean\": \"104.24us\"}, \"rewarder.frame\": {\"calls\": 222, \"std\": \"1.03ms\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 1.7320508075688772, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 222, \"std\": 2.5600170255946013, \"mean\": 0.25675675675675674}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 20, \"std\": 2.521486612465373, \"value\": 10, \"mean\": 16.4}} (export_time=166.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:07,404] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 2 reward messages to agent: reward=10.0 reward_min=2.0 reward_max=8 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2151 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:08,787] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=12.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20858.7 vnc_pixels_ps[total]=111028.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:08,788] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"803.38us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.48ms\", \"mean\": \"640.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"6.28us\", \"mean\": \"24.14us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"467.36us\", \"mean\": \"265.69us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"51.92us\", \"mean\": \"5.24ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"21.35us\", \"mean\": \"138.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.03us\", \"mean\": \"98.61us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"14.45us\", \"mean\": \"61.56us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.69us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 3.0550504633038935, \"mean\": 4.666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.041241452319315, \"value\": 24.0, \"mean\": 19.083333333333332}} (export_time=106.33us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:08,788] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.38s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:13,804] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6542.5 vnc_pixels_ps[total]=42683.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:13,804] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"420.70us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.36ms\", \"mean\": \"493.23us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"9.49us\", \"mean\": \"25.88us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"416.75us\", \"mean\": \"252.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.42ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"39.17us\", \"mean\": \"146.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.99us\", \"mean\": \"98.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"14.36us\", \"mean\": \"60.08us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"14.81us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.4217411678366489, \"value\": 25.0, \"mean\": 24.782608695652176}} (export_time=93.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:13,805] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=211us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 72->73, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,571] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,572] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,572] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=73\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,572] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,572] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,584] init detected end of child process 29422 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,587] init detected end of child process 29437 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,591] init detected end of child process 29644 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,591] init detected end of child process 29639 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,606] init detected end of child process 29666 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:20:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:20:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:20:14 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,645] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,646] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:14 [info] 70#70: *382 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:14 [info] 70#70: *383 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:14 [info] 70#70: *384 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:14 [info] 70#70: *381 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:14,738] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,965] init detected end of child process 29425 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,965] init detected end of child process 29433 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,965] init detected end of child process 29434 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:20:14,965] init detected end of child process 29436 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:15,987] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:15,988] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,024] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,509] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,510] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,510] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2, 'compress_level': 0, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,510] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,517] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,517] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:20:16 I0508 22:20:16.51809 30043 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:20:16 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::44382\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:20:16 I0508 22:20:16.519743 30043 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:16,637] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:20,704] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,338] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['349us', '282us', '184us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,339] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,340] [play_vexpect] vexpect macro complete in 6.788381s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:20:23 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::44382 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 131.153 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3193 KiB (1:31.3954 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 331.026 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.85 KiB (1:9.66185 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08464 MiB (1:2.78003 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,619] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 73->73, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,619] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,620] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=72->73, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,621] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.82s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,621] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=15.0 episode_count=7 episode_duration=19.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,622] [INFO:universe.wrappers.logger] Stats for the past 9.82s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1028.1 vnc_pixels_ps[total]=4124.6 reward_lag=None rewarder_message_lag=None fps=4.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,632] [INFO:gym_controlplane.reward.reward] First score parsed: score=29. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:23,632] [INFO:universe.pyprofile] [pyprofile] period=9.83s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"219.16us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"3.77ms\", \"mean\": \"1.74ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.26ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"7.87us\", \"mean\": \"17.40us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"1.56ms\", \"mean\": \"466.35us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.97us\", \"mean\": \"34.73us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"100.84us\", \"mean\": \"184.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"43.10us\", \"mean\": \"97.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"18.92us\", \"mean\": \"44.98us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.25ms\", \"mean\": \"16.44ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 4.3711906899726545, \"mean\": 0.7446808510638298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 6.123724356957945, \"value\": 10, \"mean\": 22.5}} (export_time=120.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:28,639] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17832.1 vnc_pixels_ps[total]=94793.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:28,640] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"731.25us\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"142.04us\", \"mean\": \"452.31us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"49.24us\", \"mean\": \"75.52us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"307.93us\", \"mean\": \"423.71us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"177.89us\", \"mean\": \"403.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.05us\", \"mean\": \"140.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.23us\", \"mean\": \"134.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.05us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 19.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 29.0, \"mean\": 29.0}} (export_time=256.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:28,640] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=19 reward_min=0 reward_max=19 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:33,655] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5938.2 vnc_pixels_ps[total]=44015.3 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:33,656] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"361.04us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"251.86us\", \"mean\": \"442.94us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"51.84us\", \"mean\": \"66.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"305.95us\", \"mean\": \"393.48us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"261.89us\", \"mean\": \"366.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.25us\", \"mean\": \"128.54us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"100.78us\", \"mean\": \"132.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.88us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 29.0, \"mean\": 29.0}} (export_time=276.57us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:33,657] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:35,005] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.35s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:37,188] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:38,672] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8425.4 vnc_pixels_ps[total]=44990.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:38,672] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"15.95ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.69ms\", \"mean\": \"1.66ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"27.12us\", \"mean\": \"61.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"506.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.82ms\", \"mean\": \"10.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"137.69us\", \"mean\": \"343.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"59.64us\", \"mean\": \"129.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"34.02us\", \"mean\": \"114.12us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.70us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152826}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.8127751780498977, \"value\": 34.0, \"mean\": 30.61538461538462}} (export_time=206.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:38,673] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.48s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:41,505] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.83s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:43,022] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=10.0 reward_min=2.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:43,688] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9481.4 vnc_pixels_ps[total]=47030.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:43,688] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.35ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.82ms\", \"mean\": \"1.93ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"22.51us\", \"mean\": \"62.66us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.33ms\", \"mean\": \"532.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.90ms\", \"mean\": \"10.62ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"96.84us\", \"mean\": \"346.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"76.13us\", \"mean\": \"126.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"31.90us\", \"mean\": \"118.52us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.76us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.9235384061671346, \"mean\": 2.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395347}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 4.3246249493315565, \"value\": 45.0, \"mean\": 37.035714285714285}} (export_time=158.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:46,054] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:48,705] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8446.3 vnc_pixels_ps[total]=44997.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:48,706] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.63ms\", \"mean\": \"1.67ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"58.63us\", \"mean\": \"56.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"476.52us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.42ms\", \"mean\": \"10.43ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"364.55us\", \"mean\": \"354.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.30us\", \"mean\": \"122.01us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.81us\", \"mean\": \"101.02us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.26us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9168313422570833, \"value\": 47.0, \"mean\": 45.833333333333336}} (export_time=324.49us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:48,707] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.65s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1940 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *389 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *390 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *391 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *392 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *393 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *394 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *395 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *396 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *397 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:20:50 [info] 70#70: *398 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:52,555] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.85s, sent 3 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:53,722] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9244.8 vnc_pixels_ps[total]=45279.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:53,723] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.34ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.81ms\", \"mean\": \"1.92ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.86ms\", \"mean\": \"10.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"27.39us\", \"mean\": \"61.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.32ms\", \"mean\": \"550.33us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"1.48ms\", \"mean\": \"1.81ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"133.65us\", \"mean\": \"348.35us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"67.26us\", \"mean\": \"133.61us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"32.78us\", \"mean\": \"115.38us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.61us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.0488088481701514, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774087}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.0939473213563398, \"value\": 56.0, \"mean\": 50.666666666666664}} (export_time=278.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:53,723] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.17s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2324 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:58,738] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.9 vnc_pixels_ps[total]=44345.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:58,738] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"328.82us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"132.56us\", \"mean\": \"433.37us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.79us\", \"mean\": \"64.65us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"274.95us\", \"mean\": \"397.82us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"106.39us\", \"mean\": \"362.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.82us\", \"mean\": \"130.40us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"40.26us\", \"mean\": \"125.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.88us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 56.0, \"mean\": 56.0}} (export_time=174.76us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:20:58,739] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1713 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:02,538] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.80s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:03,754] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8421.1 vnc_pixels_ps[total]=44999.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:03,755] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"813.69us\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.32ms\", \"mean\": \"1.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.82us\", \"mean\": \"60.91us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"804.43us\", \"mean\": \"455.83us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.78ms\", \"mean\": \"7.05ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"112.90us\", \"mean\": \"340.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.12us\", \"mean\": \"125.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"32.91us\", \"mean\": \"110.52us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.19us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152829}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.8566482089201827, \"value\": 59.0, \"mean\": 56.42307692307692}} (export_time=164.27us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:03,756] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:06,671] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.92s, sent 3 reward messages to agent: reward=8.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:08,772] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8485.5 vnc_pixels_ps[total]=45397.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:08,772] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.20ms\", \"mean\": \"1.47ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"25.29us\", \"mean\": \"54.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.05ms\", \"mean\": \"440.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.00ms\", \"mean\": \"9.01ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"131.32us\", \"mean\": \"308.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.33us\", \"mean\": \"116.44us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"39.55us\", \"mean\": \"112.19us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.65us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.632993161855452, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613574, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.70801280154532, \"value\": 67.0, \"mean\": 63.8}} (export_time=219.58us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:08,773] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.10s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1915 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:10,171] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.40s, sent 3 reward messages to agent: reward=11.0 reward_min=2.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:11,255] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:12,988] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:13,788] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9197.5 vnc_pixels_ps[total]=44875.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:13,788] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.58ms\", \"mean\": \"1.70ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"27.17us\", \"mean\": \"49.49us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"450.36us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.18ms\", \"mean\": \"9.02ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"136.31us\", \"mean\": \"277.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.57us\", \"mean\": \"109.85us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"33.25us\", \"mean\": \"94.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.81us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.8618986725025255, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774084}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 4.4027963142320585, \"value\": 81.0, \"mean\": 76.66666666666667}} (export_time=95.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,337] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=219us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,338] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,338] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.35s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1929 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,338] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,338] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,338] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 73->74, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,339] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,339] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,339] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=74\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,339] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,340] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,357] init detected end of child process 29795 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,361] init detected end of child process 29810 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,364] init detected end of child process 30012 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,366] init detected end of child process 30019 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,382] init detected end of child process 30041 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,421] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,421] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:15,508] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:15 [info] 70#70: *386 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:15 [info] 70#70: *387 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:15 [info] 70#70: *388 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:15 [info] 70#70: *385 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,697] init detected end of child process 29798 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,697] init detected end of child process 29806 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,697] init detected end of child process 29807 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:15,698] init detected end of child process 29809 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:16,768] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:16,769] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,162] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,669] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,670] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,670] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'compress_level': 0, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,670] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,677] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,678] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:21:20 I0508 22:21:20.678308 30603 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:21:20 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::44680\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:21:20 I0508 22:21:20.679581 30603 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:20,800] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,118] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['286us', '162us', '147us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,118] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,119] [play_vexpect] vexpect macro complete in 3.407200s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:21:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::44680 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3721 KiB (1:15.3392 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 998.4 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.85778 MiB (1:1.33283 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 43 rects, 1.08649 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.87836 MiB (1:1.4401 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,371] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 74->74, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,372] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,372] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=73->74, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,372] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.03s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,372] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=71.0 episode_count=36 episode_duration=60.75\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,373] [INFO:universe.wrappers.logger] Stats for the past 10.58s: vnc_updates_ps=0.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1312.8 vnc_pixels_ps[total]=6457.1 reward_lag=None rewarder_message_lag=None fps=8.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,382] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:24,382] [INFO:universe.pyprofile] [pyprofile] period=10.59s timers={\"rewarder.sleep\": {\"calls\": 93, \"std\": \"240.81us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 9, \"std\": \"2.55ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.78ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 27, \"std\": \"28.18us\", \"mean\": \"35.44us\"}, \"rewarder.compute_reward\": {\"calls\": 94, \"std\": \"986.69us\", \"mean\": \"372.93us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.27us\", \"mean\": \"34.45us\"}, \"reward.parsing.gameover\": {\"calls\": 9, \"std\": \"144.41us\", \"mean\": \"259.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 94, \"std\": \"38.63us\", \"mean\": \"96.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 9, \"std\": \"48.11us\", \"mean\": \"86.86us\"}, \"rewarder.frame\": {\"calls\": 94, \"std\": \"1.53ms\", \"mean\": \"16.60ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 94, \"std\": 3.098106077500336, \"mean\": 0.4042553191489362}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 8, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 9, \"std\": 23.666666666666668, \"value\": 10, \"mean\": 73.11111111111111}} (export_time=115.63us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:26,673] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.30s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2085 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:27,990] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:29,389] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20620.4 vnc_pixels_ps[total]=97944.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:29,390] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"923.34us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.43ms\", \"mean\": \"1.58ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"23.47us\", \"mean\": \"46.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.17ms\", \"mean\": \"417.15us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"65.80us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.29ms\", \"mean\": \"8.43ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"115.01us\", \"mean\": \"263.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.63us\", \"mean\": \"105.65us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"31.76us\", \"mean\": \"92.54us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"71.51us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.4675987714106855, \"value\": 15.0, \"mean\": 12.333333333333332}} (export_time=86.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:29,390] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.40s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2003 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:34,406] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6776.0 vnc_pixels_ps[total]=44449.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:34,407] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"638.03us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.94ms\", \"mean\": \"747.28us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"30.10us\", \"mean\": \"55.67us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"630.90us\", \"mean\": \"344.94us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.44ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"142.11us\", \"mean\": \"309.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.34us\", \"mean\": \"106.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"30.20us\", \"mean\": \"101.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.41us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260707, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 15.0, \"mean\": 15.0}} (export_time=148.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:34,407] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1833 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:39,423] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5945.5 vnc_pixels_ps[total]=44110.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:39,423] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"199.61us\", \"mean\": \"16.25ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.04us\", \"mean\": \"262.38us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.27us\", \"mean\": \"32.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"159.86us\", \"mean\": \"253.97us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"74.60us\", \"mean\": \"189.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.16us\", \"mean\": \"91.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.39us\", \"mean\": \"77.03us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.81us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.834057656228299, \"value\": 19.0, \"mean\": 18.826086956521742}} (export_time=93.70us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:39,423] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1786 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:40,573] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 2 reward messages to agent: reward=6.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:44,440] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7593.1 vnc_pixels_ps[total]=44641.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:44,440] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"504.88us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.42ms\", \"mean\": \"697.74us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"17.91us\", \"mean\": \"37.98us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"495.37us\", \"mean\": \"297.84us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"169.43us\", \"mean\": \"5.18ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"93.06us\", \"mean\": \"215.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.15us\", \"mean\": \"94.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"28.78us\", \"mean\": \"79.79us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.94us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531558}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.3108440016582703, \"value\": 25.0, \"mean\": 23.559999999999995}} (export_time=124.93us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:44,440] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.87s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=328us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.70s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 74->75, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,140] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=75\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,141] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,141] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,154] init detected end of child process 30331 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,159] init detected end of child process 30346 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,161] init detected end of child process 30548 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,168] init detected end of child process 30553 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,181] init detected end of child process 30575 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:47 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:47 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:21:47 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,220] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,220] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:47 [info] 70#70: *400 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:47 [info] 70#70: *401 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:47 [info] 70#70: *402 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:21:47 [info] 70#70: *399 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:47,314] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,337] init detected end of child process 30334 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,337] init detected end of child process 30342 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,337] init detected end of child process 30343 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:21:47,337] init detected end of child process 30345 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:48,576] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:48,576] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:48,623] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,108] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,108] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,109] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,109] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,116] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,116] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:21:49 I0508 22:21:49.116275 30947 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:21:49 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::44814\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:21:49 I0508 22:21:49.117643 30947 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:49,234] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:53,301] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,019] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['328us', '187us', '173us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,019] [play_vexpect] Reaching start state: ready1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,020] [play_vexpect] vexpect macro complete in 6.869954s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:21:56 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::44814 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.031 KiB (1:10.3262 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.0925 MiB (1:2.76003 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,219] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 75->75, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,220] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,220] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=74->75, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,221] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.08s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,221] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=15.0 episode_count=13 episode_duration=31.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,222] [INFO:universe.wrappers.logger] Stats for the past 11.78s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1841.3 vnc_pixels_ps[total]=10740.2 reward_lag=None rewarder_message_lag=None fps=13.83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,231] [INFO:gym_controlplane.reward.reward] First score parsed: score=14. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:21:56,231] [INFO:universe.pyprofile] [pyprofile] period=11.79s timers={\"rewarder.sleep\": {\"calls\": 162, \"std\": \"205.94us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 15, \"std\": \"2.05ms\", \"mean\": \"771.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.98ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 45, \"std\": \"21.01us\", \"mean\": \"27.85us\"}, \"rewarder.compute_reward\": {\"calls\": 163, \"std\": \"766.29us\", \"mean\": \"302.11us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.29us\", \"mean\": \"53.29us\"}, \"reward.parsing.gameover\": {\"calls\": 15, \"std\": \"139.33us\", \"mean\": \"214.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 163, \"std\": \"43.45us\", \"mean\": \"94.79us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 15, \"std\": \"23.70us\", \"mean\": \"65.42us\"}, \"rewarder.frame\": {\"calls\": 163, \"std\": \"1.18ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 163, \"std\": 2.2043418352441595, \"mean\": 0.25766871165644173}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 39, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 14, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 15, \"std\": 3.872983346207417, \"value\": 10, \"mean\": 24.0}} (export_time=173.33us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:00,556] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.34s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2079 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:01,238] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18095.3 vnc_pixels_ps[total]=96591.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:01,238] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.12ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.89ms\", \"mean\": \"996.92us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"38.26us\", \"mean\": \"67.15us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"912.79us\", \"mean\": \"445.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.08ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"138.94us\", \"mean\": \"373.50us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"55.93us\", \"mean\": \"136.24us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.07us\", \"mean\": \"116.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.95us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 3.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.0134958870382642, \"value\": 17.0, \"mean\": 14.375000000000002}} (export_time=146.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:02,289] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:06,254] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6720.5 vnc_pixels_ps[total]=43979.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:06,255] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"944.78us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.00ms\", \"mean\": \"1.02ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.15us\", \"mean\": \"58.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"932.50us\", \"mean\": \"427.03us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"93.78us\", \"mean\": \"330.42us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.75us\", \"mean\": \"124.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.68us\", \"mean\": \"115.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.72us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.8846517369293831, \"value\": 19.0, \"mean\": 18.499999999999996}} (export_time=237.70us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:06,256] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.97s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1898 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:07,305] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.05s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:09,455] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.15s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:11,271] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8420.7 vnc_pixels_ps[total]=44997.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:11,272] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.35ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.09ms\", \"mean\": \"1.79ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"21.46us\", \"mean\": \"56.75us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.34ms\", \"mean\": \"496.40us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.91ms\", \"mean\": \"12.03ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"105.79us\", \"mean\": \"318.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"61.94us\", \"mean\": \"123.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"35.52us\", \"mean\": \"113.83us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.21us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4951202678663067, \"value\": 23.0, \"mean\": 20.653846153846153}} (export_time=206.95us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:11,273] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.82s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:16,288] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.7 vnc_pixels_ps[total]=44182.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:16,288] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"275.20us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"107.89us\", \"mean\": \"383.69us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.86us\", \"mean\": \"58.08us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"241.93us\", \"mean\": \"356.25us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"102.33us\", \"mean\": \"328.37us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.35us\", \"mean\": \"117.96us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"30.13us\", \"mean\": \"109.36us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.72us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 23.0, \"mean\": 23.0}} (export_time=167.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:16,289] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:17,471] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.18s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:21,305] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6828.4 vnc_pixels_ps[total]=44851.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:21,306] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"950.54us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.04ms\", \"mean\": \"1.04ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.40us\", \"mean\": \"64.10us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"942.18us\", \"mean\": \"431.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"102.45us\", \"mean\": \"362.54us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.32us\", \"mean\": \"125.15us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.67us\", \"mean\": \"120.35us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.35us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.46430562148753574, \"value\": 24.0, \"mean\": 23.708333333333336}} (export_time=224.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:21,306] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.83s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:24,886] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.58s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:26,321] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7559.3 vnc_pixels_ps[total]=44419.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:26,321] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.31ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.02ms\", \"mean\": \"1.58ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"25.67us\", \"mean\": \"62.53us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.28ms\", \"mean\": \"482.19us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"58.16us\", \"mean\": \"14.35ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"123.32us\", \"mean\": \"351.71us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.86us\", \"mean\": \"126.13us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"36.52us\", \"mean\": \"117.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.14us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.7637626158259737, \"value\": 26.0, \"mean\": 24.4}} (export_time=102.52us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:26,322] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.44s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:31,338] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5943.5 vnc_pixels_ps[total]=44097.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:31,339] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"245.02us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"98.11us\", \"mean\": \"364.70us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.58us\", \"mean\": \"53.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"239.34us\", \"mean\": \"360.38us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"102.44us\", \"mean\": \"305.66us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.19us\", \"mean\": \"119.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"30.15us\", \"mean\": \"107.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.50us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 26.0, \"mean\": 26.0}} (export_time=226.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:31,340] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:36,340] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"289.65us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"120.34us\", \"mean\": \"365.99us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"46.37us\", \"mean\": \"56.73us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"240.25us\", \"mean\": \"366.07us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"172.12us\", \"mean\": \"310.06us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"48.88us\", \"mean\": \"122.41us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.24us\", \"mean\": \"103.15us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"23.75us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2717464881947029, \"mean\": 0.08000000000000006}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 26.0, \"mean\": 26.0}} (export_time=295.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:36,340] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:36,357] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6130.8 vnc_pixels_ps[total]=45465.1 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:38,505] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.16s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:41,104] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:41,354] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"696.47us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.83ms\", \"mean\": \"929.84us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"28.49us\", \"mean\": \"56.69us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"646.26us\", \"mean\": \"416.03us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"73.00us\", \"mean\": \"6.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"146.11us\", \"mean\": \"320.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"70.69us\", \"mean\": \"124.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"44.93us\", \"mean\": \"112.19us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"60.56us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531565}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5773502691896252, \"value\": 28.0, \"mean\": 26.599999999999998}} (export_time=198.36us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:41,372] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7633.8 vnc_pixels_ps[total]=44952.1 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:43,271] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:46,354] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"790.05us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.41ms\", \"mean\": \"1.03ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"20.64us\", \"mean\": \"49.28us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"786.71us\", \"mean\": \"420.90us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.48ms\", \"mean\": \"8.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"104.51us\", \"mean\": \"278.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"51.97us\", \"mean\": \"120.22us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"31.19us\", \"mean\": \"100.49us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"26.41us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.08333333333333333}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.1354156504062614, \"value\": 34.0, \"mean\": 32.32000000000001}} (export_time=186.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:46,355] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.08s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:46,388] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7599.5 vnc_pixels_ps[total]=44730.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:22:48 [info] 70#70: *404 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:22:48 [info] 70#70: *405 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:22:48 [info] 70#70: *406 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:51,371] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"281.11us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"109.56us\", \"mean\": \"395.58us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.40us\", \"mean\": \"59.39us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"265.20us\", \"mean\": \"385.69us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"110.45us\", \"mean\": \"333.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.46us\", \"mean\": \"128.72us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.91us\", \"mean\": \"115.75us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.09us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 34.0, \"mean\": 34.0}} (export_time=282.05us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:51,372] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:51,404] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.3 vnc_pixels_ps[total]=44187.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:56,289] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.92s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:56,387] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"696.49us\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.09ms\", \"mean\": \"825.59us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.84us\", \"mean\": \"60.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"681.68us\", \"mean\": \"425.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.18ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"108.08us\", \"mean\": \"342.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"73.80us\", \"mean\": \"133.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"25.70us\", \"mean\": \"113.12us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.56us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 34.0, \"mean\": 34.0}} (export_time=152.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:22:56,422] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.4 vnc_pixels_ps[total]=44291.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:01,388] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"245.70us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"97.82us\", \"mean\": \"372.63us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"18.26us\", \"mean\": \"53.30us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"232.39us\", \"mean\": \"367.20us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"89.41us\", \"mean\": \"301.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.58us\", \"mean\": \"125.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.49us\", \"mean\": \"107.29us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"21.76us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666672}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=229.84us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:01,389] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.10s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:01,438] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.6 vnc_pixels_ps[total]=44343.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:06,405] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"246.81us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"110.86us\", \"mean\": \"346.47us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"27.59us\", \"mean\": \"50.93us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"217.12us\", \"mean\": \"351.76us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"107.70us\", \"mean\": \"283.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.43us\", \"mean\": \"121.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.20us\", \"mean\": \"99.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.34us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=345.23us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:06,406] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:06,454] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.8 vnc_pixels_ps[total]=44337.8 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:11,421] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"314.39us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"204.75us\", \"mean\": \"432.65us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"45.32us\", \"mean\": \"63.20us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"283.93us\", \"mean\": \"398.40us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"222.08us\", \"mean\": \"353.68us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"74.69us\", \"mean\": \"135.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.27us\", \"mean\": \"112.72us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.23us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=112.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:11,421] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:11,471] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.5 vnc_pixels_ps[total]=45933.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:16,421] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"234.38us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"106.98us\", \"mean\": \"369.40us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.93us\", \"mean\": \"52.64us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"223.37us\", \"mean\": \"355.90us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"97.94us\", \"mean\": \"299.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"44.67us\", \"mean\": \"119.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"30.08us\", \"mean\": \"105.99us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"20.98us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666677}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=197.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:16,421] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:16,488] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5953.9 vnc_pixels_ps[total]=44177.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:21,438] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"228.27us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"96.24us\", \"mean\": \"336.13us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.81us\", \"mean\": \"47.15us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"209.21us\", \"mean\": \"355.46us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"89.04us\", \"mean\": \"268.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.55us\", \"mean\": \"122.22us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.26us\", \"mean\": \"98.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.57us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260707, \"mean\": 0.0797342192691031}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 35.0, \"mean\": 35.0}} (export_time=86.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:21,438] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:21,506] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5935.9 vnc_pixels_ps[total]=43998.4 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,039] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=632us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,039] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,039] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,039] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,040] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 75->76, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,040] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,041] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,041] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=76\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,042] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,043] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,073] init detected end of child process 30696 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,078] init detected end of child process 30711 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,079] init detected end of child process 30920 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,098] init detected end of child process 30945 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:22 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,136] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,136] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:22,227] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,401] init detected end of child process 30699 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,401] init detected end of child process 30707 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,401] init detected end of child process 30708 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:22,401] init detected end of child process 30710 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:23,488] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:23,488] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:23,524] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,002] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,002] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,002] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,002] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,011] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,011] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:23:24 I0508 22:23:24.011975 31478 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:23:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::45108\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:23:24 I0508 22:23:24.017114 31478 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:24,137] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:28,187] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:29,804] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['168us', '90us', '72us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:29,804] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:29,804] [play_vexpect] vexpect macro complete in 5.758933s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:23:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::45108 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 131.153 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3193 KiB (1:31.3954 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 331.026 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.863 KiB (1:9.66086 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08465 MiB (1:2.77999 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,009] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 76->76, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,009] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,010] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=75->76, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,010] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.57s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,010] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=25.0 episode_count=32 episode_duration=93.79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,011] [INFO:universe.wrappers.logger] Stats for the past 8.50s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=888.6 vnc_pixels_ps[total]=2550.5 reward_lag=None rewarder_message_lag=None fps=3.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,023] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:30,023] [INFO:universe.pyprofile] [pyprofile] period=8.59s timers={\"rewarder.sleep\": {\"calls\": 36, \"std\": \"476.73us\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 4, \"std\": \"5.20ms\", \"mean\": \"2.97ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.56ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 12, \"std\": \"21.87us\", \"mean\": \"37.59us\"}, \"rewarder.compute_reward\": {\"calls\": 37, \"std\": \"2.04ms\", \"mean\": \"788.34us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"32.01us\", \"mean\": \"70.49us\"}, \"reward.parsing.gameover\": {\"calls\": 4, \"std\": \"366.88us\", \"mean\": \"475.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 37, \"std\": \"170.57us\", \"mean\": \"144.91us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 4, \"std\": \"51.69us\", \"mean\": \"81.12us\"}, \"rewarder.frame\": {\"calls\": 37, \"std\": \"2.18ms\", \"mean\": \"16.43ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 37, \"std\": 4.5977863847333795, \"mean\": 0.8378378378378379}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 6, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 3, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 4, \"std\": 12.5, \"value\": 10, \"mean\": 28.75}} (export_time=160.69us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:23:33 [info] 70#70: *408 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:23:33 [info] 70#70: *409 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:23:33 [info] 70#70: *410 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:33,544] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.53s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2056 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:35,027] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22823.5 vnc_pixels_ps[total]=87791.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:35,027] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"880.36us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.15ms\", \"mean\": \"528.12us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.68us\", \"mean\": \"41.57us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"391.41us\", \"mean\": \"297.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.66ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"109.24us\", \"mean\": \"236.86us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.49us\", \"mean\": \"98.46us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.74us\", \"mean\": \"84.54us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"60.55us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.44232586846469146, \"value\": 11.0, \"mean\": 10.25}} (export_time=103.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:35,028] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.48s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1885 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:36,177] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:37,710] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:40,044] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9249.9 vnc_pixels_ps[total]=45243.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:40,044] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"710.88us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.06ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"10.98us\", \"mean\": \"28.27us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"707.38us\", \"mean\": \"312.02us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"553.62us\", \"mean\": \"5.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"31.52us\", \"mean\": \"156.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.70us\", \"mean\": \"88.29us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"10.97us\", \"mean\": \"60.28us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.33us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358054, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.5419556372089707, \"value\": 17.0, \"mean\": 13.666666666666664}} (export_time=92.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:40,044] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.33s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,060] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6798.0 vnc_pixels_ps[total]=44526.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,061] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"623.69us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.94ms\", \"mean\": \"700.48us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"23.57us\", \"mean\": \"42.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"616.72us\", \"mean\": \"311.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"114.10us\", \"mean\": \"236.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.10us\", \"mean\": \"97.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.47us\", \"mean\": \"80.45us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.82us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 2.0816659994661326, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.7523276445668026, \"value\": 22.0, \"mean\": 21.125000000000004}} (export_time=125.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,061] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 3 reward messages to agent: reward=5.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,827] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=261us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,827] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,827] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,828] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,828] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 76->77, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,828] [INFO:root] [Rewarder] Blocking until env finishes resetting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,828] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,828] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=77\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,829] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,829] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:45,843] init detected end of child process 31233 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:45,848] init detected end of child process 31248 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:45,851] init detected end of child process 31450 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:45,851] init detected end of child process 31455 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:45,870] init detected end of child process 31476 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:23:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,906] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,906] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:23:45 [info] 70#70: *407 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:45,994] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:46,181] init detected end of child process 31236 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:46,182] init detected end of child process 31244 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:46,182] init detected end of child process 31245 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:23:46,183] init detected end of child process 31247 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:47,265] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:47,265] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:50,958] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,449] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,449] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,449] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'start_timeout': 7, 'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,449] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,451] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,451] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:23:51 I0508 22:23:51.451556 31867 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:23:51 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::45294\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:23:51 I0508 22:23:51.453323 31867 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:51,585] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,619] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,652] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['162us', '71us', '63us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,652] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,652] [play_vexpect] vexpect macro complete in 4.167485s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:23:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::45294 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 16 rects, 933.888 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.67289 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 1.01378 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.69197 MiB (1:1.43672 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,859] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 77->77, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,860] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,860] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=76->77, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,861] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.80s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,861] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=12.0 episode_count=11 episode_duration=25.85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,862] [INFO:universe.wrappers.logger] Stats for the past 10.80s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=948.9 vnc_pixels_ps[total]=3859.8 reward_lag=None rewarder_message_lag=None fps=4.35\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,873] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:55,874] [INFO:universe.pyprofile] [pyprofile] period=10.81s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"321.83us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"4.09ms\", \"mean\": \"2.06ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"30.56us\", \"mean\": \"33.74us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"1.73ms\", \"mean\": \"589.05us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.98us\", \"mean\": \"38.39us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"153.90us\", \"mean\": \"309.47us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"38.79us\", \"mean\": \"112.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"153.88us\", \"mean\": \"139.40us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.16ms\", \"mean\": \"16.46ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 5.39014415614757, \"mean\": 0.8936170212765958}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 4.898979485566356, \"value\": 10, \"mean\": 20.0}} (export_time=160.93us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:23:57,394] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 5 reward messages to agent: reward=4.0 reward_min=-1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2070 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:00,879] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=12.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26631.9 vnc_pixels_ps[total]=105491.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:00,880] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.30ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.05ms\", \"mean\": \"1.33ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"24.32us\", \"mean\": \"45.87us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.03ms\", \"mean\": \"422.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.85ms\", \"mean\": \"8.94ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"117.76us\", \"mean\": \"256.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.55us\", \"mean\": \"109.53us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"33.97us\", \"mean\": \"101.49us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"84.79us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 0.9831920802501751, \"mean\": 0.8333333333333334}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609666, \"mean\": 0.08970099667774091}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.6233692233523598, \"value\": 15.0, \"mean\": 13.59259259259259}} (export_time=315.90us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:00,880] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.49s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:05,895] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5946.3 vnc_pixels_ps[total]=44117.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:05,896] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"327.87us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"138.93us\", \"mean\": \"378.38us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"30.36us\", \"mean\": \"53.98us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"258.85us\", \"mean\": \"352.52us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"159.74us\", \"mean\": \"309.63us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"41.93us\", \"mean\": \"113.93us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"57.05us\", \"mean\": \"115.44us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.16us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 15.0, \"mean\": 15.0}} (export_time=149.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:05,896] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:07,579] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.68s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:08,662] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:09,745] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:10,911] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10920.1 vnc_pixels_ps[total]=46062.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:10,912] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.52ms\", \"mean\": \"15.85ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"4.83ms\", \"mean\": \"2.76ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"32.53us\", \"mean\": \"70.07us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.76ms\", \"mean\": \"654.94us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"67.47us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"3.24ms\", \"mean\": \"11.20ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"152.55us\", \"mean\": \"388.56us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.27us\", \"mean\": \"133.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"42.29us\", \"mean\": \"123.44us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.32us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.414213562373095, \"mean\": 1.9999999999999998}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2955558608590778, \"mean\": 0.09634551495016608}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 5.459433919300775, \"value\": 29.0, \"mean\": 22.344827586206897}} (export_time=195.74us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:10,912] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.17s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2031 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:12,795] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.88s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:15,828] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:15,928] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7562.1 vnc_pixels_ps[total]=44402.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:15,929] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"990.82us\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.02ms\", \"mean\": \"1.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"29.03us\", \"mean\": \"65.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"979.93us\", \"mean\": \"476.99us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"5.99ms\", \"mean\": \"9.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"150.49us\", \"mean\": \"366.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.48us\", \"mean\": \"131.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"40.33us\", \"mean\": \"122.79us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.53us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531558}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.5000000000000007, \"value\": 32.0, \"mean\": 30.799999999999997}} (export_time=309.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:17,795] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1931 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:19,512] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:20,945] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7881.4 vnc_pixels_ps[total]=45126.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:20,945] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.34ms\", \"mean\": \"15.91ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.99ms\", \"mean\": \"1.82ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"26.70us\", \"mean\": \"65.43us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.32ms\", \"mean\": \"546.43us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.23ms\", \"mean\": \"11.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"124.91us\", \"mean\": \"365.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"60.16us\", \"mean\": \"139.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"35.17us\", \"mean\": \"123.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.92us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.4258226201879194, \"value\": 39.0, \"mean\": 35.730769230769226}} (export_time=154.97us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:20,946] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.43s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:25,962] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.9 vnc_pixels_ps[total]=44022.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:25,962] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"323.57us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"119.25us\", \"mean\": \"421.81us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.77us\", \"mean\": \"61.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"285.91us\", \"mean\": \"405.25us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"225.64us\", \"mean\": \"387.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.49us\", \"mean\": \"130.05us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"37.69us\", \"mean\": \"125.44us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"43.73us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289044}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 39.0, \"mean\": 39.0}} (export_time=219.58us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:25,963] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:27,545] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.58s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:30,979] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7619.3 vnc_pixels_ps[total]=44884.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:30,980] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"736.50us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.66ms\", \"mean\": \"1.46ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"24.63us\", \"mean\": \"59.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.18ms\", \"mean\": \"465.92us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"238.42us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"3.31ms\", \"mean\": \"12.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"122.74us\", \"mean\": \"334.91us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.40us\", \"mean\": \"120.57us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"46.64us\", \"mean\": \"126.15us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"31.29us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.388044187577136, \"value\": 42.0, \"mean\": 40.519999999999996}} (export_time=259.88us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:30,981] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.44s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2002 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:35,779] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.80s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:35,996] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6797.5 vnc_pixels_ps[total]=44613.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:35,998] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"348.14us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.19ms\", \"mean\": \"1.01ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"29.58us\", \"mean\": \"59.97us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"428.30us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"1.07ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.59ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"146.41us\", \"mean\": \"334.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"83.96us\", \"mean\": \"126.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"28.72us\", \"mean\": \"107.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"61.27us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.2000000000000001, \"value\": 43.0, \"mean\": 42.04}} (export_time=258.21us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:37,081] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=5.0 reward_min=0.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1999 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:39,680] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:41,013] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8657.5 vnc_pixels_ps[total]=46749.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:41,014] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.15ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.50ms\", \"mean\": \"1.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"21.25us\", \"mean\": \"55.94us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.48ms\", \"mean\": \"502.71us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"576.73us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.61ms\", \"mean\": \"13.41ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"100.41us\", \"mean\": \"314.23us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.39us\", \"mean\": \"121.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"33.15us\", \"mean\": \"108.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"33.80us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.7320508075688772, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.199650321860621, \"value\": 49.0, \"mean\": 47.03846153846155}} (export_time=161.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:41,014] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.33s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2019 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:42,264] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.25s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:44,213] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:46,031] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10076.7 vnc_pixels_ps[total]=45537.3 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:46,031] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.44ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.93ms\", \"mean\": \"2.67ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"20.34us\", \"mean\": \"61.34us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.72ms\", \"mean\": \"591.69us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"675.68us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.65ms\", \"mean\": \"12.10ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"94.92us\", \"mean\": \"343.71us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"63.09us\", \"mean\": \"126.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"31.58us\", \"mean\": \"117.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"38.99us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774092}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.8335275732378167, \"value\": 54.0, \"mean\": 50.851851851851855}} (export_time=172.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:46,032] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.82s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2017 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:24:47 [info] 70#70: *412 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:24:47 [info] 70#70: *413 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:24:47 [info] 70#70: *414 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:51,047] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.8 vnc_pixels_ps[total]=44021.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:51,048] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"264.83us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"108.27us\", \"mean\": \"361.24us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.55us\", \"mean\": \"51.73us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.24us\", \"mean\": \"349.80us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"103.51us\", \"mean\": \"293.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.55us\", \"mean\": \"118.66us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.50us\", \"mean\": \"102.13us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.78us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.7358681786057767, \"value\": 57.0, \"mean\": 56.78260869565218}} (export_time=167.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:51,049] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1771 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:52,881] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.83s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:56,064] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7599.3 vnc_pixels_ps[total]=44728.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:56,064] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"976.01us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.01ms\", \"mean\": \"1.18ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.94us\", \"mean\": \"49.20us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"958.74us\", \"mean\": \"374.55us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.39ms\", \"mean\": \"10.34ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"121.40us\", \"mean\": \"279.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.86us\", \"mean\": \"101.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"43.88us\", \"mean\": \"102.99us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.32us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.912870929175273, \"value\": 59.0, \"mean\": 58.00000000000001}} (export_time=132.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:24:56,064] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.18s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:01,081] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.2 vnc_pixels_ps[total]=44017.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:01,082] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"270.18us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"97.48us\", \"mean\": \"384.00us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.45us\", \"mean\": \"58.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"264.23us\", \"mean\": \"358.95us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"107.69us\", \"mean\": \"334.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.22us\", \"mean\": \"118.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"26.99us\", \"mean\": \"111.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.36us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=292.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:01,083] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1720 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:06,098] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.8 vnc_pixels_ps[total]=44345.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:06,099] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"335.18us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"71.16us\", \"mean\": \"429.52us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"21.60us\", \"mean\": \"67.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"285.74us\", \"mean\": \"394.19us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"106.04us\", \"mean\": \"379.62us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.45us\", \"mean\": \"130.10us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.54us\", \"mean\": \"121.66us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.72us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=291.11us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:06,100] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:11,114] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6188.0 vnc_pixels_ps[total]=45906.4 reward_lag=None rewarder_message_lag=None fps=60.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:11,114] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"320.73us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"94.27us\", \"mean\": \"379.13us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.19us\", \"mean\": \"54.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"234.05us\", \"mean\": \"360.21us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"87.89us\", \"mean\": \"304.33us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.87us\", \"mean\": \"123.53us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.92us\", \"mean\": \"109.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.64us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=107.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:11,114] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:16,131] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:16,132] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"190.27us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"63.65us\", \"mean\": \"269.61us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"12.51us\", \"mean\": \"36.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"178.68us\", \"mean\": \"282.79us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"62.17us\", \"mean\": \"212.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.69us\", \"mean\": \"100.39us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.77us\", \"mean\": \"80.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.10us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289037}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=177.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:16,132] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:21,147] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.6 vnc_pixels_ps[total]=44343.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:21,148] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"273.48us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"91.63us\", \"mean\": \"371.23us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.73us\", \"mean\": \"56.45us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"231.43us\", \"mean\": \"369.54us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"113.70us\", \"mean\": \"317.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.73us\", \"mean\": \"121.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"25.30us\", \"mean\": \"108.91us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.97us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=188.83us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:21,148] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:26,164] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5964.9 vnc_pixels_ps[total]=44261.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:26,164] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"284.08us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"119.09us\", \"mean\": \"400.82us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"26.40us\", \"mean\": \"59.67us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"249.81us\", \"mean\": \"376.59us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"139.47us\", \"mean\": \"336.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.11us\", \"mean\": \"121.10us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.42us\", \"mean\": \"116.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.93us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 59.0, \"mean\": 59.0}} (export_time=91.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:26,164] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,630] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=306us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,631] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,631] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.47s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,631] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,631] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,631] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 77->78, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,632] [INFO:root] [Rewarder] Blocking until env finishes resetting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,632] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,632] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=78\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,632] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,633] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:30,651] init detected end of child process 31598 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:30,656] init detected end of child process 31613 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:30,658] init detected end of child process 31822 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:30,671] init detected end of child process 31843 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:25:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:25:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:25:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,715] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,716] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:30,807] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:31,065] init detected end of child process 31601 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:31,065] init detected end of child process 31609 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:31,065] init detected end of child process 31610 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:25:31,065] init detected end of child process 31612 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,098] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.29s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,098] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,137] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,664] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,664] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,664] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,665] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,666] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,666] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:25:32 I0508 22:25:32.667038 32387 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:25:32 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::45672\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:25:32 I0508 22:25:32.677247 32387 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:32,787] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:36,821] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,688] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['181us', '86us', '58us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,688] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,688] [play_vexpect] vexpect macro complete in 6.987480s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:25:39 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::45672 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.21 KiB (1:10.3206 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09267 MiB (1:2.76049 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,961] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 78->78, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,961] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,962] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=77->78, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,962] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.33s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,963] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=49.0 episode_count=49 episode_duration=104.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,964] [INFO:universe.wrappers.logger] Stats for the past 13.80s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2344.4 vnc_pixels_ps[total]=14906.0 reward_lag=None rewarder_message_lag=None fps=19.49\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,974] [INFO:gym_controlplane.reward.reward] First score parsed: score=14. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:39,974] [INFO:universe.pyprofile] [pyprofile] period=13.81s timers={\"rewarder.sleep\": {\"calls\": 268, \"std\": \"278.86us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.93ms\", \"mean\": \"790.60us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.46ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"32.82us\", \"mean\": \"53.74us\"}, \"rewarder.compute_reward\": {\"calls\": 269, \"std\": \"726.55us\", \"mean\": \"386.16us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.96us\", \"mean\": \"51.86us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"153.96us\", \"mean\": \"332.50us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 269, \"std\": \"43.38us\", \"mean\": \"111.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"78.46us\", \"mean\": \"112.21us\"}, \"rewarder.frame\": {\"calls\": 269, \"std\": \"888.29us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 269, \"std\": 1.8446655193617472, \"mean\": 0.19330855018587367}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 10.217206288796664, \"value\": 10, \"mean\": 56.869565217391305}} (export_time=155.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:43,080] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.12s, sent 5 reward messages to agent: reward=8.0 reward_min=-2.0 reward_max=4 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2101 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:44,979] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=18939.5 vnc_pixels_ps[total]=97115.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:44,980] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"897.19us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.66ms\", \"mean\": \"738.22us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"20.78us\", \"mean\": \"36.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"551.95us\", \"mean\": \"288.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"656.48us\", \"mean\": \"5.95ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"111.64us\", \"mean\": \"209.30us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"31.05us\", \"mean\": \"85.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"25.73us\", \"mean\": \"80.45us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.62us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 2.1908902300206643, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.375984496036687, \"value\": 18.0, \"mean\": 16.32}} (export_time=109.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:44,980] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.90s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:47,230] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.25s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:48,763] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:49,996] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8461.7 vnc_pixels_ps[total]=45313.5 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:49,997] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"745.94us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.24ms\", \"mean\": \"1.06ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"17.43us\", \"mean\": \"37.47us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"742.98us\", \"mean\": \"346.15us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.29ms\", \"mean\": \"6.79ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"88.01us\", \"mean\": \"213.73us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"30.28us\", \"mean\": \"89.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.74us\", \"mean\": \"82.13us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.51us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662219, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 0.81523946458411, \"value\": 20.0, \"mean\": 18.769230769230766}} (export_time=136.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:50,004] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.24s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1937 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *419 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *420 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *421 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *422 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *423 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *424 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *425 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *426 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *427 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:25:50 [info] 70#70: *428 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:52,463] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.46s, sent 3 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:53,546] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:55,013] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10044.9 vnc_pixels_ps[total]=45167.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:55,013] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.68ms\", \"mean\": \"15.82ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.87ms\", \"mean\": \"2.02ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.52ms\", \"mean\": \"9.34ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"19.45us\", \"mean\": \"41.39us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.39ms\", \"mean\": \"488.85us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"2.93ms\", \"mean\": \"2.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"66.02us\", \"mean\": \"232.50us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"424.53us\", \"mean\": \"138.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"18.84us\", \"mean\": \"81.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"681.39us\", \"mean\": \"16.93ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 0.752772652709081, \"mean\": 1.1666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774085}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.9414506867883061, \"value\": 27.0, \"mean\": 24.33333333333333}} (export_time=131.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:55,014] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.47s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2339 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:25:57,946] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.93s, sent 2 reward messages to agent: reward=4.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:00,030] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6767.2 vnc_pixels_ps[total]=44380.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:00,030] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"970.60us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.86ms\", \"mean\": \"686.35us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"13.08us\", \"mean\": \"42.76us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"602.57us\", \"mean\": \"323.99us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"47.12us\", \"mean\": \"240.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"124.72us\", \"mean\": \"96.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.96us\", \"mean\": \"95.73us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"747.13us\", \"mean\": \"16.89ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.1293194051465605, \"value\": 31.0, \"mean\": 29.666666666666664}} (export_time=144.48us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:00,031] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.08s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1916 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:01,230] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:02,830] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.60s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,046] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8951.0 vnc_pixels_ps[total]=42954.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,047] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.61ms\", \"mean\": \"15.89ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.30ms\", \"mean\": \"2.08ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"8.71us\", \"mean\": \"41.39us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.41ms\", \"mean\": \"449.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.13ms\", \"mean\": \"11.10ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"23.44us\", \"mean\": \"234.96us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"155.43us\", \"mean\": \"105.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"11.36us\", \"mean\": \"86.27us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"597.34us\", \"mean\": \"16.91ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613574, \"mean\": 0.08305647840531567}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.783882181415011, \"value\": 38.0, \"mean\": 34.8}} (export_time=165.22us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,047] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.22s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,746] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=278us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,746] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 78->79, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,747] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=79\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,748] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,748] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:05,765] init detected end of child process 32138 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:05,780] init detected end of child process 32153 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:05,782] init detected end of child process 32355 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:05,785] init detected end of child process 32362 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:05,810] init detected end of child process 32385 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,880] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:05,881] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:05 [info] 70#70: *416 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:05 [info] 70#70: *417 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:05 [info] 70#70: *418 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:05 [info] 70#70: *415 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:06,033] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:06,121] init detected end of child process 32149 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:06,121] init detected end of child process 32141 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:06,121] init detected end of child process 32150 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:06,121] init detected end of child process 32152 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:07,435] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.40s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:07,436] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,136] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,976] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,976] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,976] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,977] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,997] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:13,997] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:26:14 I0508 22:26:14.005088 305 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:26:14 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::46142\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:26:14 I0508 22:26:14.013054 305 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:14,182] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:15,799] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['215us', '118us', '103us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:15,799] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:15,799] [play_vexpect] vexpect macro complete in 1.756780s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:26:15 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::46142 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 14.173 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.92969 KiB (1:28.7085 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 18 rects, 999.424 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.86049 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 32 rects, 1.08196 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.87993 MiB (1:1.43327 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,011] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 79->79, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,016] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,016] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=78->79, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,017] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.97s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,017] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=28.0 episode_count=24 episode_duration=36.05\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,019] [INFO:universe.wrappers.logger] Stats for the past 10.97s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=813.1 vnc_pixels_ps[total]=2880.8 reward_lag=None rewarder_message_lag=None fps=3.92\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,040] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:16,041] [INFO:universe.pyprofile] [pyprofile] period=10.99s timers={\"rewarder.sleep\": {\"calls\": 42, \"std\": \"651.49us\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"9.12ms\", \"mean\": \"4.35ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"20.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"15.39us\", \"mean\": \"29.06us\"}, \"rewarder.compute_reward\": {\"calls\": 43, \"std\": \"3.44ms\", \"mean\": \"837.64us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"34.27us\", \"mean\": \"60.32us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"145.79us\", \"mean\": \"329.78us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 43, \"std\": \"219.69us\", \"mean\": \"114.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"34.46us\", \"mean\": \"68.04us\"}, \"rewarder.frame\": {\"calls\": 43, \"std\": \"2.41ms\", \"mean\": \"16.57ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 43, \"std\": 4.569870997110592, \"mean\": 0.7906976744186046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 12.521980673998822, \"value\": 10, \"mean\": 32.4}} (export_time=215.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:17,093] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.profile': '<2085 bytes>', 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:18,826] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:20,359] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:21,026] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19900.7 vnc_pixels_ps[total]=90626.9 reward_lag=None rewarder_message_lag=None fps=59.93\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:21,042] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.97ms\", \"mean\": \"15.69ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.87ms\", \"mean\": \"2.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.55us\", \"mean\": \"43.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.71ms\", \"mean\": \"559.80us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.59ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.65ms\", \"mean\": \"11.75ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"52.57us\", \"mean\": \"243.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"565.00us\", \"mean\": \"161.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"25.30us\", \"mean\": \"90.41us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"17.03ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.6478424121816424, \"value\": 15.0, \"mean\": 12.346153846153848}} (export_time=173.09us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:21,876] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2018 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:25,192] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.32s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:26,042] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7553.2 vnc_pixels_ps[total]=44332.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:26,043] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.06ms\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.37ms\", \"mean\": \"974.40us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"10.35us\", \"mean\": \"39.67us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"780.47us\", \"mean\": \"360.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.64ms\", \"mean\": \"8.15ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"41.05us\", \"mean\": \"225.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"275.70us\", \"mean\": \"115.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"16.22us\", \"mean\": \"86.95us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"676.01us\", \"mean\": \"16.88ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470293, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.4440030912488508, \"value\": 20.0, \"mean\": 18.45833333333333}} (export_time=124.22us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:27,576] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:31,059] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6196.3 vnc_pixels_ps[total]=43971.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:31,060] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"579.87us\", \"mean\": \"16.24ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.91ms\", \"mean\": \"656.82us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"9.57us\", \"mean\": \"34.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"575.78us\", \"mean\": \"283.09us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.14ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"40.69us\", \"mean\": \"198.70us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"26.54us\", \"mean\": \"83.00us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"9.94us\", \"mean\": \"76.01us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.96us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.4869847535576732, \"value\": 21.0, \"mean\": 20.65217391304348}} (export_time=150.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:31,060] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.48s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:36,076] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.7 vnc_pixels_ps[total]=45935.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:36,077] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"195.96us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"63.96us\", \"mean\": \"266.41us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.02us\", \"mean\": \"35.51us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"165.96us\", \"mean\": \"277.11us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"71.23us\", \"mean\": \"201.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"31.00us\", \"mean\": \"92.86us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.79us\", \"mean\": \"82.23us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"45.44us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260707, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 21.0, \"mean\": 21.0}} (export_time=867.37us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:36,078] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:37,578] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.50s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:39,944] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.37s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:41,078] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10065.1 vnc_pixels_ps[total]=45447.3 reward_lag=None rewarder_message_lag=None fps=59.99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:41,078] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"988.83us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"4.19ms\", \"mean\": \"1.93ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"15.95us\", \"mean\": \"39.29us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.43ms\", \"mean\": \"431.85us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.34ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"5.46ms\", \"mean\": \"9.18ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"73.53us\", \"mean\": \"222.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"35.42us\", \"mean\": \"91.94us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"21.66us\", \"mean\": \"79.14us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"214.84us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.6431676725154984, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.29138503682901845, \"mean\": 0.09333333333333335}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.631464074351605, \"value\": 30.0, \"mean\": 26.964285714285722}} (export_time=110.15us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:41,078] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.13s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2013 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:42,161] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=6.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,795] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=249us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,795] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.63s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 79->80, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,796] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,797] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,797] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,797] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:45,820] init detected end of child process 32505 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:45,824] init detected end of child process 32520 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:45,827] init detected end of child process 32722 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:45,831] init detected end of child process 32727 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:45,847] init detected end of child process 32749 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:26:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,918] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:45,918] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:45 [info] 70#70: *430 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:45 [info] 70#70: *431 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:45 [info] 70#70: *432 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:26:45 [info] 70#70: *429 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:46,059] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:46,168] init detected end of child process 32508 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:46,169] init detected end of child process 32516 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:46,169] init detected end of child process 32517 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:26:46,169] init detected end of child process 32519 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:48,412] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 2.35s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:48,413] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:53,486] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,302] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,302] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,302] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,303] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,333] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,333] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:26:54 I0508 22:26:54.333379 681 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:26:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::46644\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:26:54 I0508 22:26:54.349054 681 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:54,538] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:58,605] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,456] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['297us', '181us', '156us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,457] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,457] [play_vexpect] vexpect macro complete in 5.090377s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:26:59 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::46644 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 6 rects, 3.068 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            192 B (1:64.2917 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 19 rects, 892.288 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.55391 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 32 rects, 963.295 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.57156 MiB (1:1.42911 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,687] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 80->80, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,688] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,688] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=79->80, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,691] [INFO:universe.rewarder.remote] [Rewarder] Over past 13.89s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,691] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=27.0 episode_count=22 episode_duration=43.67\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,693] [INFO:universe.wrappers.logger] Stats for the past 18.61s: vnc_updates_ps=1.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2187.7 vnc_pixels_ps[total]=11227.6 reward_lag=None rewarder_message_lag=None fps=15.26\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,723] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:26:59,724] [INFO:universe.pyprofile] [pyprofile] period=18.65s timers={\"rewarder.sleep\": {\"calls\": 283, \"std\": \"634.91us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"5.92ms\", \"mean\": \"1.91ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"13.11ms\", \"mean\": \"13.74ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"20.66us\", \"mean\": \"30.83us\"}, \"rewarder.compute_reward\": {\"calls\": 284, \"std\": \"1.97ms\", \"mean\": \"422.53us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"27.47us\", \"mean\": \"49.99us\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"122.22us\", \"mean\": \"206.33us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 284, \"std\": \"143.20us\", \"mean\": \"95.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.73us\", \"mean\": \"75.15us\"}, \"rewarder.frame\": {\"calls\": 284, \"std\": \"865.99us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 5, \"std\": 1.51657508881031, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 284, \"std\": 2.62073702973183, \"mean\": 0.23943661971830987}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 5.575840743780259, \"value\": 10, \"mean\": 34.56}} (export_time=295.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:00,931] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.24s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<2160 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:03,917] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.99s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:04,700] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=13.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=27655.4 vnc_pixels_ps[total]=111802.1 reward_lag=None rewarder_message_lag=None fps=59.72\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:04,734] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 297, \"std\": \"1.06ms\", \"mean\": \"15.75ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"5.77ms\", \"mean\": \"2.44ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.62us\", \"mean\": \"67.52us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.87ms\", \"mean\": \"595.11us\"}, \"rewarder.sleep.missed\": {\"calls\": 4, \"std\": \"9.19ms\", \"mean\": \"7.00ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"578.53us\", \"mean\": \"17.70ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"57.93us\", \"mean\": \"373.74us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"217.29us\", \"mean\": \"142.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"18.22us\", \"mean\": \"115.93us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"1.55ms\", \"mean\": \"17.18ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117918, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4120361729949245, \"value\": 15.0, \"mean\": 12.076923076923078}} (export_time=223.88us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:05,157] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.24s, sent 2 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2035 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:08,173] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.02s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:09,473] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:09,706] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10090.1 vnc_pixels_ps[total]=45626.7 reward_lag=None rewarder_message_lag=None fps=59.94\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:09,739] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.54ms\", \"mean\": \"15.76ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"5.06ms\", \"mean\": \"2.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"17.75us\", \"mean\": \"45.19us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.78ms\", \"mean\": \"568.67us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.23ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"5.71ms\", \"mean\": \"11.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"75.54us\", \"mean\": \"252.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"464.38us\", \"mean\": \"143.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"22.16us\", \"mean\": \"95.14us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"999.40us\", \"mean\": \"17.01ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.1690451944500122, \"mean\": 1.8333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.29138503682901834, \"mean\": 0.09333333333333335}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 3.2159901418680654, \"value\": 26.0, \"mean\": 18.750000000000004}} (export_time=143.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:13,590] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.12s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2034 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:14,717] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8423.0 vnc_pixels_ps[total]=44892.3 reward_lag=None rewarder_message_lag=None fps=59.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:14,753] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.14ms\", \"mean\": \"15.99ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"5.86ms\", \"mean\": \"2.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"11.00us\", \"mean\": \"40.06us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.82ms\", \"mean\": \"467.71us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.61ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"8.98ms\", \"mean\": \"15.77ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"33.10us\", \"mean\": \"225.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"288.46us\", \"mean\": \"116.22us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"14.95us\", \"mean\": \"86.28us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"853.86us\", \"mean\": \"16.94ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.08333333333333333}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.0049875621120885, \"value\": 29.0, \"mean\": 26.52}} (export_time=170.47us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:14,753] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.16s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1991 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:19,734] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5957.7 vnc_pixels_ps[total]=44127.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:19,767] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"304.27us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 22, \"std\": \"38.34us\", \"mean\": \"220.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 66, \"std\": \"8.31us\", \"mean\": \"28.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"120.62us\", \"mean\": \"228.77us\"}, \"reward.parsing.gameover\": {\"calls\": 22, \"std\": \"38.48us\", \"mean\": \"164.21us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"32.04us\", \"mean\": \"80.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 22, \"std\": \"20.45us\", \"mean\": \"70.60us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"165.95us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.260717130098715, \"mean\": 0.07308970099667775}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 22, \"std\": 0.4264014327112206, \"value\": 31.0, \"mean\": 30.90909090909091}} (export_time=143.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:19,767] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1785 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=277us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 80->81, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,484] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=81\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,485] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,485] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,504] init detected end of child process 410 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,514] init detected end of child process 425 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,519] init detected end of child process 627 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,522] init detected end of child process 632 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,539] init detected end of child process 654 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:20 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,596] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,596] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:20,704] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:20 [info] 70#70: *434 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:20 [info] 70#70: *435 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:20 [info] 70#70: *436 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:20 [info] 70#70: *433 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,921] init detected end of child process 424 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,933] init detected end of child process 413 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,933] init detected end of child process 421 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:20,933] init detected end of child process 422 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:21,979] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:21,980] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,052] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,705] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,705] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,705] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'subsample_level': 2, 'start_timeout': 7, 'encoding': 'zrle', 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,705] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,715] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,715] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:27:26 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::47078\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:27:26 I0508 22:27:26.715311 1086 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:27:26 I0508 22:27:26.716986 1086 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:26,852] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,003] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['149us', '68us', '62us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,003] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,003] [play_vexpect] vexpect macro complete in 2.254480s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:27:29 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::47078 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 18 rects, 897.024 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.56744 MiB (1:1.33287 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 30 rects, 965.471 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.58506 MiB (1:1.42485 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,245] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 81->81, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,245] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,245] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=80->81, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,246] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.48s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,246] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=21.0 episode_count=17 episode_duration=29.56\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,247] [INFO:universe.wrappers.logger] Stats for the past 9.51s: vnc_updates_ps=0.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1062.9 vnc_pixels_ps[total]=4247.5 reward_lag=None rewarder_message_lag=None fps=4.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,263] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:29,264] [INFO:universe.pyprofile] [pyprofile] period=9.50s timers={\"rewarder.sleep\": {\"calls\": 43, \"std\": \"176.86us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 6, \"std\": \"6.14ms\", \"mean\": \"2.72ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"15.05ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 18, \"std\": \"8.91us\", \"mean\": \"21.21us\"}, \"rewarder.compute_reward\": {\"calls\": 44, \"std\": \"2.52ms\", \"mean\": \"623.82us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.81us\", \"mean\": \"45.46us\"}, \"reward.parsing.gameover\": {\"calls\": 6, \"std\": \"134.55us\", \"mean\": \"227.69us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 44, \"std\": \"28.00us\", \"mean\": \"78.62us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 6, \"std\": \"19.94us\", \"mean\": \"52.61us\"}, \"rewarder.frame\": {\"calls\": 44, \"std\": \"2.30ms\", \"mean\": \"16.40ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 44, \"std\": 3.6148478163996596, \"mean\": 0.6590909090909091}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 12, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 5, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 6, \"std\": 8.573214099741124, \"value\": 10, \"mean\": 27.5}} (export_time=161.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:30,382] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.14s, sent 3 reward messages to agent: reward=6.0 reward_min=0 reward_max=3 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2073 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:31,919] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.54s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:34,252] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20027.7 vnc_pixels_ps[total]=87548.7 reward_lag=None rewarder_message_lag=None fps=59.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:34,268] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.40ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"5.03ms\", \"mean\": \"2.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"22.19us\", \"mean\": \"44.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.75ms\", \"mean\": \"530.11us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"620.40us\", \"mean\": \"2.65ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"5.22ms\", \"mean\": \"11.71ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"121.90us\", \"mean\": \"250.95us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"391.24us\", \"mean\": \"129.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"29.38us\", \"mean\": \"82.02us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"260.86us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.7511900715418263, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006218, \"mean\": 0.09302325581395349}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 4.503966505838413, \"value\": 24.0, \"mean\": 17.714285714285715}} (export_time=144.24us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:34,268] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.35s, sent 2 reward messages to agent: reward=5.0 reward_min=0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2050 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:36,674] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.41s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:39,258] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6811.8 vnc_pixels_ps[total]=44707.8 reward_lag=None rewarder_message_lag=None fps=59.94\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:39,277] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"848.64us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"4.36ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"9.77us\", \"mean\": \"36.87us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.35ms\", \"mean\": \"361.49us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.22ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"21.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"32.14us\", \"mean\": \"211.42us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"334.79us\", \"mean\": \"106.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"9.74us\", \"mean\": \"84.16us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"824.15us\", \"mean\": \"16.92ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423704, \"mean\": 0.08333333333333331}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5099019513592774, \"value\": 25.0, \"mean\": 24.48}} (export_time=138.52us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:39,278] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1987 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:41,874] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:44,274] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7013.6 vnc_pixels_ps[total]=46205.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:44,291] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.02ms\", \"mean\": \"901.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"11.62us\", \"mean\": \"37.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"995.62us\", \"mean\": \"354.07us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.71ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"53.47us\", \"mean\": \"214.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"430.95us\", \"mean\": \"116.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"22.64us\", \"mean\": \"88.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"301.99us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.035909510816207, \"value\": 29.0, \"mean\": 26.833333333333332}} (export_time=164.03us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:44,291] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.42s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,007] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=286us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,008] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,008] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,008] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,008] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 81->82, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,008] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,009] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,009] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,009] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,009] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,023] init detected end of child process 784 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,029] init detected end of child process 799 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,032] init detected end of child process 1026 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,032] init detected end of child process 1032 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,052] init detected end of child process 1053 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:27:45 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,105] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,106] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:45 [info] 70#70: *438 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:45 [info] 70#70: *439 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:45 [info] 70#70: *440 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:27:45 [info] 70#70: *437 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:45,207] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,361] init detected end of child process 787 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,361] init detected end of child process 795 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,361] init detected end of child process 796 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:27:45,361] init detected end of child process 798 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:46,458] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.25s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:46,459] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:46,555] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,188] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,188] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,188] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'compress_level': 0, 'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,188] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,196] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,196] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:27:47 I0508 22:27:47.197134 1424 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:27:47 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::47348\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:27:47 I0508 22:27:47.216799 1424 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:47,337] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:51,371] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:54,888] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['226us', '130us', '118us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:54,888] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:54,889] [play_vexpect] vexpect macro complete in 7.655219s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:27:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::47348 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.219 KiB (1:10.32 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.2723 MiB (1:2.37075 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,113] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 82->82, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,114] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,119] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=81->82, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,119] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.83s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,119] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=19.0 episode_count=12 episode_duration=25.87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,120] [INFO:universe.wrappers.logger] Stats for the past 10.85s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=820.9 vnc_pixels_ps[total]=2922.0 reward_lag=None rewarder_message_lag=None fps=4.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,146] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:27:55,146] [INFO:universe.pyprofile] [pyprofile] period=10.86s timers={\"rewarder.sleep\": {\"calls\": 43, \"std\": \"182.99us\", \"mean\": \"16.28ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"10.87ms\", \"mean\": \"5.10ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"24.29ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"10.50us\", \"mean\": \"21.01us\"}, \"rewarder.compute_reward\": {\"calls\": 44, \"std\": \"3.99ms\", \"mean\": \"840.99us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"25.43us\", \"mean\": \"57.74us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"171.62us\", \"mean\": \"277.76us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 44, \"std\": \"15.46us\", \"mean\": \"71.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"31.94us\", \"mean\": \"58.89us\"}, \"rewarder.frame\": {\"calls\": 44, \"std\": \"2.26ms\", \"mean\": \"16.41ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 44, \"std\": 4.367560119259818, \"mean\": 0.75}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 8.497058314499201, \"value\": 10, \"mean\": 25.2}} (export_time=220.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:00,131] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17296.9 vnc_pixels_ps[total]=96228.4 reward_lag=None rewarder_message_lag=None fps=59.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:00,147] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"126.25us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"41.72us\", \"mean\": \"218.07us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"11.15us\", \"mean\": \"30.33us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"123.63us\", \"mean\": \"228.50us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.60ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"55.33us\", \"mean\": \"174.43us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"27.82us\", \"mean\": \"80.59us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"15.00us\", \"mean\": \"68.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"664.74us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 12.0, \"mean\": 12.0}} (export_time=106.10us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:00,148] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 2 reward messages to agent: reward=2 reward_min=0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1816 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:03,064] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.92s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:04,798] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:05,148] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9266.9 vnc_pixels_ps[total]=45414.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:05,148] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"946.21us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.66ms\", \"mean\": \"1.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"15.25us\", \"mean\": \"34.97us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"918.46us\", \"mean\": \"352.11us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.35ms\", \"mean\": \"7.16ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"71.56us\", \"mean\": \"198.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"35.34us\", \"mean\": \"80.58us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"434.80us\", \"mean\": \"150.79us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"240.95us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.28665992577177274, \"mean\": 0.09}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.5806882989936697, \"value\": 17.0, \"mean\": 13.962962962962962}} (export_time=153.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:06,383] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.58s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1912 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,966] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=371us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,966] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,966] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.58s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,966] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,966] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,967] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 82->83, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,967] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,967] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,967] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=83\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,967] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:09,968] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:09,993] init detected end of child process 1168 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:09,997] init detected end of child process 1183 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,009] init detected end of child process 1385 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,020] init detected end of child process 1390 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,045] init detected end of child process 1415 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:10 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:10 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:10 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:10,146] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:10,147] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:10 [info] 70#70: *442 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:10 [info] 70#70: *443 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:10 [info] 70#70: *444 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:10 [info] 70#70: *441 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:10,299] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,348] init detected end of child process 1171 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,349] init detected end of child process 1179 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,349] init detected end of child process 1180 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:10,349] init detected end of child process 1182 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:11,769] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.47s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:11,773] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:11,888] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,757] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,757] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,758] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,760] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,801] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,801] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:28:12 I0508 22:28:12.801538 1806 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:28:12 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::47696\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:28:12 I0508 22:28:12.805335 1806 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:12,993] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:17,014] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,015] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['217us', '126us', '119us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,015] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,016] [play_vexpect] vexpect macro complete in 7.179854s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:28:20 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::47696 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 17 rects, 397.074 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.432 KiB (1:10.3121 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 790.879 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27251 MiB (1:2.37113 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,204] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 83->83, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,204] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,204] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=82->83, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,206] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.24s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,206] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=11.0 episode_count=11 episode_duration=25.09\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,207] [INFO:universe.wrappers.logger] Stats for the past 15.06s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2931.1 vnc_pixels_ps[total]=13564.4 reward_lag=None rewarder_message_lag=None fps=19.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,224] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:20,225] [INFO:universe.pyprofile] [pyprofile] period=15.08s timers={\"rewarder.sleep\": {\"calls\": 288, \"std\": \"1.31ms\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"5.31ms\", \"mean\": \"2.48ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.41ms\", \"mean\": \"14.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"20.07us\", \"mean\": \"40.74us\"}, \"rewarder.compute_reward\": {\"calls\": 290, \"std\": \"1.90ms\", \"mean\": \"524.66us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"1.27ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"22.39us\", \"mean\": \"61.43us\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"103.67us\", \"mean\": \"260.66us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 290, \"std\": \"533.23us\", \"mean\": \"129.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.28us\", \"mean\": \"80.85us\"}, \"rewarder.frame\": {\"calls\": 290, \"std\": \"1.04ms\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 0.8}, \"reward.vnc.updates.n\": {\"calls\": 290, \"std\": 1.836939502723557, \"mean\": 0.19310344827586207}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.3693556410649195, \"value\": 10, \"mean\": 19.576923076923073}} (export_time=221.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:21,477] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.27s, sent 3 reward messages to agent: reward=4.0 reward_min=1 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2262 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:25,210] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25592.4 vnc_pixels_ps[total]=94358.2 reward_lag=None rewarder_message_lag=None fps=59.98\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:25,227] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"871.92us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.60ms\", \"mean\": \"1.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"11.35us\", \"mean\": \"36.95us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"852.19us\", \"mean\": \"345.52us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"4.88ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.42ms\", \"mean\": \"7.74ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"50.73us\", \"mean\": \"210.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"164.47us\", \"mean\": \"90.30us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"17.26us\", \"mean\": \"75.58us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"324.93us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.380476142847617, \"mean\": 2.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 3.6161674002549535, \"value\": 20.0, \"mean\": 16.919999999999998}} (export_time=161.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:25,227] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.75s, sent 2 reward messages to agent: reward=6.0 reward_min=0 reward_max=6.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2019 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:26,460] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.23s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:28,517] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.06s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:30,227] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10056.5 vnc_pixels_ps[total]=45474.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:30,227] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.15ms\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.29ms\", \"mean\": \"1.73ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"11.09us\", \"mean\": \"36.74us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.15ms\", \"mean\": \"392.86us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.54ms\", \"mean\": \"8.19ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"44.89us\", \"mean\": \"207.52us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"24.37us\", \"mean\": \"80.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"13.62us\", \"mean\": \"73.02us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"22.24us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 0.9831920802501749, \"mean\": 1.1666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.29138503682901834, \"mean\": 0.09333333333333338}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.6084924389832547, \"value\": 27.0, \"mean\": 23.285714285714285}} (export_time=108.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:30,228] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.71s, sent 3 reward messages to agent: reward=2.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1930 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,044] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=461us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,044] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,044] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.82s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 83->84, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,045] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,046] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,046] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,084] init detected end of child process 1547 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,088] init detected end of child process 1562 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,091] init detected end of child process 1770 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,103] init detected end of child process 1765 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,119] init detected end of child process 1792 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:28:32 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,172] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,172] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:32,291] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:32 [info] 70#70: *446 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:32 [info] 70#70: *447 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:32 [info] 70#70: *448 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:28:32 [info] 70#70: *445 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,841] init detected end of child process 1550 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,841] init detected end of child process 1558 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,841] init detected end of child process 1559 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:32,841] init detected end of child process 1561 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:33,604] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.31s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:33,605] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:33,713] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,417] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,418] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,418] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2, 'compress_level': 0, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,418] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,429] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,429] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:28:34 I0508 22:28:34.430009 2183 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:28:34 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::48116\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:28:34 I0508 22:28:34.445096 2183 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:34,587] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:38,621] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:41,971] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['221us', '129us', '105us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:41,975] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:41,976] [play_vexpect] vexpect macro complete in 7.512510s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:28:42 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::48116 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.217 KiB (1:10.3201 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.2723 MiB (1:2.37075 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,265] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 84->84, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,266] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,267] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=83->84, env_state=running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,268] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.22s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,268] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=17.0 episode_count=12 episode_duration=22.06\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,269] [INFO:universe.wrappers.logger] Stats for the past 12.04s: vnc_updates_ps=0.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1263.7 vnc_pixels_ps[total]=6518.5 reward_lag=None rewarder_message_lag=None fps=9.14\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,295] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:42,295] [INFO:universe.pyprofile] [pyprofile] period=12.07s timers={\"rewarder.sleep\": {\"calls\": 109, \"std\": \"197.84us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"7.84ms\", \"mean\": \"2.74ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"24.82ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"12.96us\", \"mean\": \"32.16us\"}, \"rewarder.compute_reward\": {\"calls\": 110, \"std\": \"2.56ms\", \"mean\": \"497.83us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.52us\", \"mean\": \"61.71us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"171.04us\", \"mean\": \"267.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 110, \"std\": \"24.20us\", \"mean\": \"81.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"25.71us\", \"mean\": \"69.79us\"}, \"rewarder.frame\": {\"calls\": 110, \"std\": \"1.38ms\", \"mean\": \"16.62ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 110, \"std\": 2.960682021374987, \"mean\": 0.36363636363636365}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 5.375872022286245, \"value\": 10, \"mean\": 25.3}} (export_time=181.91us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:47,280] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17938.1 vnc_pixels_ps[total]=95177.2 reward_lag=None rewarder_message_lag=None fps=59.88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:47,297] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"496.12us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.59ms\", \"mean\": \"536.21us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"10.66us\", \"mean\": \"27.65us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"491.51us\", \"mean\": \"251.96us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.74ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.71ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"52.24us\", \"mean\": \"158.76us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.88us\", \"mean\": \"85.77us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"16.00us\", \"mean\": \"63.95us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"674.63us\", \"mean\": \"16.81ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.3269776053940747, \"value\": 14.0, \"mean\": 13.249999999999998}} (export_time=271.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:47,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1998 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:52,296] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6756.3 vnc_pixels_ps[total]=44296.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:52,297] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"856.63us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.79ms\", \"mean\": \"866.28us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"24.59us\", \"mean\": \"43.12us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"850.86us\", \"mean\": \"313.61us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.55ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"112.86us\", \"mean\": \"239.10us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"42.75us\", \"mean\": \"93.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.72us\", \"mean\": \"85.94us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"33.32us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.8846517369293828, \"value\": 16.0, \"mean\": 15.500000000000002}} (export_time=133.99us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:52,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:54,713] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.42s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:56,230] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:57,313] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10840.9 vnc_pixels_ps[total]=45234.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:57,314] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"896.49us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.45ms\", \"mean\": \"1.48ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"13.54us\", \"mean\": \"33.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"897.12us\", \"mean\": \"376.92us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"427.77us\", \"mean\": \"5.94ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"62.38us\", \"mean\": \"189.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.99us\", \"mean\": \"97.17us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"22.93us\", \"mean\": \"68.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.66us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.3662601021279464, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2955558608590778, \"mean\": 0.09634551495016612}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 2.8039381172767053, \"value\": 24.0, \"mean\": 18.827586206896555}} (export_time=109.20us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:57,314] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,963] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=206us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,963] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,963] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.65s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 84->85, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=85\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,964] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:28:59,965] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:59,983] init detected end of child process 1927 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:59,988] init detected end of child process 1942 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:59,989] init detected end of child process 2144 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:28:59,990] init detected end of child process 2149 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:00,006] init detected end of child process 2171 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:00 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:00 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:00 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:00,045] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:00,045] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:00 [info] 70#70: *450 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:00 [info] 70#70: *451 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:00 [info] 70#70: *452 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:00 [info] 70#70: *449 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:00,138] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:00,309] init detected end of child process 1930 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:00,309] init detected end of child process 1938 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:00,309] init detected end of child process 1939 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:00,309] init detected end of child process 1941 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,402] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,403] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,474] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,970] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,970] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,970] [play_vexpect] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 0, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,970] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,977] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:01,977] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:01 I0508 22:29:01.977828 2555 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:01 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::48284\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:01 I0508 22:29:01.97919 2555 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:02,103] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:06,153] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,037] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['192us', '166us', '80us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,037] [play_vexpect] Reaching start state: ready1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,037] [play_vexpect] vexpect macro complete in 7.026167s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:09 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::48284 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 396.562 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.01 KiB (1:10.3276 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 27 rects, 790.367 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09247 MiB (1:2.76008 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,275] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 85->85, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,276] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,276] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=84->85, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,276] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.31s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,277] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=16.0 episode_count=12 episode_duration=27.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,278] [INFO:universe.wrappers.logger] Stats for the past 11.96s: vnc_updates_ps=1.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1817.0 vnc_pixels_ps[total]=10606.0 reward_lag=None rewarder_message_lag=None fps=13.37\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,288] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:09,288] [INFO:universe.pyprofile] [pyprofile] period=11.97s timers={\"rewarder.sleep\": {\"calls\": 159, \"std\": \"190.16us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.60ms\", \"mean\": \"928.30us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.81ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"13.41us\", \"mean\": \"24.01us\"}, \"rewarder.compute_reward\": {\"calls\": 160, \"std\": \"883.14us\", \"mean\": \"298.77us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"16.09us\", \"mean\": \"33.82us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"78.34us\", \"mean\": \"176.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 160, \"std\": \"39.76us\", \"mean\": \"88.93us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"18.45us\", \"mean\": \"57.70us\"}, \"rewarder.frame\": {\"calls\": 160, \"std\": \"1.20ms\", \"mean\": \"16.68ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 160, \"std\": 2.381062272845843, \"mean\": 0.26875000000000004}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 4.27617987059879, \"value\": 10, \"mean\": 24.857142857142858}} (export_time=129.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:10,294] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 2 reward messages to agent: reward=4.0 reward_min=2 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2128 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:11,610] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:13,778] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.17s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:14,294] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21397.9 vnc_pixels_ps[total]=97615.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:14,295] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.38ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"4.44ms\", \"mean\": \"2.14ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"18.74us\", \"mean\": \"37.62us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.52ms\", \"mean\": \"469.64us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"419.86us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"4.17ms\", \"mean\": \"10.42ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"91.88us\", \"mean\": \"213.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.69us\", \"mean\": \"105.31us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"21.20us\", \"mean\": \"78.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"35.54us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 0.5477225575051661, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006217, \"mean\": 0.09302325581395351}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 2.1491969707422416, \"value\": 19.0, \"mean\": 15.214285714285714}} (export_time=236.51us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:15,728] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2013 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:17,227] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.50s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:19,311] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8381.3 vnc_pixels_ps[total]=44655.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:19,312] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.48ms\", \"mean\": \"1.51ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"21.95us\", \"mean\": \"48.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"436.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.13ms\", \"mean\": \"10.25ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"112.26us\", \"mean\": \"274.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.19us\", \"mean\": \"111.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"29.19us\", \"mean\": \"92.81us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.31us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.2703724469013606, \"value\": 22.0, \"mean\": 20.57692307692308}} (export_time=197.65us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:19,312] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.08s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:24,327] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.7 vnc_pixels_ps[total]=44344.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:24,328] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"275.71us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"91.40us\", \"mean\": \"383.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.23us\", \"mean\": \"56.19us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"232.29us\", \"mean\": \"355.93us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"96.90us\", \"mean\": \"315.16us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.45us\", \"mean\": \"119.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"23.25us\", \"mean\": \"111.37us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.04us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 22.0, \"mean\": 22.0}} (export_time=161.41us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:24,328] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,028] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=547us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,028] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,028] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,029] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,029] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 85->86, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,030] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,030] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,030] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=86\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,031] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,032] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,057] init detected end of child process 2298 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,064] init detected end of child process 2313 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,069] init detected end of child process 2515 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,071] init detected end of child process 2521 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,087] init detected end of child process 2546 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:25 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,127] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,127] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:25 [info] 70#70: *454 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:25 [info] 70#70: *455 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:25 [info] 70#70: *456 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:25 [info] 70#70: *453 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:25,221] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,421] init detected end of child process 2301 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,421] init detected end of child process 2309 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,421] init detected end of child process 2310 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:25,422] init detected end of child process 2312 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:26,454] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:26,455] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:29,824] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,356] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,356] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,357] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,357] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,359] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,359] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:30 I0508 22:29:30.359748 2935 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:30 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::48470\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:30 I0508 22:29:30.361462 2935 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:30,492] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,525] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,793] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['306us', '157us', '135us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,793] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,794] [play_vexpect] vexpect macro complete in 4.400506s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:34 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::48470 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.916 KiB (1:15.7374 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 31 rects, 1.02707 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.93988 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 46 rects, 1.12335 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.96196 MiB (1:1.44694 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,956] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 86->86, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,956] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,956] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=85->86, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,957] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.63s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,957] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=12.0 episode_count=13 episode_duration=25.68\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,958] [INFO:universe.wrappers.logger] Stats for the past 10.63s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=959.2 vnc_pixels_ps[total]=3884.3 reward_lag=None rewarder_message_lag=None fps=4.05\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,971] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:34,971] [INFO:universe.pyprofile] [pyprofile] period=10.64s timers={\"rewarder.sleep\": {\"calls\": 42, \"std\": \"300.70us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"5.30ms\", \"mean\": \"2.66ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.92ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"16.32us\", \"mean\": \"31.20us\"}, \"rewarder.compute_reward\": {\"calls\": 43, \"std\": \"2.04ms\", \"mean\": \"690.64us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"25.80us\", \"mean\": \"64.85us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"295.34us\", \"mean\": \"366.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 43, \"std\": \"53.42us\", \"mean\": \"127.50us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"39.60us\", \"mean\": \"65.33us\"}, \"rewarder.frame\": {\"calls\": 43, \"std\": \"2.06ms\", \"mean\": \"16.46ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 43, \"std\": 5.026507806708054, \"mean\": 0.8604651162790697}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 5.366563145999495, \"value\": 10, \"mean\": 19.6}} (export_time=163.32us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:37,491] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2084 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:39,024] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:39,974] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19453.0 vnc_pixels_ps[total]=100697.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:39,974] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.56ms\", \"mean\": \"705.44us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"15.41us\", \"mean\": \"34.28us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"514.61us\", \"mean\": \"296.99us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"852.72us\", \"mean\": \"5.53ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"77.56us\", \"mean\": \"195.61us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.79us\", \"mean\": \"95.40us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"28.44us\", \"mean\": \"78.93us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.52us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896257, \"mean\": 1.6666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.080123449734644, \"value\": 15.0, \"mean\": 12.799999999999999}} (export_time=125.65us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,807] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=240us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,807] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.78s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 6211, 'rewarder.profile': '<1938 bytes>', 'rewarder.vnc.updates.pixels': 11691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 86->87, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,808] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,809] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,809] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,809] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:43,824] init detected end of child process 2667 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:43,829] init detected end of child process 2682 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:43,831] init detected end of child process 2890 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:43,831] init detected end of child process 2964 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:43,846] init detected end of child process 2911 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:29:43 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,885] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,886] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:43,969] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:43 [info] 70#70: *458 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:43 [info] 70#70: *459 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:43 [info] 70#70: *460 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:29:43 [info] 70#70: *457 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:44,209] init detected end of child process 2670 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:44,209] init detected end of child process 2678 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:44,209] init detected end of child process 2679 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:29:44,209] init detected end of child process 2681 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:45,203] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:45,203] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:45,574] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,088] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,088] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,088] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,088] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,097] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,097] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:46 I0508 22:29:46.098171 3286 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:46 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::48572\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:29:46 I0508 22:29:46.101033 3286 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:46,233] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:50,283] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:50,917] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['165us', '97us', '87us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:50,917] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:50,918] [play_vexpect] vexpect macro complete in 4.784611s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:29:51 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::48572 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 13 rects, 330.146 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.24 KiB (1:9.68015 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.26358 MiB (1:2.38279 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,197] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 87->87, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,197] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,197] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=86->87, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,198] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.39s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,198] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=5.0 episode_count=5 episode_duration=16.24\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,199] [INFO:universe.wrappers.logger] Stats for the past 11.22s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2524.4 vnc_pixels_ps[total]=15608.7 reward_lag=None rewarder_message_lag=None fps=20.58\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,211] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:51,211] [INFO:universe.pyprofile] [pyprofile] period=11.24s timers={\"rewarder.sleep\": {\"calls\": 230, \"std\": \"126.35us\", \"mean\": \"16.30ms\"}, \"reward.parsing.score\": {\"calls\": 19, \"std\": \"2.56ms\", \"mean\": \"800.56us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 57, \"std\": \"8.35us\", \"mean\": \"23.94us\"}, \"rewarder.compute_reward\": {\"calls\": 231, \"std\": \"835.75us\", \"mean\": \"280.06us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"15.65us\", \"mean\": \"35.56us\"}, \"reward.parsing.gameover\": {\"calls\": 19, \"std\": \"67.48us\", \"mean\": \"164.35us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 231, \"std\": \"42.18us\", \"mean\": \"90.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 19, \"std\": \"19.25us\", \"mean\": \"60.58us\"}, \"rewarder.frame\": {\"calls\": 231, \"std\": \"980.66us\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 231, \"std\": 1.20936492566681, \"mean\": 0.1558441558441559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 51, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 18, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 19, \"std\": 1.1470786693528088, \"value\": 10, \"mean\": 14.736842105263158}} (export_time=102.52us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:53,082] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.88s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2093 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:56,216] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=14482.3 vnc_pixels_ps[total]=76768.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:56,217] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.09ms\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.42ms\", \"mean\": \"791.77us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.63us\", \"mean\": \"45.09us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"762.80us\", \"mean\": \"378.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"11.65ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"103.66us\", \"mean\": \"252.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.13us\", \"mean\": \"120.19us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.82us\", \"mean\": \"90.43us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.78us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5036101551853343, \"value\": 11.0, \"mean\": 10.583333333333336}} (export_time=259.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:56,217] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.14s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:58,032] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.81s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:29:59,566] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:01,232] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8401.3 vnc_pixels_ps[total]=44844.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:01,233] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.03ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.99ms\", \"mean\": \"1.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"25.99us\", \"mean\": \"61.50us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"512.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.91ms\", \"mean\": \"8.58ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"121.94us\", \"mean\": \"341.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"66.31us\", \"mean\": \"141.31us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"34.71us\", \"mean\": \"118.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.56us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.0615528128088303, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.0863787375415282}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.6821816275764485, \"value\": 20.0, \"mean\": 14.961538461538462}} (export_time=293.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:01,234] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1915 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:02,382] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.15s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:06,249] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6777.1 vnc_pixels_ps[total]=44456.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:06,249] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"897.94us\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.79ms\", \"mean\": \"1.01ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.46us\", \"mean\": \"60.45us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"880.19us\", \"mean\": \"461.22us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.54ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"85.58us\", \"mean\": \"340.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.87us\", \"mean\": \"139.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.19us\", \"mean\": \"124.76us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.78us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.271332383726071, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.46430562148753574, \"value\": 21.0, \"mean\": 20.708333333333336}} (export_time=155.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:06,250] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.87s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:08,432] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 2 reward messages to agent: reward=7.0 reward_min=3.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:09,515] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:11,265] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8679.5 vnc_pixels_ps[total]=46915.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:11,265] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"15.96ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.65ms\", \"mean\": \"1.66ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"19.53us\", \"mean\": \"59.89us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"502.66us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.58ms\", \"mean\": \"11.21ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"91.79us\", \"mean\": \"337.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.44us\", \"mean\": \"124.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"29.47us\", \"mean\": \"113.15us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.45us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.707825127659933, \"mean\": 2.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.1173624617533195, \"value\": 30.0, \"mean\": 26.555555555555557}} (export_time=115.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:11,266] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,898] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=284us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,898] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.63s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 87->88, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,899] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,900] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=88\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,900] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,900] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:15,912] init detected end of child process 3029 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:15,924] init detected end of child process 3044 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:15,925] init detected end of child process 3246 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:15,926] init detected end of child process 3252 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:15,937] init detected end of child process 3274 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:30:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:30:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:30:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,980] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:15,980] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:16 [info] 70#70: *462 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:16 [info] 70#70: *463 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:16 [info] 70#70: *464 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:16 [info] 70#70: *461 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:16,070] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:16,249] init detected end of child process 3032 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:16,249] init detected end of child process 3040 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:16,249] init detected end of child process 3041 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:30:16,249] init detected end of child process 3043 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:17,337] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:17,337] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,214] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,690] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,690] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,690] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,690] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,696] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,696] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:30:21 I0508 22:30:21.697118 3666 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:30:21 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::48774\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:30:21 I0508 22:30:21.701068 3666 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:21,831] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,648] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['189us', '70us', '58us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,649] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,649] [play_vexpect] vexpect macro complete in 3.918136s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:30:25 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::48774 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 13.585 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.85352 KiB (1:28.6491 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 22 rects, 909.312 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.60269 MiB (1:1.33285 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 36 rects, 991.263 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.62207 MiB (1:1.44229 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,887] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 88->88, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,888] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,888] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=87->88, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,889] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.99s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,889] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=20.0 episode_count=14 episode_duration=34.69\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,890] [INFO:universe.wrappers.logger] Stats for the past 14.62s: vnc_updates_ps=1.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2201.6 vnc_pixels_ps[total]=13959.1 reward_lag=None rewarder_message_lag=None fps=19.08\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,897] [INFO:gym_controlplane.reward.reward] First score parsed: score=22. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:25,897] [INFO:universe.pyprofile] [pyprofile] period=14.63s timers={\"rewarder.sleep\": {\"calls\": 278, \"std\": \"223.80us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.31ms\", \"mean\": \"578.85us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.87us\", \"mean\": \"39.00us\"}, \"rewarder.compute_reward\": {\"calls\": 279, \"std\": \"514.87us\", \"mean\": \"306.20us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.73us\", \"mean\": \"46.57us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"106.93us\", \"mean\": \"247.96us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 279, \"std\": \"43.09us\", \"mean\": \"96.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.26us\", \"mean\": \"88.56us\"}, \"rewarder.frame\": {\"calls\": 279, \"std\": \"890.80us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 279, \"std\": 2.524212959764643, \"mean\": 0.22939068100358423}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 4.170288281141495, \"value\": 10, \"mean\": 29.130434782608695}} (export_time=135.18us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:28,956] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.07s, sent 2 reward messages to agent: reward=14.0 reward_min=2.0 reward_max=12 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:30,906] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=13.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=28736.7 vnc_pixels_ps[total]=106643.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:30,906] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.21ms\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.20ms\", \"mean\": \"1.50ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"17.98us\", \"mean\": \"38.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.10ms\", \"mean\": \"410.92us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"2.54ms\", \"mean\": \"8.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"90.48us\", \"mean\": \"216.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.38us\", \"mean\": \"106.36us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"23.67us\", \"mean\": \"80.19us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.67us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 5.354126134736337, \"mean\": 4.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.09302325581395351}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 1.749905515211983, \"value\": 26.0, \"mean\": 23.392857142857142}} (export_time=115.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:30,907] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.95s, sent 3 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1922 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:33,939] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:35,672] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:35,912] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"653.19us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.30ms\", \"mean\": \"1.10ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"14.30us\", \"mean\": \"35.90us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"738.67us\", \"mean\": \"325.44us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.08ms\", \"mean\": \"6.66ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"66.92us\", \"mean\": \"201.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"44.28us\", \"mean\": \"93.30us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.92us\", \"mean\": \"75.28us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"27.14us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.7320508075688772, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.08}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.1293194051465592, \"value\": 32.0, \"mean\": 30.333333333333336}} (export_time=98.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:35,922] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8724.6 vnc_pixels_ps[total]=47068.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:36,972] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 3 reward messages to agent: reward=4.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1907 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:40,439] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.47s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:40,922] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"674.68us\", \"mean\": \"16.19ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.68ms\", \"mean\": \"726.58us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"12.70us\", \"mean\": \"32.26us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"549.66us\", \"mean\": \"293.59us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"773.65us\", \"mean\": \"5.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"56.23us\", \"mean\": \"182.70us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.81us\", \"mean\": \"89.13us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"18.31us\", \"mean\": \"72.68us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.38us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2583057392117916, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961355, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.5416441439796238, \"value\": 37.0, \"mean\": 35.28}} (export_time=126.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:40,939] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6931.2 vnc_pixels_ps[total]=43827.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:45,923] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"188.95us\", \"mean\": \"16.22ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"75.73us\", \"mean\": \"265.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.25us\", \"mean\": \"37.35us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"178.49us\", \"mean\": \"272.33us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"104.88us\", \"mean\": \"216.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"45.80us\", \"mean\": \"98.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.60us\", \"mean\": \"77.57us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"24.91us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666667}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 37.0, \"mean\": 37.0}} (export_time=288.25us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:45,923] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.48s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:45,955] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5974.8 vnc_pixels_ps[total]=44337.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:46,956] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:48,473] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *468 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *469 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *470 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *471 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *472 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *473 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *474 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *475 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *476 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:30:50 [info] 70#70: *477 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:50,939] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"827.05us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.40ms\", \"mean\": \"1.21ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.55ms\", \"mean\": \"6.42ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.85us\", \"mean\": \"33.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"819.08us\", \"mean\": \"350.17us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"438.07us\", \"mean\": \"1.40ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"61.71us\", \"mean\": \"187.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.08us\", \"mean\": \"89.63us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"19.19us\", \"mean\": \"71.47us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"36.53us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.6}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774087}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.170824980053465, \"value\": 45.0, \"mean\": 41.85185185185185}} (export_time=124.69us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:50,939] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.47s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2344 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:50,973] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9242.4 vnc_pixels_ps[total]=45267.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:53,889] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.95s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:55,939] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"749.05us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.32ms\", \"mean\": \"926.57us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"14.52us\", \"mean\": \"37.49us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"746.37us\", \"mean\": \"321.27us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"2.34ms\", \"mean\": \"8.11ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"67.54us\", \"mean\": \"213.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.24us\", \"mean\": \"93.76us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"24.36us\", \"mean\": \"78.32us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"23.10us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 0.5773502691896258, \"mean\": 0.6666666666666666}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423705, \"mean\": 0.08333333333333334}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.7461009761866417, \"value\": 47.0, \"mean\": 46.160000000000004}} (export_time=140.43us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:55,939] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.05s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:55,989] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7076.2 vnc_pixels_ps[total]=44905.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:30:57,356] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.42s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:00,939] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"513.84us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.59ms\", \"mean\": \"632.84us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.27us\", \"mean\": \"43.13us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"512.05us\", \"mean\": \"317.65us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.73ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"85.83us\", \"mean\": \"244.71us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"46.81us\", \"mean\": \"101.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.11us\", \"mean\": \"88.86us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"26.91us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.271746488194703, \"mean\": 0.07999999999999997}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.48154341234307513, \"value\": 48.0, \"mean\": 47.66666666666667}} (export_time=186.92us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:00,939] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.58s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1903 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:01,006] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.4 vnc_pixels_ps[total]=44290.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:05,606] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.67s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:05,939] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"867.41us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.81ms\", \"mean\": \"860.34us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"15.20us\", \"mean\": \"39.17us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"857.47us\", \"mean\": \"342.36us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.68ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"74.95us\", \"mean\": \"221.22us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.82us\", \"mean\": \"102.81us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"24.00us\", \"mean\": \"84.77us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"31.76us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2717464881947029, \"mean\": 0.08}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.40824829046386274, \"value\": 50.0, \"mean\": 48.083333333333336}} (export_time=187.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:06,023] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6767.0 vnc_pixels_ps[total]=44378.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:10,939] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"190.21us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"76.56us\", \"mean\": \"278.54us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.85us\", \"mean\": \"36.97us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"176.09us\", \"mean\": \"282.56us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"73.98us\", \"mean\": \"208.55us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"42.34us\", \"mean\": \"103.77us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.45us\", \"mean\": \"84.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"27.29us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666672}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 50.0, \"mean\": 50.0}} (export_time=436.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:10,940] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.33s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:11,039] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5946.1 vnc_pixels_ps[total]=44115.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:15,411] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.47s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:15,955] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"543.10us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.55ms\", \"mean\": \"721.30us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.19us\", \"mean\": \"39.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"519.84us\", \"mean\": \"291.81us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"104.02us\", \"mean\": \"5.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"133.29us\", \"mean\": \"228.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.48us\", \"mean\": \"84.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"26.50us\", \"mean\": \"78.80us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.27us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 4.725815626252609, \"mean\": 3.6666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.08305647840531566}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.5537749241945377, \"value\": 52.0, \"mean\": 50.160000000000004}} (export_time=154.50us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:16,056] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7855.9 vnc_pixels_ps[total]=46634.4 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:31:17 [info] 70#70: *466 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:31:17 [info] 70#70: *467 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:20,972] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"196.23us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"71.21us\", \"mean\": \"285.88us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"13.73us\", \"mean\": \"39.14us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"186.30us\", \"mean\": \"291.67us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"67.33us\", \"mean\": \"221.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.86us\", \"mean\": \"100.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"18.62us\", \"mean\": \"83.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.30us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 61.0, \"mean\": 61.0}} (export_time=153.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:20,973] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.56s, sent 3 reward messages to agent: reward=9.0 reward_min=0 reward_max=9.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:21,072] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.2 vnc_pixels_ps[total]=44186.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:25,972] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"230.74us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"102.94us\", \"mean\": \"333.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"22.01us\", \"mean\": \"49.45us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"214.57us\", \"mean\": \"307.33us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"117.45us\", \"mean\": \"282.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"47.64us\", \"mean\": \"104.21us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"27.39us\", \"mean\": \"97.33us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"27.89us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666674}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 61.0, \"mean\": 61.0}} (export_time=237.94us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:25,973] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:26,089] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.0 vnc_pixels_ps[total]=44177.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:30,989] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"250.31us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"102.15us\", \"mean\": \"368.59us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"19.87us\", \"mean\": \"53.29us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"236.56us\", \"mean\": \"327.96us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"101.36us\", \"mean\": \"301.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.36us\", \"mean\": \"110.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.83us\", \"mean\": \"105.69us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.35us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 61.0, \"mean\": 61.0}} (export_time=100.85us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:30,989] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1725 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:31,106] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.3 vnc_pixels_ps[total]=44180.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:36,005] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"214.87us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"84.82us\", \"mean\": \"326.91us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.51us\", \"mean\": \"47.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"204.59us\", \"mean\": \"318.06us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"83.37us\", \"mean\": \"267.58us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.93us\", \"mean\": \"107.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"22.77us\", \"mean\": \"94.07us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.98us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 61.0, \"mean\": 61.0}} (export_time=112.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:36,006] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1717 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:36,123] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5954.1 vnc_pixels_ps[total]=44178.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,673] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=611us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,674] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,674] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,674] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,675] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,675] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 88->89, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,675] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,676] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,676] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=89\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,677] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,678] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:38,695] init detected end of child process 3396 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:38,701] init detected end of child process 3411 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:38,702] init detected end of child process 3620 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:38,719] init detected end of child process 3642 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:31:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:31:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:31:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,761] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,762] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:38,851] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:39,033] init detected end of child process 3399 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:39,033] init detected end of child process 3407 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:39,033] init detected end of child process 3408 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:31:39,034] init detected end of child process 3410 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:40,124] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:40,124] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:43,584] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,083] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,083] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,084] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'fine_quality_level': 50, 'start_timeout': 7, 'encoding': 'zrle', 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,084] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,093] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,093] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:31:44 I0508 22:31:44.093452 4209 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:31:44 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::49080\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:31:44 I0508 22:31:44.094884 4209 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:44,228] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:48,245] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,579] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['375us', '196us', '170us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,579] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,580] [play_vexpect] vexpect macro complete in 5.453219s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:31:49 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::49080 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 9\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3721 KiB (1:15.3392 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 36 rects, 1.09619 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.13779 MiB (1:1.3328 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 50 rects, 1.18428 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.15836 MiB (1:1.43056 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,782] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 89->89, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,783] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,783] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=88->89, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,784] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.11s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,784] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=51.0 episode_count=35 episode_duration=83.90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,785] [INFO:universe.wrappers.logger] Stats for the past 13.66s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1516.9 vnc_pixels_ps[total]=8726.0 reward_lag=None rewarder_message_lag=None fps=11.27\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,793] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:49,794] [INFO:universe.pyprofile] [pyprofile] period=13.79s timers={\"rewarder.sleep\": {\"calls\": 160, \"std\": \"288.70us\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.04ms\", \"mean\": \"927.19us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"7.82ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"26.40us\", \"mean\": \"50.85us\"}, \"rewarder.compute_reward\": {\"calls\": 161, \"std\": \"784.89us\", \"mean\": \"410.25us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"30.55us\", \"mean\": \"67.31us\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"217.17us\", \"mean\": \"362.65us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 161, \"std\": \"50.45us\", \"mean\": \"111.87us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"46.39us\", \"mean\": \"104.61us\"}, \"rewarder.frame\": {\"calls\": 161, \"std\": \"1.03ms\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 161, \"std\": 3.0793718606073903, \"mean\": 0.3229813664596274}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 13.630323337533643, \"value\": 10, \"mean\": 57.357142857142854}} (export_time=126.12us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:51,851] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.07s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:54,801] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20308.1 vnc_pixels_ps[total]=112668.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:54,802] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"721.22us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.09ms\", \"mean\": \"586.27us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"19.36us\", \"mean\": \"54.10us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"396.83us\", \"mean\": \"361.17us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.35ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"97.97us\", \"mean\": \"303.02us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.64us\", \"mean\": \"119.94us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"32.45us\", \"mean\": \"109.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.26us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.5068698018697012, \"value\": 12.0, \"mean\": 11.56521739130435}} (export_time=290.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:54,803] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.95s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1891 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:56,834] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.03s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:58,368] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:59,818] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9193.3 vnc_pixels_ps[total]=44884.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:59,819] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.60ms\", \"mean\": \"15.93ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.68ms\", \"mean\": \"2.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.21us\", \"mean\": \"56.63us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.59ms\", \"mean\": \"537.89us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"3.04ms\", \"mean\": \"12.49ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"99.16us\", \"mean\": \"319.12us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.54us\", \"mean\": \"121.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"32.03us\", \"mean\": \"107.05us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.80us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.6431676725154984, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096663, \"mean\": 0.08970099667774083}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.9526172657404692, \"value\": 21.0, \"mean\": 14.888888888888888}} (export_time=224.35us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:31:59,820] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:02,922] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.10s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 5482, 'rewarder.vnc.updates.pixels': 10968, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:04,834] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7562.7 vnc_pixels_ps[total]=44320.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:04,834] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"605.24us\", \"mean\": \"16.13ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.70ms\", \"mean\": \"843.71us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"25.82us\", \"mean\": \"45.98us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"569.58us\", \"mean\": \"352.61us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.30ms\", \"mean\": \"5.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"105.71us\", \"mean\": \"252.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.20us\", \"mean\": \"107.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"56.30us\", \"mean\": \"93.95us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.12us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607094, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.823756276622988, \"value\": 25.0, \"mean\": 22.249999999999996}} (export_time=112.77us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:04,835] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.91s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:07,017] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:08,552] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:09,836] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10108.5 vnc_pixels_ps[total]=45681.3 reward_lag=None rewarder_message_lag=None fps=59.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:09,837] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.37ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"4.92ms\", \"mean\": \"2.49ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"21.87us\", \"mean\": \"47.25us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.68ms\", \"mean\": \"532.57us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"1.12ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"3.96ms\", \"mean\": \"11.61ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"98.17us\", \"mean\": \"263.27us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"49.96us\", \"mean\": \"112.61us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"33.57us\", \"mean\": \"93.32us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"63.24us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2866599257717727, \"mean\": 0.09000000000000002}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.5396007178390019, \"value\": 30.0, \"mean\": 26.296296296296294}} (export_time=286.58us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:09,837] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.29s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2021 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:11,369] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:14,403] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:14,851] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8422.1 vnc_pixels_ps[total]=45004.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:14,852] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"792.56us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.29ms\", \"mean\": \"1.03ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"18.87us\", \"mean\": \"40.13us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"769.91us\", \"mean\": \"384.63us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.06ms\", \"mean\": \"6.63ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"95.54us\", \"mean\": \"233.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.30us\", \"mean\": \"108.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"26.08us\", \"mean\": \"82.22us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.42us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.4142135623730951, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609667, \"mean\": 0.08970099667774084}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.9281983087713572, \"value\": 38.0, \"mean\": 34.44444444444444}} (export_time=78.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,569] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=536us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,569] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,570] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.17s, sent 2 reward messages to agent: reward=2.0 reward_min=0.0 reward_max=2.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,570] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,570] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,570] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 89->90, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,571] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,571] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,572] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=90\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,572] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,573] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,594] init detected end of child process 3933 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,598] init detected end of child process 3948 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,599] init detected end of child process 4156 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,601] init detected end of child process 4150 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,614] init detected end of child process 4178 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:19 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,654] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,654] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:19 [info] 70#70: *479 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:19 [info] 70#70: *480 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:19 [info] 70#70: *478 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:19,747] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,917] init detected end of child process 3936 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,917] init detected end of child process 3944 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,917] init detected end of child process 3945 with exit code 0, not killed by signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:19,917] init detected end of child process 3947 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,008] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,009] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,081] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,578] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,578] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,578] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'fine_quality_level': 50, 'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,578] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,585] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,585] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:32:21 I0508 22:32:21.585757 4562 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:32:21 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::49226\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:32:21 I0508 22:32:21.586992 4562 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:21,706] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:25,756] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,406] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['223us', '68us', '59us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,406] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,407] [play_vexpect] vexpect macro complete in 6.786759s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:32:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::49226 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 3 rects, 131.153 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 16.3193 KiB (1:31.3954 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 15 rects, 331.282 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  134.053 KiB (1:9.65475 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.08484 MiB (1:2.78043 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,673] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 90->90, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,674] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,674] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=89->90, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,675] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.10s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,675] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=30.0 episode_count=21 episode_duration=38.89\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,676] [INFO:universe.wrappers.logger] Stats for the past 13.82s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2425.8 vnc_pixels_ps[total]=15454.6 reward_lag=None rewarder_message_lag=None fps=20.54\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,686] [INFO:gym_controlplane.reward.reward] First score parsed: score=19. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:28,687] [INFO:universe.pyprofile] [pyprofile] period=13.83s timers={\"rewarder.sleep\": {\"calls\": 283, \"std\": \"191.52us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"1.97ms\", \"mean\": \"689.55us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.35us\", \"mean\": \"34.95us\"}, \"rewarder.compute_reward\": {\"calls\": 284, \"std\": \"685.64us\", \"mean\": \"310.79us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"30.52us\", \"mean\": \"57.18us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"171.71us\", \"mean\": \"236.53us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 284, \"std\": \"43.25us\", \"mean\": \"96.82us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"33.42us\", \"mean\": \"75.32us\"}, \"rewarder.frame\": {\"calls\": 284, \"std\": \"809.50us\", \"mean\": \"16.72ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 284, \"std\": 1.7369824259449507, \"mean\": 0.1795774647887324}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 63, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 6.255432421712243, \"value\": 10, \"mean\": 38.69565217391305}} (export_time=157.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:29,892] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.22s, sent 2 reward messages to agent: reward=12.0 reward_min=3.0 reward_max=9 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2131 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:31,191] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:33,691] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20027.8 vnc_pixels_ps[total]=97470.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:33,692] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.08ms\", \"mean\": \"1.07ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"13.57us\", \"mean\": \"29.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"715.27us\", \"mean\": \"316.86us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"812.96us\", \"mean\": \"5.66ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"71.17us\", \"mean\": \"167.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"37.97us\", \"mean\": \"91.18us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"28.57us\", \"mean\": \"72.59us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.54us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 3.3466401061363023, \"mean\": 3.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.0897009966777409}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.869428206737055, \"value\": 26.0, \"mean\": 23.18518518518518}} (export_time=105.62us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:33,692] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.50s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1932 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,425] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=232us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,425] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,425] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.73s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 90->91, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,426] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=91\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,427] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,427] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,439] init detected end of child process 4306 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,443] init detected end of child process 4321 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,446] init detected end of child process 4528 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,447] init detected end of child process 4523 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,464] init detected end of child process 4550 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:32:38 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,501] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,501] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:38 [info] 70#70: *482 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:38 [info] 70#70: *483 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:32:38 [info] 70#70: *481 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:38,590] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,809] init detected end of child process 4309 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,809] init detected end of child process 4317 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,809] init detected end of child process 4318 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:32:38,810] init detected end of child process 4320 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:39,822] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:39,823] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,228] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,730] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,730] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,730] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,731] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,737] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,737] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:32:43 I0508 22:32:43.737397 4946 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:32:43 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::49394\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:32:43 I0508 22:32:43.739054 4946 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:43,863] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:47,897] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,164] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['148us', '67us', '59us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,164] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,164] [play_vexpect] vexpect macro complete in 4.393405s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:32:48 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::49394 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 7 rects, 76.05 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  19.3721 KiB (1:15.3392 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 43 rects, 1.0783 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.85492 MiB (1:1.44097 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,434] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 91->91, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,435] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,435] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=90->91, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,435] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.01s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,435] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=16.0 episode_count=7 episode_duration=19.76\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,436] [INFO:universe.wrappers.logger] Stats for the past 14.74s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2273.2 vnc_pixels_ps[total]=14495.6 reward_lag=None rewarder_message_lag=None fps=19.33\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,447] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:48,448] [INFO:universe.pyprofile] [pyprofile] period=14.76s timers={\"rewarder.sleep\": {\"calls\": 284, \"std\": \"155.95us\", \"mean\": \"16.26ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.09ms\", \"mean\": \"667.87us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.31ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.48us\", \"mean\": \"28.62us\"}, \"rewarder.compute_reward\": {\"calls\": 285, \"std\": \"720.90us\", \"mean\": \"293.13us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"20.32us\", \"mean\": \"40.81us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"95.55us\", \"mean\": \"187.64us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 285, \"std\": \"38.39us\", \"mean\": \"97.84us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.42us\", \"mean\": \"69.14us\"}, \"rewarder.frame\": {\"calls\": 285, \"std\": \"881.45us\", \"mean\": \"16.71ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 285, \"std\": 2.0863375917089044, \"mean\": 0.20350877192982464}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 66, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 3.265986323710904, \"value\": 10, \"mean\": 25.333333333333332}} (export_time=127.08us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:49,719] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1347, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 9824, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:50,802] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:52,536] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:53,453] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=12.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21010.8 vnc_pixels_ps[total]=106280.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:53,454] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.28ms\", \"mean\": \"16.03ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.35ms\", \"mean\": \"1.39ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"16.30us\", \"mean\": \"41.10us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.07ms\", \"mean\": \"406.17us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.54ms\", \"mean\": \"9.21ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"81.48us\", \"mean\": \"234.05us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.64us\", \"mean\": \"107.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"25.54us\", \"mean\": \"82.33us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.63us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.5459624833740317, \"value\": 14.0, \"mean\": 11.839999999999998}} (export_time=306.61us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:53,836] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1920 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:56,020] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.18s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:58,470] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8446.4 vnc_pixels_ps[total]=45151.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:58,470] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.14ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.48ms\", \"mean\": \"1.50ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"16.16us\", \"mean\": \"50.36us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"456.65us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.20ms\", \"mean\": \"9.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"79.85us\", \"mean\": \"282.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"44.37us\", \"mean\": \"120.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"22.56us\", \"mean\": \"97.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.88us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662219, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.29916372756571, \"value\": 20.0, \"mean\": 17.615384615384613}} (export_time=156.40us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:58,471] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.45s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1914 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:32:59,920] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:01,203] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:02,798] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.59s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:03,486] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9264.6 vnc_pixels_ps[total]=45434.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:03,486] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.61ms\", \"mean\": \"1.81ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"16.84us\", \"mean\": \"53.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"479.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.86ms\", \"mean\": \"9.78ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"91.83us\", \"mean\": \"308.17us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.37us\", \"mean\": \"118.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"30.39us\", \"mean\": \"101.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"31.53us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.8366600265340756, \"mean\": 1.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.7694784912663177, \"value\": 26.0, \"mean\": 21.851851851851855}} (export_time=126.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:05,103] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.30s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:08,503] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6797.0 vnc_pixels_ps[total]=44610.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:08,504] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"607.46us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.88ms\", \"mean\": \"716.77us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.13us\", \"mean\": \"48.23us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"607.32us\", \"mean\": \"363.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.10ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"90.74us\", \"mean\": \"272.92us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.33us\", \"mean\": \"117.14us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.58us\", \"mean\": \"95.04us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"32.31us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260708, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9890707100936801, \"value\": 28.0, \"mean\": 27.25}} (export_time=218.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:08,505] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.40s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1890 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:10,536] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.03s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:13,519] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6997.4 vnc_pixels_ps[total]=44378.2 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:13,519] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"972.61us\", \"mean\": \"16.04ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.90ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"22.45us\", \"mean\": \"52.74us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"922.93us\", \"mean\": \"415.25us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"4.44ms\", \"mean\": \"9.92ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"107.92us\", \"mean\": \"296.49us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"50.79us\", \"mean\": \"118.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"34.47us\", \"mean\": \"102.30us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.96us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 2.0816659994661326, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 3.279735761714147, \"value\": 35.0, \"mean\": 31.44}} (export_time=118.49us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:13,520] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.98s, sent 2 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:15,936] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.42s, sent 1 reward messages to agent: reward=4.0 reward_min=4.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:18,536] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.2 vnc_pixels_ps[total]=44289.6 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:18,538] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"449.06us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.18ms\", \"mean\": \"642.40us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"19.00us\", \"mean\": \"60.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"450.02us\", \"mean\": \"409.72us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.05ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"89.56us\", \"mean\": \"341.10us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.73us\", \"mean\": \"131.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"27.31us\", \"mean\": \"112.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.16us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531563}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.0396078054371163, \"value\": 39.0, \"mean\": 36.919999999999995}} (export_time=165.46us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:18,538] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.60s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1896 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:20,053] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.51s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:23,553] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7045.3 vnc_pixels_ps[total]=46449.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:23,553] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"924.24us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.91ms\", \"mean\": \"978.74us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.93us\", \"mean\": \"59.72us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"904.25us\", \"mean\": \"403.45us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.18ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"108.56us\", \"mean\": \"335.60us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.60us\", \"mean\": \"121.52us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.13us\", \"mean\": \"108.67us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"28.07us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910303}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.48154341234307513, \"value\": 40.0, \"mean\": 39.66666666666667}} (export_time=202.18us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:23,554] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.50s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:25,252] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.70s, sent 2 reward messages to agent: reward=5.0 reward_min=2.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:26,769] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:28,570] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9242.2 vnc_pixels_ps[total]=45266.5 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:28,570] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"772.35us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.64ms\", \"mean\": \"1.67ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"26.90us\", \"mean\": \"50.90us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"454.60us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"478.74us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.42ms\", \"mean\": \"9.06ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"95.73us\", \"mean\": \"279.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.42us\", \"mean\": \"111.99us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"32.13us\", \"mean\": \"91.10us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"35.47us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.353998840549953, \"value\": 47.0, \"mean\": 44.18518518518519}} (export_time=150.68us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:28,571] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.80s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2029 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:30,453] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.88s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:32,837] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:33,588] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8420.1 vnc_pixels_ps[total]=44993.8 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:33,589] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"640.97us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.41ms\", \"mean\": \"1.48ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.70us\", \"mean\": \"57.05us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.13ms\", \"mean\": \"456.43us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"270.13us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"4.96ms\", \"mean\": \"9.51ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"118.06us\", \"mean\": \"323.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.04us\", \"mean\": \"118.25us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"32.02us\", \"mean\": \"104.18us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"33.01us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.3196736193235254, \"value\": 51.0, \"mean\": 48.307692307692314}} (export_time=375.51us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:38,604] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.6 vnc_pixels_ps[total]=44189.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:38,604] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"304.55us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"112.99us\", \"mean\": \"375.04us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"25.31us\", \"mean\": \"57.11us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"235.16us\", \"mean\": \"377.31us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"123.08us\", \"mean\": \"320.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.81us\", \"mean\": \"126.03us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.51us\", \"mean\": \"108.29us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"29.20us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289042}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 51.0, \"mean\": 51.0}} (export_time=177.38us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:38,605] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.77s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:33:39 [info] 70#70: *485 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:33:39 [info] 70#70: *486 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:41,504] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.90s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:43,621] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6755.7 vnc_pixels_ps[total]=44292.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:43,622] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"606.94us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.75ms\", \"mean\": \"781.93us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.84us\", \"mean\": \"64.82us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"598.82us\", \"mean\": \"405.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.67ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"118.39us\", \"mean\": \"364.85us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.72us\", \"mean\": \"120.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.18us\", \"mean\": \"117.31us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"30.72us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4945353550468404, \"value\": 52.0, \"mean\": 51.375}} (export_time=341.89us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:43,623] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.12s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1892 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:48,637] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5955.2 vnc_pixels_ps[total]=44186.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:48,638] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"347.83us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"98.32us\", \"mean\": \"423.63us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"24.47us\", \"mean\": \"63.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"251.46us\", \"mean\": \"378.41us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"121.71us\", \"mean\": \"360.24us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.18us\", \"mean\": \"118.27us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"28.01us\", \"mean\": \"124.11us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.71us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079444, \"mean\": 0.07641196013289046}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 52.0, \"mean\": 52.0}} (export_time=173.33us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:48,638] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1722 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:49,737] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:53,654] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8454.7 vnc_pixels_ps[total]=45159.4 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:53,655] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.16ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.45ms\", \"mean\": \"1.61ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"33.30us\", \"mean\": \"61.99us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.15ms\", \"mean\": \"486.59us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.42ms\", \"mean\": \"10.37ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"153.29us\", \"mean\": \"342.80us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.26us\", \"mean\": \"118.98us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"37.97us\", \"mean\": \"118.07us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.79us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152824}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.4685716829466697, \"value\": 58.0, \"mean\": 56.42307692307693}} (export_time=157.59us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:53,656] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.92s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:56,037] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.38s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:57,771] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:58,671] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8658.2 vnc_pixels_ps[total]=46752.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:33:58,672] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.25ms\", \"mean\": \"15.90ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.67ms\", \"mean\": \"1.72ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"28.81us\", \"mean\": \"73.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"552.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.46ms\", \"mean\": \"10.82ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"136.11us\", \"mean\": \"405.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.27us\", \"mean\": \"135.57us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"31.51us\", \"mean\": \"135.57us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.15us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.0863787375415282}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.412580834991264, \"value\": 63.0, \"mean\": 59.34615384615385}} (export_time=292.30us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:02,103] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.33s, sent 3 reward messages to agent: reward=4.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1312, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9536, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:03,687] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7603.0 vnc_pixels_ps[total]=44716.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:03,688] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.07ms\", \"mean\": \"1.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"25.81us\", \"mean\": \"70.00us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"513.39us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"670.30us\", \"mean\": \"11.16ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"130.97us\", \"mean\": \"394.32us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.80us\", \"mean\": \"135.64us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"51.12us\", \"mean\": \"141.74us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.92us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531562}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.540562667772175, \"value\": 67.0, \"mean\": 63.96000000000001}} (export_time=259.64us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:03,689] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.58s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1936 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:07,104] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.41s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:08,188] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:08,703] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8434.7 vnc_pixels_ps[total]=45003.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:08,704] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"984.74us\", \"mean\": \"16.02ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"2.95ms\", \"mean\": \"1.36ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"20.55us\", \"mean\": \"52.16us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"965.88us\", \"mean\": \"451.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"3.65ms\", \"mean\": \"8.29ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"101.40us\", \"mean\": \"295.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"49.56us\", \"mean\": \"123.04us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.91us\", \"mean\": \"103.80us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.68us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.9574271077563381, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961356, \"mean\": 0.08305647840531565}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.5937377450509185, \"value\": 72.0, \"mean\": 67.96000000000001}} (export_time=181.20us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:10,804] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.62s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1923 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:13,720] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6784.5 vnc_pixels_ps[total]=44397.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:13,721] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"686.96us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.13ms\", \"mean\": \"793.97us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"28.29us\", \"mean\": \"53.81us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"680.76us\", \"mean\": \"376.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.36ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"126.05us\", \"mean\": \"298.26us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.08us\", \"mean\": \"115.67us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"35.44us\", \"mean\": \"102.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.62us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 2.8284271247461903, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.0359095108162024, \"value\": 76.0, \"mean\": 74.16666666666666}} (export_time=146.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:13,721] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.92s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1901 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,170] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=334us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,170] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,170] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.45s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 91->92, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,171] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=92\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,172] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,172] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,184] init detected end of child process 4674 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,189] init detected end of child process 4689 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,190] init detected end of child process 4898 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,206] init detected end of child process 4920 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:15 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,246] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,247] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:15,334] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,533] init detected end of child process 4677 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,533] init detected end of child process 4685 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,533] init detected end of child process 4686 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:15,533] init detected end of child process 4688 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:16,605] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:16,606] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:16,664] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,177] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,177] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,177] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2, 'start_timeout': 7, 'compress_level': 0}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,178] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,184] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,184] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:34:17 I0508 22:34:17.184767 5481 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:34:17 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::49656\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:34:17 I0508 22:34:17.186269 5481 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:17,308] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:21,358] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,025] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['164us', '64us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,025] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,026] [play_vexpect] vexpect macro complete in 4.807517s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:34:22 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::49656 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.682 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  85.1123 KiB (1:18.1618 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 23 rects, 789.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.02901 MiB (1:2.92596 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,273] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 92->92, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,274] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,274] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=91->92, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,274] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.10s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,274] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=66.0 episode_count=54 episode_duration=93.84\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,275] [INFO:universe.wrappers.logger] Stats for the past 8.55s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1652.0 vnc_pixels_ps[total]=8240.7 reward_lag=None rewarder_message_lag=None fps=10.29\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,286] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:22,286] [INFO:universe.pyprofile] [pyprofile] period=8.57s timers={\"rewarder.sleep\": {\"calls\": 87, \"std\": \"274.88us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 9, \"std\": \"3.35ms\", \"mean\": \"1.40ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.17ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 27, \"std\": \"17.37us\", \"mean\": \"31.65us\"}, \"rewarder.compute_reward\": {\"calls\": 88, \"std\": \"1.25ms\", \"mean\": \"453.92us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"18.48us\", \"mean\": \"42.48us\"}, \"reward.parsing.gameover\": {\"calls\": 9, \"std\": \"137.98us\", \"mean\": \"252.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 88, \"std\": \"63.58us\", \"mean\": \"110.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 9, \"std\": \"39.15us\", \"mean\": \"76.40us\"}, \"rewarder.frame\": {\"calls\": 88, \"std\": \"1.58ms\", \"mean\": \"16.60ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 88, \"std\": 2.6708838779803163, \"mean\": 0.375}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 8, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 9, \"std\": 22.0, \"value\": 10, \"mean\": 68.66666666666667}} (export_time=110.86us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:23,358] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 3 reward messages to agent: reward=3.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2060 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:27,224] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.87s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:27,291] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22690.1 vnc_pixels_ps[total]=79781.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:27,292] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"995.27us\", \"mean\": \"16.18ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.18ms\", \"mean\": \"1.02ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"10.18us\", \"mean\": \"25.56us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"686.72us\", \"mean\": \"299.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"233.10us\", \"mean\": \"6.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"21.98us\", \"mean\": \"142.04us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.85us\", \"mean\": \"95.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"19.55us\", \"mean\": \"65.44us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.82us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 1.25}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910298}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 21, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5646597025732808, \"value\": 13.0, \"mean\": 12.666666666666664}} (export_time=121.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,174] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=207us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.95s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=3.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1912 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 92->93, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,175] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,176] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=93\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,176] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,176] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,188] init detected end of child process 5223 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,191] init detected end of child process 5238 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,194] init detected end of child process 5440 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,197] init detected end of child process 5447 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,211] init detected end of child process 5472 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:34:30 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,249] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,249] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:34:30 [info] 70#70: *488 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:34:30 [info] 70#70: *489 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:34:30 [info] 70#70: *487 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:30,345] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,577] init detected end of child process 5226 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,577] init detected end of child process 5234 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,577] init detected end of child process 5235 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:34:30,577] init detected end of child process 5237 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:31,578] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.23s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:31,579] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:34,906] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,403] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,403] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,403] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'encoding': 'zrle', 'fine_quality_level': 50, 'subsample_level': 2, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,403] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,405] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,405] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:34:35 I0508 22:34:35.405763 5857 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:34:35 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::49820\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:34:35 I0508 22:34:35.406977 5857 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:35,534] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:36,869] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['299us', '228us', '151us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:36,870] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:36,870] [play_vexpect] vexpect macro complete in 1.430988s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:34:37 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::49820 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 83.106 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.1123 KiB (1:16.1445 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 29 rects, 990.208 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.83434 MiB (1:1.33282 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 38 rects, 1.07362 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.85409 MiB (1:1.43513 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,092] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 93->93, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,092] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,093] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=92->93, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,093] [INFO:universe.rewarder.remote] [Rewarder] Over past 6.92s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,093] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=8.0 episode_count=7 episode_duration=14.82\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,094] [INFO:universe.wrappers.logger] Stats for the past 9.80s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2511.9 vnc_pixels_ps[total]=12083.3 reward_lag=None rewarder_message_lag=None fps=17.75\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,103] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:37,103] [INFO:universe.pyprofile] [pyprofile] period=9.81s timers={\"rewarder.sleep\": {\"calls\": 173, \"std\": \"509.66us\", \"mean\": \"16.27ms\"}, \"reward.parsing.score\": {\"calls\": 15, \"std\": \"2.45ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.34ms\", \"mean\": \"6.86ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 45, \"std\": \"8.10us\", \"mean\": \"21.63us\"}, \"rewarder.compute_reward\": {\"calls\": 174, \"std\": \"867.99us\", \"mean\": \"307.38us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"26.72us\", \"mean\": \"41.96us\"}, \"reward.parsing.gameover\": {\"calls\": 15, \"std\": \"81.51us\", \"mean\": \"164.00us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 174, \"std\": \"43.81us\", \"mean\": \"93.32us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 15, \"std\": \"14.63us\", \"mean\": \"52.50us\"}, \"rewarder.frame\": {\"calls\": 174, \"std\": \"1.15ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 3, \"std\": 1.7320508075688772, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 174, \"std\": 1.3855466618592185, \"mean\": 0.18390804597701155}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 39, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 15, \"std\": 2.2886885410853175, \"value\": 10, \"mean\": 16.666666666666668}} (export_time=149.73us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:40,377] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.28s, sent 2 reward messages to agent: reward=2.0 reward_min=1 reward_max=1 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2149 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:42,111] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=8.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=15238.1 vnc_pixels_ps[total]=76601.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:42,113] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.38ms\", \"mean\": \"16.00ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.85ms\", \"mean\": \"1.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"25.96us\", \"mean\": \"49.45us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.24ms\", \"mean\": \"436.27us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"1.50ms\", \"mean\": \"13.93ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"129.98us\", \"mean\": \"277.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"125.32us\", \"mean\": \"122.23us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"32.75us\", \"mean\": \"94.16us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"89.18us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.1547005383792517, \"mean\": 1.6666666666666665}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.5728465131239455, \"value\": 15.0, \"mean\": 11.923076923076923}} (export_time=308.04us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:42,114] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.74s, sent 2 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:44,044] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.93s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:47,094] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.05s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:47,127] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8680.6 vnc_pixels_ps[total]=46849.0 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:47,128] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"913.05us\", \"mean\": \"16.01ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.57ms\", \"mean\": \"1.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"23.05us\", \"mean\": \"52.14us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"866.35us\", \"mean\": \"445.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.56ms\", \"mean\": \"7.57ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"118.20us\", \"mean\": \"292.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.18us\", \"mean\": \"126.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"33.71us\", \"mean\": \"102.54us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"22.83us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358056, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152818}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4076712903012771, \"value\": 18.0, \"mean\": 16.692307692307693}} (export_time=153.78us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:48,411] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.32s, sent 4 reward messages to agent: reward=9.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:49,894] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.48s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:52,144] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10962.6 vnc_pixels_ps[total]=46295.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:52,145] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.32ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"3.67ms\", \"mean\": \"2.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"18.40us\", \"mean\": \"48.58us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.31ms\", \"mean\": \"529.71us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"2.66ms\", \"mean\": \"8.29ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"83.49us\", \"mean\": \"270.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.27us\", \"mean\": \"126.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"26.18us\", \"mean\": \"92.52us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"24.49us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 7, \"std\": 1.4960264830861913, \"mean\": 2.2857142857142856}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2909487288006216, \"mean\": 0.09302325581395346}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 5.27384983323303, \"value\": 37.0, \"mean\": 30.535714285714285}} (export_time=249.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:52,145] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.25s, sent 2 reward messages to agent: reward=4.0 reward_min=0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1933 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:55,961] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.82s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:57,061] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.10s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:57,161] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8421.2 vnc_pixels_ps[total]=44999.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:57,161] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.23ms\", \"mean\": \"15.97ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"3.70ms\", \"mean\": \"1.65ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"21.82us\", \"mean\": \"53.92us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.22ms\", \"mean\": \"483.96us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.97ms\", \"mean\": \"11.10ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"107.11us\", \"mean\": \"299.59us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.33us\", \"mean\": \"122.71us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"26.45us\", \"mean\": \"102.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.82us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662218, \"mean\": 0.08637873754152828}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.1293292767765362, \"value\": 40.0, \"mean\": 37.65384615384615}} (export_time=158.55us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:58,127] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1919 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:34:59,644] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:02,177] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9243.5 vnc_pixels_ps[total]=45200.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:02,178] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.51ms\", \"mean\": \"15.92ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.50ms\", \"mean\": \"2.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"21.54us\", \"mean\": \"56.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.51ms\", \"mean\": \"540.76us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.18ms\", \"mean\": \"12.08ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"103.62us\", \"mean\": \"311.82us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"73.54us\", \"mean\": \"127.48us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"31.65us\", \"mean\": \"105.89us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.31us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29764673182427176, \"mean\": 0.08970099667774085}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.7701707806281832, \"value\": 48.0, \"mean\": 44.92307692307692}} (export_time=211.48us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:02,179] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.53s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1930 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:07,194] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5975.3 vnc_pixels_ps[total]=44341.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:07,195] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"242.58us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"70.36us\", \"mean\": \"361.74us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.58us\", \"mean\": \"52.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"209.82us\", \"mean\": \"358.49us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"69.43us\", \"mean\": \"291.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.66us\", \"mean\": \"123.11us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"20.11us\", \"mean\": \"105.04us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.75us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 48.0, \"mean\": 48.0}} (export_time=192.17us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:07,195] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:12,211] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.9 vnc_pixels_ps[total]=44022.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:12,212] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"252.09us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"90.56us\", \"mean\": \"355.25us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"17.69us\", \"mean\": \"52.08us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"237.48us\", \"mean\": \"363.30us\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"88.92us\", \"mean\": \"295.08us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.44us\", \"mean\": \"124.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.71us\", \"mean\": \"102.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.36us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260707, \"mean\": 0.0797342192691031}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 48.0, \"mean\": 48.0}} (export_time=181.91us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:12,213] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1718 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:15,477] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.26s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:17,227] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6733.8 vnc_pixels_ps[total]=44041.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:17,228] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"630.00us\", \"mean\": \"16.11ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.86ms\", \"mean\": \"689.75us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"24.57us\", \"mean\": \"46.89us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"602.18us\", \"mean\": \"361.86us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.96ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"118.92us\", \"mean\": \"266.87us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"53.94us\", \"mean\": \"115.47us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"28.88us\", \"mean\": \"87.91us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.25us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9630868246861537, \"value\": 50.0, \"mean\": 48.666666666666664}} (export_time=149.49us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:17,229] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1899 bytes>', 'rewarder.vnc.updates.pixels': 9600}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:22,244] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6191.5 vnc_pixels_ps[total]=45933.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:22,245] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"248.89us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"90.51us\", \"mean\": \"350.96us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"17.77us\", \"mean\": \"50.71us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"216.10us\", \"mean\": \"363.42us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"93.93us\", \"mean\": \"293.34us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.41us\", \"mean\": \"123.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.38us\", \"mean\": \"99.45us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.72us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794456, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 50.0, \"mean\": 50.0}} (export_time=204.80us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:22,246] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1726 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:27,194] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.95s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:27,261] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6777.1 vnc_pixels_ps[total]=44456.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:27,261] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"485.21us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.30ms\", \"mean\": \"653.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"15.25us\", \"mean\": \"54.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"461.44us\", \"mean\": \"404.91us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"72.73us\", \"mean\": \"308.20us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"51.19us\", \"mean\": \"130.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"26.60us\", \"mean\": \"110.53us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.85us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.0, \"value\": 50.0, \"mean\": 50.0}} (export_time=164.03us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:30,427] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.23s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1870 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:31 [info] 70#70: *491 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:31 [info] 70#70: *492 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:31,727] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:32,278] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8400.6 vnc_pixels_ps[total]=44840.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:32,279] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.36ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.14ms\", \"mean\": \"1.81ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"19.35us\", \"mean\": \"55.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.36ms\", \"mean\": \"484.25us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.66ms\", \"mean\": \"12.51ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"86.28us\", \"mean\": \"306.97us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"48.68us\", \"mean\": \"115.80us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.10us\", \"mean\": \"100.92us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"25.21us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.816496580927726, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.08637873754152821}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.4120361729949253, \"value\": 55.0, \"mean\": 51.92307692307692}} (export_time=219.58us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:37,294] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6798.2 vnc_pixels_ps[total]=44618.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:37,295] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"397.88us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.04ms\", \"mean\": \"563.93us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"15.99us\", \"mean\": \"49.89us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"377.47us\", \"mean\": \"384.67us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.18ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"74.35us\", \"mean\": \"280.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.03us\", \"mean\": \"123.45us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"23.61us\", \"mean\": \"99.18us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"23.13us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910296}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.33783196234608953, \"value\": 56.0, \"mean\": 55.87499999999999}} (export_time=275.61us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:37,296] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.57s, sent 3 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:42,310] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.4 vnc_pixels_ps[total]=44026.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:42,311] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"286.56us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"121.62us\", \"mean\": \"368.83us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"20.08us\", \"mean\": \"50.91us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"226.55us\", \"mean\": \"359.79us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"99.76us\", \"mean\": \"287.68us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"52.25us\", \"mean\": \"121.13us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"31.63us\", \"mean\": \"107.18us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"27.75us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 56.0, \"mean\": 56.0}} (export_time=134.71us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:42,311] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,877] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=451us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,878] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,878] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.57s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,878] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,878] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,879] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 93->94, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,879] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,879] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,880] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=94\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,880] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,881] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:44,901] init detected end of child process 5590 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:44,907] init detected end of child process 5605 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:44,908] init detected end of child process 5813 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:44,923] init detected end of child process 5834 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:35:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:35:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:35:44 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,961] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:44,961] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:45,048] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:45,245] init detected end of child process 5593 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:45,245] init detected end of child process 5601 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:45,245] init detected end of child process 5602 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:35:45,246] init detected end of child process 5604 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,311] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,312] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,377] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,855] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,855] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,856] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'subsample_level': 2, 'start_timeout': 7, 'encoding': 'zrle', 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,856] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,861] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,861] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:35:46 I0508 22:35:46.86218 6380 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:35:46 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::50044\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:35:46 I0508 22:35:46.863591 6380 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:46,989] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *496 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *497 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *498 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *499 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *500 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *501 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *502 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *503 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *504 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:35:50 [info] 70#70: *505 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:51,056] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,773] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['143us', '68us', '56us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,773] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,773] [play_vexpect] vexpect macro complete in 7.877847s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:35:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::50044 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.229 KiB (1:10.3193 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27231 MiB (1:2.37073 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,960] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 94->94, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,960] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,960] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=93->94, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,961] [INFO:universe.rewarder.remote] [Rewarder] Over past 10.08s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,961] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=46.0 episode_count=39 episode_duration=77.87\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,963] [INFO:universe.wrappers.logger] Stats for the past 12.65s: vnc_updates_ps=1.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1628.3 vnc_pixels_ps[total]=9365.8 reward_lag=None rewarder_message_lag=None fps=12.25\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,974] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:54,975] [INFO:universe.pyprofile] [pyprofile] period=12.66s timers={\"rewarder.sleep\": {\"calls\": 154, \"std\": \"247.22us\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 14, \"std\": \"2.84ms\", \"mean\": \"1.12ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"24.58us\", \"mean\": \"50.98us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 155, \"std\": \"55.90us\", \"mean\": \"125.47us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 42, \"std\": \"19.96us\", \"mean\": \"48.65us\"}, \"rewarder.compute_reward\": {\"calls\": 155, \"std\": \"1.02ms\", \"mean\": \"452.32us\"}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"calls\": 10, \"std\": \"1.05ms\", \"mean\": \"1.56ms\"}, \"reward.parsing.gameover\": {\"calls\": 14, \"std\": \"135.35us\", \"mean\": \"326.94us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"10.84ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 14, \"std\": \"30.67us\", \"mean\": \"97.84us\"}, \"rewarder.frame\": {\"calls\": 155, \"std\": \"1.13ms\", \"mean\": \"16.70ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 155, \"std\": 2.658420079447607, \"mean\": 0.2967741935483871}, \"rewarder_protocol.messages\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"rewarder_protocol.messages.v0.control.ping\": {\"calls\": 10, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 36, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 13, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 14, \"std\": 12.294017127971522, \"value\": 10, \"mean\": 52.714285714285715}} (export_time=119.45us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:56,328] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.37s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1145, 'rewarder.profile': '<2501 bytes>', 'rewarder.vnc.updates.pixels': 8448, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:58,044] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:59,578] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:59,978] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=12.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22360.8 vnc_pixels_ps[total]=104656.1 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:35:59,979] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.21ms\", \"mean\": \"16.12ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.57ms\", \"mean\": \"1.38ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.30us\", \"mean\": \"28.48us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"885.80us\", \"mean\": \"341.79us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"1.45ms\", \"mean\": \"6.28ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"60.46us\", \"mean\": \"163.51us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"42.18us\", \"mean\": \"89.38us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"17.58us\", \"mean\": \"61.65us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"183.81us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.1690451944500122, \"mean\": 1.8333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2862287726609665, \"mean\": 0.08970099667774085}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 3.198557367121815, \"value\": 21.0, \"mean\": 14.999999999999998}} (export_time=151.16us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:04,994] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6006.7 vnc_pixels_ps[total]=44370.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:04,995] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"154.15us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"17.61us\", \"mean\": \"207.20us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"6.22us\", \"mean\": \"23.55us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"110.57us\", \"mean\": \"225.34us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"20.20us\", \"mean\": \"137.07us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.46us\", \"mean\": \"92.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"8.60us\", \"mean\": \"59.06us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"17.97us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289045}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 21.0, \"mean\": 21.0}} (export_time=85.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:04,995] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.42s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1723 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,778] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=259us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,778] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,778] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.78s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,778] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 94->95, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=95\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,779] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:08,791] init detected end of child process 6122 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:08,801] init detected end of child process 6137 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:08,802] init detected end of child process 6346 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:08,806] init detected end of child process 6428 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:08,821] init detected end of child process 6371 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,862] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,862] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:08 [info] 70#70: *494 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:08 [info] 70#70: *495 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:08 [info] 70#70: *493 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:08,951] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:09,193] init detected end of child process 6125 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:09,193] init detected end of child process 6133 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:09,193] init detected end of child process 6134 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:09,193] init detected end of child process 6136 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:10,189] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.24s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:10,190] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:10,590] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,067] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,067] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,067] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,067] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,069] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,069] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:11 I0508 22:36:11.069675 6747 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:11 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::50228\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:11 I0508 22:36:11.078095 6747 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:11,195] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:15,229] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,112] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['143us', '72us', '80us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,113] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,113] [play_vexpect] vexpect macro complete in 5.009812s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:16 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::50228 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 6\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 559.266 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  133.458 KiB (1:16.3708 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 25 rects, 952.792 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.25585 MiB (1:2.89437 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,368] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 95->95, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,369] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,369] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=94->95, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,369] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.59s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,370] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=11.0 episode_count=9 episode_duration=21.41\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,371] [INFO:universe.wrappers.logger] Stats for the past 11.38s: vnc_updates_ps=1.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2503.9 vnc_pixels_ps[total]=15487.9 reward_lag=None rewarder_message_lag=None fps=20.04\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,384] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:16,384] [INFO:universe.pyprofile] [pyprofile] period=11.39s timers={\"rewarder.sleep\": {\"calls\": 227, \"std\": \"145.43us\", \"mean\": \"16.29ms\"}, \"reward.parsing.score\": {\"calls\": 20, \"std\": \"2.74ms\", \"mean\": \"843.16us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"12.29ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 60, \"std\": \"12.13us\", \"mean\": \"27.01us\"}, \"rewarder.compute_reward\": {\"calls\": 228, \"std\": \"934.99us\", \"mean\": \"291.90us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.05us\", \"mean\": \"41.13us\"}, \"reward.parsing.gameover\": {\"calls\": 20, \"std\": \"83.60us\", \"mean\": \"184.99us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 228, \"std\": \"41.17us\", \"mean\": \"90.75us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 20, \"std\": \"20.48us\", \"mean\": \"64.55us\"}, \"rewarder.frame\": {\"calls\": 228, \"std\": \"1.00ms\", \"mean\": \"16.69ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 228, \"std\": 1.6731999624158203, \"mean\": 0.19298245614035087}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 54, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 19, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 20, \"std\": 2.4596747752497685, \"value\": 10, \"mean\": 20.45}} (export_time=167.13us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:17,620] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.25s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2100 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:21,387] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22040.4 vnc_pixels_ps[total]=82990.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:21,387] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"977.06us\", \"mean\": \"16.14ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.22ms\", \"mean\": \"555.26us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"21.39us\", \"mean\": \"44.41us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"419.68us\", \"mean\": \"314.38us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"6.01ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"109.38us\", \"mean\": \"251.48us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"45.31us\", \"mean\": \"104.60us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"30.25us\", \"mean\": \"95.96us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.75us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910301}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.4643056214875366, \"value\": 13.0, \"mean\": 12.708333333333334}} (export_time=180.72us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:21,388] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.77s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1900 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=205us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 95->96, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,120] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,121] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=96\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,121] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,121] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,135] init detected end of child process 6489 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,140] init detected end of child process 6504 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,142] init detected end of child process 6706 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,142] init detected end of child process 6713 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,166] init detected end of child process 6735 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:23 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,201] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,201] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:23 [info] 70#70: *507 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:23 [info] 70#70: *508 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:23 [info] 70#70: *506 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:23,299] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,529] init detected end of child process 6492 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,529] init detected end of child process 6500 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,529] init detected end of child process 6501 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:23,529] init detected end of child process 6503 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:24,563] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.26s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:24,564] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:27,976] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,458] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,458] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,458] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'compress_level': 0, 'encoding': 'zrle', 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,458] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,461] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,461] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:28 I0508 22:36:28.461536 7123 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:28 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::50394\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:28 I0508 22:36:28.469154 7123 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:28,594] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:30,928] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['174us', '64us', '55us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:30,928] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:30,928] [play_vexpect] vexpect macro complete in 2.433288s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:31 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::50394 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 8 rects, 84.242 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  20.8506 KiB (1:15.7868 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 41 rects, 1.16531 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.33569 MiB (1:1.33279 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 55 rects, 1.25014 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.35625 MiB (1:1.42109 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,146] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 96->96, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,146] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,147] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=95->96, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,147] [INFO:universe.rewarder.remote] [Rewarder] Over past 8.03s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,147] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=3.0 episode_count=4 episode_duration=14.78\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,148] [INFO:universe.wrappers.logger] Stats for the past 9.76s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1580.2 vnc_pixels_ps[total]=8205.1 reward_lag=None rewarder_message_lag=None fps=10.76\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,157] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:31,158] [INFO:universe.pyprofile] [pyprofile] period=9.77s timers={\"rewarder.sleep\": {\"calls\": 104, \"std\": \"290.57us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 10, \"std\": \"2.50ms\", \"mean\": \"1.11ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"8.05ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 30, \"std\": \"21.41us\", \"mean\": \"38.66us\"}, \"rewarder.compute_reward\": {\"calls\": 105, \"std\": \"951.90us\", \"mean\": \"383.19us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"19.64us\", \"mean\": \"41.52us\"}, \"reward.parsing.gameover\": {\"calls\": 10, \"std\": \"92.81us\", \"mean\": \"277.26us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 105, \"std\": \"38.75us\", \"mean\": \"101.06us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 10, \"std\": \"36.48us\", \"mean\": \"82.33us\"}, \"rewarder.frame\": {\"calls\": 105, \"std\": \"1.50ms\", \"mean\": \"16.62ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 105, \"std\": 2.253731135096649, \"mean\": 0.30476190476190473}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 24, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 10, \"std\": 0.9486832980505137, \"value\": 10, \"mean\": 12.7}} (export_time=160.93us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:32,981] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.83s, sent 2 reward messages to agent: reward=6.0 reward_min=2 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2095 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:34,281] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:36,164] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=9.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=17738.7 vnc_pixels_ps[total]=88103.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:36,165] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.11ms\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.90ms\", \"mean\": \"1.17ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"18.99us\", \"mean\": \"47.86us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"905.42us\", \"mean\": \"400.39us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"555.50us\", \"mean\": \"10.22ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"95.89us\", \"mean\": \"272.77us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"40.74us\", \"mean\": \"112.33us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"19.26us\", \"mean\": \"97.78us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.07us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 2.3333333333333335}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 2.2778072344036153, \"value\": 17.0, \"mean\": 14.833333333333334}} (export_time=115.39us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:36,165] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.88s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1939 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:39,498] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.33s, sent 1 reward messages to agent: reward=5.0 reward_min=5.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:41,181] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8351.5 vnc_pixels_ps[total]=44461.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:41,181] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"775.42us\", \"mean\": \"16.07ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.25ms\", \"mean\": \"1.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"25.02us\", \"mean\": \"48.32us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"769.31us\", \"mean\": \"416.73us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.51ms\", \"mean\": \"6.84ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"132.24us\", \"mean\": \"273.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"47.39us\", \"mean\": \"116.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"31.78us\", \"mean\": \"102.34us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"18.44us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 2.160246899469287, \"mean\": 2.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2813903150662217, \"mean\": 0.08637873754152825}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 3.1329514224425212, \"value\": 25.0, \"mean\": 19.153846153846153}} (export_time=137.57us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:41,182] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.68s, sent 3 reward messages to agent: reward=3.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1918 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:42,748] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.57s, sent 2 reward messages to agent: reward=4.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:45,764] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.02s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:46,197] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=8435.0 vnc_pixels_ps[total]=45065.8 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:46,198] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"869.44us\", \"mean\": \"16.05ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"2.51ms\", \"mean\": \"1.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"27.14us\", \"mean\": \"58.46us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"858.57us\", \"mean\": \"425.30us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"2.68ms\", \"mean\": \"7.38ms\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"144.53us\", \"mean\": \"329.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"46.41us\", \"mean\": \"114.12us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"38.94us\", \"mean\": \"111.41us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.47us\", \"mean\": \"16.77ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 1.2909944487358054, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622175, \"mean\": 0.0863787375415283}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 78, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 1.9135146880906009, \"value\": 31.0, \"mean\": 27.692307692307686}} (export_time=108.00us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=313us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.18s, sent 2 reward messages to agent: reward=0.0 reward_min=0 reward_max=0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.profile': '<1921 bytes>', 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 96->97, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,948] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,949] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,949] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=97\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,949] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:48,949] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:48,960] init detected end of child process 6852 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:48,963] init detected end of child process 6867 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:48,965] init detected end of child process 7069 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:48,968] init detected end of child process 7075 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:48,984] init detected end of child process 7100 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:48 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:36:49 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:49,025] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:49,025] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:49 [info] 70#70: *510 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:49 [info] 70#70: *511 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:36:49 [info] 70#70: *509 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:49,114] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:49,321] init detected end of child process 6855 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:49,321] init detected end of child process 6863 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:49,321] init detected end of child process 6864 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:36:49,321] init detected end of child process 6866 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:50,393] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.28s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:50,394] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:53,977] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,458] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,458] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,458] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'start_timeout': 7, 'encoding': 'zrle', 'compress_level': 0, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,458] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,460] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,461] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:54 I0508 22:36:54.461148 7492 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:54 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::50550\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:36:54 I0508 22:36:54.463009 7492 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:54,585] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,669] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['171us', '63us', '55us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,669] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,670] [play_vexpect] vexpect macro complete in 1.174966s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:36:55 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::50550 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 2 rects, 229 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            60 B (1:15.6667 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 11.529 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 1.55176 KiB (1:29.0371 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 4 rects, 66.722 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.0781 KiB (1:15.264 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 17 rects, 909.312 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  2.60258 MiB (1:1.33288 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 25 rects, 987.792 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          2.62083 MiB (1:1.43787 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,949] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 97->97, fps=60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,950] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,950] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=96->97, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,951] [INFO:universe.rewarder.remote] [Rewarder] Over past 7.00s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,951] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=21.0 episode_count=13 episode_duration=24.80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,952] [INFO:universe.wrappers.logger] Stats for the past 9.75s: vnc_updates_ps=1.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2224.1 vnc_pixels_ps[total]=12973.1 reward_lag=None rewarder_message_lag=None fps=17.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,966] [INFO:gym_controlplane.reward.reward] First score parsed: score=10. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:36:55,967] [INFO:universe.pyprofile] [pyprofile] period=9.77s timers={\"rewarder.sleep\": {\"calls\": 165, \"std\": \"221.85us\", \"mean\": \"16.20ms\"}, \"reward.parsing.score\": {\"calls\": 15, \"std\": \"3.39ms\", \"mean\": \"1.20ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.29ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 45, \"std\": \"24.72us\", \"mean\": \"41.77us\"}, \"rewarder.compute_reward\": {\"calls\": 166, \"std\": \"1.18ms\", \"mean\": \"392.94us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"12.43us\", \"mean\": \"43.31us\"}, \"reward.parsing.gameover\": {\"calls\": 15, \"std\": \"115.86us\", \"mean\": \"280.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 166, \"std\": \"32.51us\", \"mean\": \"97.02us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 15, \"std\": \"32.64us\", \"mean\": \"93.56us\"}, \"rewarder.frame\": {\"calls\": 166, \"std\": \"1.16ms\", \"mean\": \"16.67ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 166, \"std\": 1.8769756538019653, \"mean\": 0.22891566265060243}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 39, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 14, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 15, \"std\": 5.422176684690384, \"value\": 10, \"mean\": 29.6}} (export_time=154.97us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:00,419] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.47s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2101 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:00,968] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=9.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=21179.2 vnc_pixels_ps[total]=80489.7 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:00,968] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"927.60us\", \"mean\": \"16.08ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"2.95ms\", \"mean\": \"978.14us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"26.75us\", \"mean\": \"56.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"917.52us\", \"mean\": \"399.02us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"260.35us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"14.40ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"133.82us\", \"mean\": \"312.29us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"54.58us\", \"mean\": \"120.43us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"38.31us\", \"mean\": \"114.88us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"21.47us\", \"mean\": \"16.78ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27133238372607077, \"mean\": 0.07973421926910304}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5646597025732797, \"value\": 12.0, \"mean\": 10.166666666666668}} (export_time=153.06us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:01,935] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.52s, sent 2 reward messages to agent: reward=2.0 reward_min=0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2001 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:05,985] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7580.4 vnc_pixels_ps[total]=44546.4 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:05,985] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"474.50us\", \"mean\": \"16.10ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.32ms\", \"mean\": \"1.19ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"27.26us\", \"mean\": \"50.53us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.06ms\", \"mean\": \"420.73us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"716.92us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"7.54ms\", \"mean\": \"10.50ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"142.08us\", \"mean\": \"281.25us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"169.67us\", \"mean\": \"126.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.74us\", \"mean\": \"101.12us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"139.86us\", \"mean\": \"16.79ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.0, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.27642713349613557, \"mean\": 0.0830564784053156}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 1.268857754044954, \"value\": 15.0, \"mean\": 14.119999999999996}} (export_time=112.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:05,986] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.05s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2005 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:08,452] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.47s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:11,002] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6776.1 vnc_pixels_ps[total]=44450.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:11,003] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"409.33us\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"1.03ms\", \"mean\": \"559.33us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"27.29us\", \"mean\": \"50.73us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"398.57us\", \"mean\": \"341.37us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"5.03ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"135.49us\", \"mean\": \"281.14us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"39.42us\", \"mean\": \"107.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"31.53us\", \"mean\": \"102.82us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.57us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910294}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.5089773777040522, \"value\": 16.0, \"mean\": 15.458333333333332}} (export_time=164.99us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:11,003] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.55s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1906 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:13,886] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.88s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:16,019] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6777.3 vnc_pixels_ps[total]=44385.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:16,019] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"390.42us\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"970.01us\", \"mean\": \"539.11us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"22.64us\", \"mean\": \"48.12us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"367.59us\", \"mean\": \"333.43us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"4.81ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"120.69us\", \"mean\": \"277.94us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"38.43us\", \"mean\": \"98.40us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"29.63us\", \"mean\": \"97.61us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"20.99us\", \"mean\": \"16.76ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 1.4142135623730951, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.07973421926910297}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 0.9890707100936816, \"value\": 18.0, \"mean\": 16.749999999999996}} (export_time=143.53us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:16,020] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.13s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1905 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:17,802] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.78s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:19,102] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 1 reward messages to agent: reward=5.0 reward_min=5.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,035] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7519.0 vnc_pixels_ps[total]=44109.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,035] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"524.41us\", \"mean\": \"16.21ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"1.47ms\", \"mean\": \"727.42us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"26.45us\", \"mean\": \"44.01us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"510.46us\", \"mean\": \"306.14us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"639.11us\", \"mean\": \"5.34ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"131.92us\", \"mean\": \"247.70us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"43.23us\", \"mean\": \"84.42us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"30.12us\", \"mean\": \"88.71us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"19.25us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 2.516611478423583, \"mean\": 2.666666666666667}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2764271334961357, \"mean\": 0.08305647840531559}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 3.452052529534663, \"value\": 26.0, \"mean\": 21.4}} (export_time=138.76us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,036] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.93s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1935 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,668] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=249us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 97->98, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,669] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=98\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,670] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,670] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:21,685] init detected end of child process 7215 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:21,690] init detected end of child process 7230 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:21,691] init detected end of child process 7432 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:21,691] init detected end of child process 7438 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:21,711] init detected end of child process 7460 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,747] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,747] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:21 [info] 70#70: *513 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:21 [info] 70#70: *514 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:21 [info] 70#70: *512 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:21,839] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:22,009] init detected end of child process 7218 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:22,009] init detected end of child process 7227 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:22,009] init detected end of child process 7229 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:22,009] init detected end of child process 7226 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,113] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.27s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,114] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,199] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,709] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,709] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,709] [play_vexpect] Using VNCSession arguments: {'fine_quality_level': 50, 'compress_level': 0, 'encoding': 'zrle', 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,709] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,713] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,714] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:37:23 I0508 22:37:23.714231 7835 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:37:23 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::50782\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:37:23 I0508 22:37:23.715826 7835 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:23,833] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:27,884] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,717] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['211us', '100us', '92us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,718] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,718] [play_vexpect] vexpect macro complete in 6.970484s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:37:30 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::50782 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 2 rects, 65.617 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 8.18457 KiB (1:31.3199 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 16 rects, 396.818 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.232 KiB (1:10.3191 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 5 rects, 327.68 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  960.354 KiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 28 rects, 790.623 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.09269 MiB (1:2.76044 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,903] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 98->98, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,903] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,903] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=97->98, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,904] [INFO:universe.rewarder.remote] [Rewarder] Over past 9.87s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,904] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=16.0 episode_count=14 episode_duration=34.95\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,905] [INFO:universe.wrappers.logger] Stats for the past 9.87s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=886.2 vnc_pixels_ps[total]=3089.4 reward_lag=None rewarder_message_lag=None fps=3.95\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,915] [INFO:gym_controlplane.reward.reward] First score parsed: score=12. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:30,916] [INFO:universe.pyprofile] [pyprofile] period=9.88s timers={\"rewarder.sleep\": {\"calls\": 38, \"std\": \"215.69us\", \"mean\": \"16.30ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"4.18ms\", \"mean\": \"2.08ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"9.36ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"12.54us\", \"mean\": \"20.57us\"}, \"rewarder.compute_reward\": {\"calls\": 39, \"std\": \"1.74ms\", \"mean\": \"508.22us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"17.35us\", \"mean\": \"35.44us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"153.64us\", \"mean\": \"245.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 39, \"std\": \"34.11us\", \"mean\": \"73.08us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"25.53us\", \"mean\": \"51.74us\"}, \"rewarder.frame\": {\"calls\": 39, \"std\": \"2.46ms\", \"mean\": \"16.35ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 39, \"std\": 4.796816308100324, \"mean\": 0.8717948717948718}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 7.155417527999327, \"value\": 10, \"mean\": 22.8}} (export_time=109.20us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:32,171] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.27s, sent 3 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=2 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2081 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:35,871] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.70s, sent 2 reward messages to agent: reward=6.0 reward_min=2.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:35,921] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=11.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20857.8 vnc_pixels_ps[total]=99408.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:35,921] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.00ms\", \"mean\": \"16.17ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"2.09ms\", \"mean\": \"1.07ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"15.00us\", \"mean\": \"30.04us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"716.95us\", \"mean\": \"314.49us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"914.08us\", \"mean\": \"5.72ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"76.43us\", \"mean\": \"170.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"35.91us\", \"mean\": \"83.53us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"22.10us\", \"mean\": \"65.44us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"26.95us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.0954451150103321, \"mean\": 2.2}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28622877266096675, \"mean\": 0.08970099667774088}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 2.6214108552065767, \"value\": 19.0, \"mean\": 16.77777777777778}} (export_time=157.12us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:36,954] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1934 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:38,678] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.72s, sent 1 reward messages to agent: reward=2.0 reward_min=2.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 4124, 'rewarder.vnc.updates.pixels': 1368, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:40,421] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.74s, sent 3 reward messages to agent: reward=6.0 reward_min=1.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:40,938] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=10887.5 vnc_pixels_ps[total]=45744.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:40,938] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"1.02ms\", \"mean\": \"16.16ms\"}, \"reward.parsing.score\": {\"calls\": 29, \"std\": \"2.75ms\", \"mean\": \"1.59ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 87, \"std\": \"17.87us\", \"mean\": \"34.80us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.01ms\", \"mean\": \"368.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 6, \"std\": \"1.04ms\", \"mean\": \"6.46ms\"}, \"reward.parsing.gameover\": {\"calls\": 29, \"std\": \"68.44us\", \"mean\": \"195.01us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"30.13us\", \"mean\": \"80.94us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 29, \"std\": \"13.95us\", \"mean\": \"65.80us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"16.34us\", \"mean\": \"16.75ms\"}} counters={\"agent_conn.reward\": {\"calls\": 6, \"std\": 1.0488088481701514, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.295555860859078, \"mean\": 0.09634551495016613}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 87, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 29, \"std\": 3.5296073547659295, \"value\": 30.0, \"mean\": 24.62068965517241}} (export_time=153.54us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:43,240] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.82s, sent 3 reward messages to agent: reward=10.0 reward_min=0 reward_max=7.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1915 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:45,946] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7577.1 vnc_pixels_ps[total]=44396.4 reward_lag=None rewarder_message_lag=None fps=59.91\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:45,951] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"481.19us\", \"mean\": \"16.23ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"3.89ms\", \"mean\": \"1.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.83us\", \"mean\": \"33.81us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.22ms\", \"mean\": \"342.89us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.91ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"8.93ms\", \"mean\": \"11.89ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"88.14us\", \"mean\": \"191.83us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"147.22us\", \"mean\": \"87.73us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"27.64us\", \"mean\": \"77.55us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"413.59us\", \"mean\": \"16.81ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 3.095695936834452, \"mean\": 2.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.27174648819470304, \"mean\": 0.07999999999999999}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 4.218661096755153, \"value\": 41.0, \"mean\": 36.83333333333333}} (export_time=181.44us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:45,951] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.71s, sent 2 reward messages to agent: reward=1.0 reward_min=0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2020 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:50,957] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5960.0 vnc_pixels_ps[total]=44087.7 reward_lag=None rewarder_message_lag=None fps=60.13\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:50,958] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"916.87us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"36.96us\", \"mean\": \"244.32us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"15.29us\", \"mean\": \"36.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"172.01us\", \"mean\": \"247.28us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"51.49us\", \"mean\": \"201.03us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"93.95us\", \"mean\": \"81.55us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"11.42us\", \"mean\": \"73.36us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"616.62us\", \"mean\": \"16.84ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 41.0, \"mean\": 41.0}} (export_time=134.71us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:50,958] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1721 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,724] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=453us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,724] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 98->99, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,725] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=99\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,726] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,726] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:51,741] init detected end of child process 7578 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:51,758] init detected end of child process 7593 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:51,764] init detected end of child process 7801 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:51,770] init detected end of child process 7795 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:51,787] init detected end of child process 7826 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:51 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:51 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:37:51 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,874] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:51,874] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:51 [info] 70#70: *516 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:51 [info] 70#70: *517 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:37:51 [info] 70#70: *515 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:52,032] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:52,121] init detected end of child process 7581 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:52,121] init detected end of child process 7589 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:52,121] init detected end of child process 7590 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:37:52,121] init detected end of child process 7592 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:53,421] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.39s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:53,422] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:37:59,209] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,041] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,041] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,041] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'fine_quality_level': 50, 'subsample_level': 2, 'encoding': 'zrle', 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,042] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,045] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,045] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:00 I0508 22:38:00.04603 8214 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:00 I0508 22:38:00.049224 8214 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:00 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::51188\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:00,271] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,846] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['249us', '126us', '115us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,846] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,847] [play_vexpect] vexpect macro complete in 1.757612s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:01 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::51188 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 7\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 5 rects, 508 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            150 B (1:13.9467 ratio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 6 rects, 67.858 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  17.8398 KiB (1:14.8623 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 22 rects, 1.27949 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  3.66204 MiB (1:1.33289 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 34 rects, 1.34793 Mpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          3.67966 MiB (1:1.39751 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,976] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 99->99, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,977] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,977] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=98->99, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,978] [INFO:universe.rewarder.remote] [Rewarder] Over past 11.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,980] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=31.0 episode_count=18 episode_duration=31.08\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:01,981] [INFO:universe.wrappers.logger] Stats for the past 11.02s: vnc_updates_ps=0.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=802.8 vnc_pixels_ps[total]=2796.0 reward_lag=None rewarder_message_lag=None fps=4.26\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:02,006] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:02,007] [INFO:universe.pyprofile] [pyprofile] period=11.05s timers={\"rewarder.sleep\": {\"calls\": 46, \"std\": \"515.44us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 5, \"std\": \"10.94ms\", \"mean\": \"5.16ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"24.56ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 15, \"std\": \"17.54us\", \"mean\": \"33.98us\"}, \"rewarder.compute_reward\": {\"calls\": 47, \"std\": \"3.85ms\", \"mean\": \"838.37us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"21.33us\", \"mean\": \"65.72us\"}, \"reward.parsing.gameover\": {\"calls\": 5, \"std\": \"242.38us\", \"mean\": \"389.91us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 47, \"std\": \"15.59us\", \"mean\": \"79.40us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 5, \"std\": \"35.17us\", \"mean\": \"66.61us\"}, \"rewarder.frame\": {\"calls\": 47, \"std\": \"2.22ms\", \"mean\": \"16.52ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 2, \"std\": 0.0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 47, \"std\": 4.37235449286604, \"mean\": 0.723404255319149}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 9, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 4, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 5, \"std\": 13.863621460498695, \"value\": 10, \"mean\": 34.8}} (export_time=181.20us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:03,108] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.13s, sent 2 reward messages to agent: reward=3.0 reward_min=1 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2077 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:03 [info] 70#70: *519 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:03 [info] 70#70: *520 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:04,860] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.75s, sent 2 reward messages to agent: reward=5.0 reward_min=1.0 reward_max=4.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:05,943] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:06,994] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=11.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26089.2 vnc_pixels_ps[total]=90843.4 reward_lag=None rewarder_message_lag=None fps=59.86\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:07,010] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.65ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 28, \"std\": \"5.04ms\", \"mean\": \"2.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 84, \"std\": \"14.21us\", \"mean\": \"43.03us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.83ms\", \"mean\": \"563.87us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"8.16ms\", \"mean\": \"7.46ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 5, \"std\": \"2.82ms\", \"mean\": \"12.53ms\"}, \"reward.parsing.gameover\": {\"calls\": 28, \"std\": \"53.16us\", \"mean\": \"241.69us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"572.16us\", \"mean\": \"149.16us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 28, \"std\": \"19.44us\", \"mean\": \"89.93us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"835.61us\", \"mean\": \"16.87ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.3038404810405297, \"mean\": 1.8}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.29094872880062156, \"mean\": 0.09302325581395347}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 84, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 28, \"std\": 3.162905033978773, \"value\": 19.0, \"mean\": 14.82142857142857}} (export_time=187.87us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:07,016] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2030 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:09,646] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.63s, sent 2 reward messages to agent: reward=2.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:10,729] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:11,996] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=5.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7600.1 vnc_pixels_ps[total]=44695.9 reward_lag=None rewarder_message_lag=None fps=59.98\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:12,013] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.32ms\", \"mean\": \"15.94ms\"}, \"reward.parsing.score\": {\"calls\": 25, \"std\": \"3.92ms\", \"mean\": \"1.39ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 75, \"std\": \"10.68us\", \"mean\": \"45.12us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.24ms\", \"mean\": \"423.68us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.41ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"6.19ms\", \"mean\": \"13.30ms\"}, \"reward.parsing.gameover\": {\"calls\": 25, \"std\": \"36.09us\", \"mean\": \"255.36us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"202.65us\", \"mean\": \"121.26us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 25, \"std\": \"17.28us\", \"mean\": \"96.76us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"807.09us\", \"mean\": \"16.91ms\"}} counters={\"agent_conn.reward\": {\"calls\": 4, \"std\": 0.5, \"mean\": 0.75}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2768471963423705, \"mean\": 0.08333333333333336}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 0.8660254037844379, \"value\": 22.0, \"mean\": 20.6}} (export_time=221.49us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:12,014] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.28s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2004 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:14,629] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.62s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:15,712] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.08s, sent 2 reward messages to agent: reward=3.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:17,012] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=5.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=9276.8 vnc_pixels_ps[total]=45431.2 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:17,013] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.69ms\", \"mean\": \"15.74ms\"}, \"reward.parsing.score\": {\"calls\": 27, \"std\": \"3.97ms\", \"mean\": \"1.94ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 81, \"std\": \"12.16us\", \"mean\": \"44.36us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"1.35ms\", \"mean\": \"471.48us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"1.42ms\", \"mean\": \"10.87ms\"}, \"reward.parsing.gameover\": {\"calls\": 27, \"std\": \"35.14us\", \"mean\": \"248.75us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"242.11us\", \"mean\": \"116.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 27, \"std\": \"22.62us\", \"mean\": \"95.42us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"1.01ms\", \"mean\": \"17.05ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 0.7071067811865476, \"mean\": 1.0}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.2866599257717727, \"mean\": 0.09000000000000002}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 81, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 27, \"std\": 1.7934670937946455, \"value\": 27.0, \"mean\": 23.296296296296298}} (export_time=179.29us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:17,014] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.30s, sent 2 reward messages to agent: reward=1.0 reward_min=0.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<1917 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:18,979] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.97s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,829] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=349us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,829] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,829] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.85s, sent 2 reward messages to agent: reward=3.0 reward_min=0.0 reward_max=3.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,830] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,830] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,830] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 99->100, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,830] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,830] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,831] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=100\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,831] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,831] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:21,846] init detected end of child process 7942 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:21,858] init detected end of child process 7957 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:21,862] init detected end of child process 8160 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:21,866] init detected end of child process 8166 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:21,883] init detected end of child process 8188 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:21 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,967] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:21,967] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:22 [info] 70#70: *518 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:22,109] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:22,229] init detected end of child process 7954 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:22,229] init detected end of child process 7945 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:22,229] init detected end of child process 7953 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:22,229] init detected end of child process 7956 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:23,490] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.38s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:23,490] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:23,631] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,453] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,453] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,453] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'subsample_level': 2, 'fine_quality_level': 50, 'compress_level': 0, 'start_timeout': 7}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,453] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,465] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,465] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:24 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::51358\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:24 I0508 22:38:24.466713 8566 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:24 I0508 22:38:24.500974 8566 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:24,666] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:28,700] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:32,766] [play_vexpect] Advancing to the next hopeful state (3/3): ready2\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,666] [play_vexpect] Handled error.VExpectTimeout: Error: vexpect has been looking for the same states for 10s: [ready0, ready1, ready2] (old plausible states: []) (runtime: 10.148689s)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:34 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::51358 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 3 rects, 279 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            90 B (1:12.8 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Bitmap RLE: 1 rects, 81 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                 51 B (1:6.58824 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 14 rects, 395.888 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  149.639 KiB (1:10.3356 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 24 rects, 789.464 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27168 MiB (1:2.3684 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,880] [INFO:root] [EnvController] RESET CAUSE: VExpect failed with returncode 10, which means it timed out internally. Going to trigger a reset.\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,880] [INFO:root] [EnvController] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,881] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 100->101, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:38:34 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,996] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,997] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:34,997] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,009] init detected end of child process 8307 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,014] init detected end of child process 8322 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,019] init detected end of child process 8531 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,025] init detected end of child process 8524 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,036] init detected end of child process 8557 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:35,139] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:35 [info] 70#70: *522 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:35 [info] 70#70: *523 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:38:35 [info] 70#70: *521 client 127.0.0.1 closed keepalive connection\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,477] init detected end of child process 8310 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,477] init detected end of child process 8318 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,477] init detected end of child process 8319 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:38:35,477] init detected end of child process 8321 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:36,428] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.29s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:36,429] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:36,484] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e internet.SlitherIO-v0 -r vnc://127.0.0.1:5900 -d\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,159] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,159] [play_vexpect] Using the golang VNC implementation\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,159] [play_vexpect] Using VNCSession arguments: {'subsample_level': 2, 'encoding': 'zrle', 'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,159] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,168] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,168] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:37 I0508 22:38:37.168678 8923 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:37 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: accepted: 127.0.0.1::51604\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:37 I0508 22:38:37.170632 8923 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:37,318] [play_vexpect] Waiting for any of [ready0, ready1, ready2] to activate\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:41,335] [play_vexpect] Advancing to the next hopeful state (2/3): ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:41 I0508 22:38:41.519876 62 gymvnc.go:374] [0:127.0.0.1:5900] update queue max of 60 reached; pausing further updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,218] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2] distance_m=[0.0049178139, 0.0, 0.0] match_time_m=['199us', '101us', '81us'])\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,218] [play_vexpect] Reaching start state: ready1\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,219] [play_vexpect] vexpect macro complete in 8.016542s\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] \n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc] Tue May  8 22:38:45 2018\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  Connections: closed: 127.0.0.1::51604 (Clean disconnection)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager: Framebuffer updates: 8\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   ZRLE:\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Solid: 6 rects, 668 pixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:            180 B (1:15.2444 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Indexed RLE: 17 rects, 396.978 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  150.181 KiB (1:10.3269 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:     Full Colour: 6 rects, 393.216 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:                  1.12541 MiB (1:1.3329 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:   Total: 29 rects, 790.862 kpixels\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [tigervnc]  EncodeManager:          1.27225 MiB (1:2.37158 ratio)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,525] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=internet.SlitherIO-v0) -> running (env_id=internet.SlitherIO-v0) (episode_id: 101->101, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,525] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,525] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=internet.SlitherIO-v0 episode_id=99->101, env_state=running\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,526] [INFO:universe.rewarder.remote] [Rewarder] Over past 23.70s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,526] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=23.0 episode_count=18 episode_duration=43.55\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m 2018/05/08 22:38:45 I0508 22:38:45.527657 62 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,528] [INFO:universe.wrappers.logger] Stats for the past 28.51s: vnc_updates_ps=0.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1509.1 vnc_pixels_ps[total]=7940.8 reward_lag=None rewarder_message_lag=None fps=10.17\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,543] [INFO:universe.pyprofile] [pyprofile] period=28.53s timers={\"rewarder.sleep\": {\"calls\": 289, \"std\": \"1.73ms\", \"mean\": \"15.75ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"4.15ms\", \"mean\": \"1.78ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 3, \"std\": \"1.09ms\", \"mean\": \"12.72ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"15.13us\", \"mean\": \"44.81us\"}, \"rewarder.compute_reward\": {\"calls\": 290, \"std\": \"1.46ms\", \"mean\": \"484.31us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 6, \"std\": \"26.05us\", \"mean\": \"57.54us\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"78.10us\", \"mean\": \"281.09us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 290, \"std\": \"373.98us\", \"mean\": \"139.68us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"21.50us\", \"mean\": \"87.23us\"}, \"rewarder.frame\": {\"calls\": 290, \"std\": \"1.56ms\", \"mean\": \"17.02ms\"}} counters={\"agent_conn.done\": {\"calls\": 1, \"std\": 0, \"mean\": 1.0}, \"agent_conn.reward\": {\"calls\": 4, \"std\": 1.7320508075688772, \"mean\": 1.5}, \"reward.vnc.updates.n\": {\"calls\": 290, \"std\": 3.587992543246842, \"mean\": 0.296551724137931}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 25, \"std\": 2.803569153775238, \"value\": 33.0, \"mean\": 30.12}} (export_time=196.46us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:45,565] [INFO:gym_controlplane.reward.reward] First score parsed: score=11. Our hardcoded initial_score=10\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:49,017] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.49s, sent 5 reward messages to agent: reward=7.0 reward_min=0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.profile': '<2149 bytes>', 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:50,534] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=17.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=37780.3 vnc_pixels_ps[total]=138853.5 reward_lag=None rewarder_message_lag=None fps=59.94\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:50,550] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"calls\": 299, \"std\": \"1.46ms\", \"mean\": \"15.90ms\"}, \"reward.parsing.score\": {\"calls\": 26, \"std\": \"5.30ms\", \"mean\": \"2.40ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 4, \"std\": \"4.88ms\", \"mean\": \"13.64ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 78, \"std\": \"13.24us\", \"mean\": \"42.40us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.78ms\", \"mean\": \"521.14us\"}, \"rewarder.sleep.missed\": {\"calls\": 2, \"std\": \"3.02ms\", \"mean\": \"3.86ms\"}, \"score.crop_cache.readthrough.MatchImage\": {\"calls\": 3, \"std\": \"10.82us\", \"mean\": \"50.70us\"}, \"reward.parsing.gameover\": {\"calls\": 26, \"std\": \"52.57us\", \"mean\": \"246.28us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"433.97us\", \"mean\": \"134.83us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 26, \"std\": \"9.45us\", \"mean\": \"90.24us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"816.03us\", \"mean\": \"16.94ms\"}} counters={\"agent_conn.reward\": {\"calls\": 5, \"std\": 1.140175425099138, \"mean\": 1.4}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.28139031506622186, \"mean\": 0.08637873754152822}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 75, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 26, \"std\": 2.072530968498329, \"value\": 17.0, \"mean\": 14.15384615384615}} (export_time=210.05us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:50,551] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.53s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2189 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:54,417] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.87s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:55,553] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6765.0 vnc_pixels_ps[total]=44270.3 reward_lag=None rewarder_message_lag=None fps=59.98\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:55,554] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.01ms\", \"mean\": \"16.09ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"2.89ms\", \"mean\": \"906.03us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"14.07us\", \"mean\": \"45.51us\"}, \"rewarder.compute_reward\": {\"calls\": 300, \"std\": \"891.46us\", \"mean\": \"352.51us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"13.88ms\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"51.76us\", \"mean\": \"254.72us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 300, \"std\": \"253.01us\", \"mean\": \"110.07us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"10.58us\", \"mean\": \"88.82us\"}, \"rewarder.frame\": {\"calls\": 300, \"std\": \"492.22us\", \"mean\": \"16.82ms\"}} counters={\"agent_conn.reward\": {\"calls\": 2, \"std\": 0.7071067811865476, \"mean\": 0.5}, \"reward.vnc.updates.n\": {\"calls\": 300, \"std\": 0.26650636207348033, \"mean\": 0.07666666666666669}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.4217411678366491, \"value\": 18.0, \"mean\": 17.217391304347828}} (export_time=150.92us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:55,561] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.14s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1902 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:57,669] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.11s, sent 1 reward messages to agent: reward=3.0 reward_min=3.0 reward_max=3.0 done=False info={'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:38:59,403] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.73s, sent 1 reward messages to agent: reward=1.0 reward_min=1.0 reward_max=1.0 done=False info={'rewarder.vnc.updates.bytes': 1294, 'rewarder.vnc.updates.pixels': 9600, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:00,569] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=7612.5 vnc_pixels_ps[total]=44731.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:00,570] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 300, \"std\": \"1.21ms\", \"mean\": \"15.98ms\"}, \"reward.parsing.score\": {\"calls\": 24, \"std\": \"4.01ms\", \"mean\": \"1.42ms\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 72, \"std\": \"16.16us\", \"mean\": \"43.64us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"1.32ms\", \"mean\": \"407.79us\"}, \"rewarder.sleep.missed\": {\"calls\": 1, \"std\": \"0.00us\", \"mean\": \"2.05ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"calls\": 2, \"std\": \"6.06ms\", \"mean\": \"13.41ms\"}, \"reward.parsing.gameover\": {\"calls\": 24, \"std\": \"53.86us\", \"mean\": \"244.15us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"556.07us\", \"mean\": \"127.57us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 24, \"std\": \"18.42us\", \"mean\": \"86.14us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"660.17us\", \"mean\": \"16.91ms\"}} counters={\"agent_conn.reward\": {\"calls\": 3, \"std\": 1.5275252316519468, \"mean\": 1.3333333333333333}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2713323837260709, \"mean\": 0.079734219269103}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 72, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 22, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 24, \"std\": 1.7610932046210162, \"value\": 22.0, \"mean\": 19.833333333333332}} (export_time=192.88us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:00,577] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.17s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<2030 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:05,586] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5933.7 vnc_pixels_ps[total]=44021.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:05,586] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"723.37us\", \"mean\": \"16.15ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"51.30us\", \"mean\": \"282.45us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"11.56us\", \"mean\": \"40.73us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"390.59us\", \"mean\": \"296.85us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"51.37us\", \"mean\": \"231.67us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"350.54us\", \"mean\": \"113.28us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"14.48us\", \"mean\": \"81.97us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"341.34us\", \"mean\": \"16.80ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.2660985088079445, \"mean\": 0.0764119601328904}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 22.0, \"mean\": 22.0}} (export_time=131.85us)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:05,587] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1719 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:10,603] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5903.9 vnc_pixels_ps[total]=43790.6 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:10,604] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"calls\": 301, \"std\": \"818.16us\", \"mean\": \"16.06ms\"}, \"reward.parsing.score\": {\"calls\": 23, \"std\": \"73.99us\", \"mean\": \"317.62us\"}, \"score.crop_cache.get.MatchImage\": {\"calls\": 69, \"std\": \"16.93us\", \"mean\": \"44.87us\"}, \"rewarder.compute_reward\": {\"calls\": 301, \"std\": \"548.33us\", \"mean\": \"321.15us\"}, \"reward.parsing.gameover\": {\"calls\": 23, \"std\": \"83.67us\", \"mean\": \"255.13us\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"calls\": 301, \"std\": \"515.43us\", \"mean\": \"118.51us\"}, \"score.crop_cache.get.OCRScorerV0\": {\"calls\": 23, \"std\": \"24.56us\", \"mean\": \"95.32us\"}, \"rewarder.frame\": {\"calls\": 301, \"std\": \"586.59us\", \"mean\": \"16.88ms\"}} counters={\"agent_conn.reward\": {\"calls\": 1, \"std\": 0, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"calls\": 301, \"std\": 0.26609850880794444, \"mean\": 0.07641196013289041}, \"score.crop_cache.hit.MatchImage\": {\"calls\": 69, \"std\": 0.0, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"calls\": 23, \"std\": 0.0, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"std\": 0.0, \"value\": 22.0, \"mean\": 22.0}} (export_time=190.73us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:10,604] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.profile': '<1714 bytes>', 'rewarder.vnc.updates.pixels': 0}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,270] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=[0.0, 0.0, 0.0] match_time=468us\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,270] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,270] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.67s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.bytes': 4865, 'rewarder.vnc.updates.pixels': 1691, 'rewarder.vnc.updates.n': 1}\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,270] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,271] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,271] [INFO:root] [EnvStatus] Changing env_state: running (env_id=internet.SlitherIO-v0) -> resetting (env_id=internet.SlitherIO-v0) (episode_id: 101->102, fps=60)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,271] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,271] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,271] [INFO:root] [EnvController] Env state: env_id=internet.SlitherIO-v0 episode_id=102\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,272] [INFO:root] [EnvController] Writing internet.SlitherIO-v0 to /tmp/demo/env_id.txt\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,273] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:39:12,298] init detected end of child process 8674 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:39:12,312] init detected end of child process 8689 with exit code 0, not killed by signal\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:39:12,319] init detected end of child process 8891 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:39:12,324] init detected end of child process 8898 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [init] [2018-05-08 22:39:12,351] init detected end of child process 8920 with exit code 0, killed by SIGTERM: 15\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:39:12 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:39:12 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/internet.SlitherIO-v0 exists; not git-lfs pulling\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [Tue May  8 22:39:12 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for internet.SlitherIO-v0\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,464] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [2018-05-08 22:39:12,464] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:39:12 [info] 70#70: *525 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:39:12 [info] 70#70: *526 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "\u001b[36muniverse-fcnLfB-0 |\u001b[0m [nginx] 2018/05/08 22:39:12 [info] 70#70: *524 client 127.0.0.1 closed keepalive connection\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('internet.SlitherIO-v0')\n",
    "env.configure(remotes=1)  # automatically creates a local docker container\n",
    "observation_n = env.reset()\n",
    "count = 0\n",
    "#event = [('PointerEvent', 200,200, True)]\n",
    "#event = [('PointerEvent', 504, 200, 0)]\n",
    "#action_n = [event for ob in observation_n]  # your agent here\n",
    "idx = -1\n",
    "while True:\n",
    "  #idx+=1\n",
    "  #idx = idx%nactions\n",
    "  #action = idx2act(idx)\n",
    "  #action_n = [action for ob in observation_n]  # your agent here\n",
    "  observation_n, reward_n, done_n, info = env.step(action_n)\n",
    "  count += reward_n[0]\n",
    "  if observation_n[0] != None:\n",
    "      print('action:',action,'\\n observation:',observation_n,'\\n reward:',reward_n,'\\n done_n:',done_n,'\\n info:',info,'\\n count:',count)\n",
    "  env.render()\n",
    "  time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute tests & exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(observation_n[0]['vision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KeyEvent<key=_ (0x5f) direction=up>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PointerEvent<x=797 y=659 buttonmask=147>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303408"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nactionstest = (386-85)*(522-18)*2 # = 301*504*2\n",
    "nactionstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.33333333333333\n",
      "100.8\n"
     ]
    }
   ],
   "source": [
    "print(int((386-85)/3))\n",
    "print(int((522-18)/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = observation_n[0]['vision'][85:386,18:522,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import resize\n",
    "from skimage import data\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.viewer import ImageViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aserra/tensorflow/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "greystate = rgb2grey(state)\n",
    "new_state = resize(state, (80,80))\n",
    "new_greystate = resize(greystate, (84,84))\n",
    "x_t = rescale_intensity(new_greystate,out_range=(0,255))\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) \n",
    "print (s_t.shape)\n",
    "#In Keras, need to reshape\n",
    "s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
    "#viewer1 = ImageViewer(state)\n",
    "#viewer2 = ImageViewer(greystate)\n",
    "#viewer3 = ImageViewer(new_state)\n",
    "#ImageViewer(new_greystate).show()\n",
    "print(s_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=504x301 at 0x7FD2B29379E8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greystate = rgb2grey(state)\n",
    "greystate = greystate.astype('uint8')\n",
    "viewer = ImageViewer(greystate)\n",
    "viewer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greystate = rgb2grey(state)\n",
    "(greystate*255).astype('uint8')\n",
    "viewer = ImageViewer(greystate)\n",
    "viewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
